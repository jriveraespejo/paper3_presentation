{"title":"Bayesian modeling of comparative judgment data with `R` and `Stan`","markdown":{"yaml":{"title":"Bayesian modeling of comparative judgment data with `R` and `Stan`\n","author":[{"name":{"given":"Jose(ma)","family":"Rivera"},"orcid":"0000-0002-3088-2783","url":"https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/","email":"JoseManuel.RiveraEspejo@uantwerpen.be","corresponding":true,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Tine","family":"van Daal"},"orcid":"0000-0001-9398-9775","url":"https://www.uantwerpen.be/en/staff/tine-vandaal/","email":"tine.vandaal@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Sven","family":"De Maeyer"},"orcid":"0000-0003-2888-1631","url":"https://www.uantwerpen.be/en/staff/sven-demaeyer/","email":"sven.demaeyer@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Steven","family":"Gillis"},"orcid":null,"url":"https://www.uantwerpen.be/nl/personeel/steven-gillis/","email":"steven.gillis@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Linguistics","group":"Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)"}]}],"date":"last-modified","bibliography":"references.bib","title-slide-attributes":{"data-notes":"(to do)\n"}},"headingText":"1. Introduction","headingAttr":{"id":"","classes":[],"keyvalue":[["style","font-size:80%;"]]},"containsRefs":true,"markdown":"\n\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nThe Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] offers a **simple method** for measuring traits and conducting statistical inference from comparative judgment (CJ) data [@Andrich_1978; @Pollitt_2012b]. [Its simplicity stems from two features:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. A reliance on an extensive set of simplifying assumptions about the traits, judges, and stimuli involved in CJ assessments [@Thurstone_1927b; @Bramley_2008],\n2. The use of ad hoc procedures to handle inferences, including hypothesis testing [@Pollitt_2012b].\n:::\n:::\n\n::: {.fragment}\nHowever, recent studies question:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Do these assumptions hold in modern CJ applications? [@Bramley_2008; @Kelly_et_al_2022; @Rivera_et_al_2025]\n- Do the ad hoc procedures effectively fulfill their intended analytical purpose? [@Kelly_et_al_2022; @Rivera_et_al_2025]\n:::\n:::\n:::\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nTo address these concerns, Rivera et al. [@Rivera_et_al_2025] proposed *The Information-Theoretical model for CJ*. \n\n[The approach extends the general form of Thurstone's law of comparative judgment [@Thurstone_1927a; @Thurstone_1927b], combining Thurstone's core theoretical principles with key CJ assessment design features.]{.fragment style=\"font-size:80%;\"}\n\n[This integration enables the development of models tailored to the assumed data-generating process of the CJ system under study, thus:]{.fragment style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Eliminating the need to rely on the simplifying assumptions of the BTL model,\n- Removing the dependence on ad hoc hypothesis-testing procedures.\n:::\n:::\n\n[Nevertheless, although approach has the potential to yield reliable trait estimates and accurate statistical inferences, **this promise still needs to be empirically tested**.]{.fragment style=\"font-size:80%;\"} \n\n<!-- ######################################### -->\n\n# 2. Research goals\n\n---\n\n## 2. Research goals {style=\"font-size:80%;\"}\n\nThus, this tutorial has two overarching goals:\n\n::: {.fragment style=\"font-size:80%;\"}\n1. **To show how apply the Information-Theoretical model for CJ to a simulated dataset**,\n\n    A **tutorial component**, offering detailed guidance on data simulation, model and prior specification, estimation, and interpretation using the software `R` and `Stan`.\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nOnce a *sufficiently trustworthy model* is found in goal 1,\n\n2. **Evaluate whether the approach yield reliable trait estimates and accurate statistical inferences**,\n\n    A **model validation component** benchmarked against the classical BTL analysis.\n:::\n\n<!-- ######################################### -->\n\n# 3. A tale of two analytical methods\n\n---\n\n## 3. A tale of two analytical methods {style=\"font-size:80%;\"}\n\nCJ data can be analyzed under two analytical approaches:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **The classical BTL analysis** [@Pollitt_2012a; @Pollitt_2012b]\n    \n    It applies several sequential methods to estimate (generate) the traits and conduct inferences,\n\n2. **The Information-Theoretical model for CJ** [@Rivera_et_al_2025]\n\n    It applies one systematic, integrated approach for the same two purposes.\n:::\n:::\n\n<!-- ######################################### -->\n\n---\n\n## 3.1 The classical BTL analysis {style=\"font-size:80%;\"}\n\nThis paradigm applies several sequential methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Apply the BTL model**,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli (mean and standard error)\n- To generate the model residuals\n:::\n:::\n\n2. **Generate summaries** or **apply (multilevel) regression** to the stimuli's trait (mean estimates),\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the trait of the stimuli at the individual level\n- To assess the variability and conduct inferences at the stimuli and individual levels\n- To calculate correlation with other methods (a way of \"concurrent validity\")\n:::\n:::\n\n3. **Generate summaries** or **apply (multilevel) regression** to the model residuals,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the remaining variability at the judges level (investigate bias)\n- To assess the remaining variability and conduct inferences about judges biases\n- To conduct *misfit* identification for stimuli, individuals, and judges\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n--- \n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nIn contrast, this paradigm applies one systematic, integrated approach to estimate traits and conduct inferences [@Rivera_et_al_2025]. [This approach can be expressed as a three-step procedure:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Start with the proposed general CJ structure, represented by a DAG and an SCM (see next slide),\n2. Adapt the structure to the assumed data-generating process of the CJ system under study,\n3. Develop a *bespoke* statistical model for the analysis of the CJ system (possible multiple models)\n:::\n:::\n\n::: {.fragment}\n\nWith these three steps a researcher can:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Estimate the traits of the stimuli and individuals (mean and standard error)\n- Assess the variability and conduct inferences at the stimuli and individual levels\n- Estimate the biases of the judges and judgments (mean and standard error)\n- Assess the variability and conduct inferences at the judgments and judges levels\n- Conduct *oulier* identification for stimuli, individuals, judgments, and judges (akin to *misfit* identification)\n:::\n:::\n\n:::\n\n--- \n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\n<!-- commands for d-separation -->\n\\newcommand{\\dsep}{\\:\\bot\\:}\n\\newcommand{\\ndsep}{\\:\\not\\bot\\:}\n\\newcommand{\\cond}{\\:|\\:}\n\nThe general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] takes the following form:\n\n::: {.fragment}\n\n::: {#fig-cj15 layout-ncol=2}\n\n![](/images/CJ_TM_15.png){width=100%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK} \n\\end{aligned}\n$$\n\nComparative judgment model. *Left panel* illustrates the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nLeading to the general probabilistic and statistical model:\n\n::: {.fragment}\n\n::: {#fig-cj16 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\ \n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, X_{IA}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J}, Z_{JK}, e_{JK} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{I} ) P( e_{IA} ) P( e_{J} ) P( e_{JK} ) \\\\ \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\nComparative judgment model, SCM, probabilistic and statistical model assuming different discriminal dispersions for the student's traits\n:::\n\n:::\n\n\n::: {.fragment}\n::: {style=\"font-size:80%;\"}\nWith the following constraints to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$ [@Depaoli_2021]: \n:::\n:::\n\n::: {.fragment}\n$$\n\\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix}; \\quad \n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & p_{IA} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & p_{JK} \n  \\end{bmatrix}; \\quad \n  \\sum_{g=1}^{2} s_{XI}[g]/2 = 1; \\quad\n  0< p_{IA} < 1; \\quad \n  \\sum_{g=1}^{3} s_{ZJ}[g]/3 = 1; \\quad\n  0< p_{JK} < 1\n$$ \n:::\n\n<!-- ######################################### -->\n\n# 4. Methods \n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\nTo achieve the two overarching goals of the study, the tutorial and model validation components, this study proceeds through the following steps:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Simulate **two replicable datasets** based on a CJ structure of interest,\n\n     $\\longrightarrow$ *Tutorial and model validation component* \n\n2.  Apply the Information-Theoretical Model for CJ to the **first dataset**,\n\n    $\\longrightarrow$ *Tutorial component*\n\n3.  Apply the classical BTL analysis to the **first dataset**,\n\n    $\\longrightarrow$ *Model validation component*\n\n4.  Compare parameter recovery, in-sample fit, and out-of-sample fit between the two models obtained in steps 2 and 3,\n\n    $\\longrightarrow$ *Model validation component*\n\n5.  Use the models obtained in steps 2 and 3 to predict outcomes in the **second dataset** and compare their out-of-sample predictive accuracy.\n\n    $\\longrightarrow$ *Model validation component*\n:::\n:::\n\n\n<!-- ######################################### -->\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\nThe dataset simulation is inspired by the analysis of Boonen et al. [@Boonen_et_al_2020], because of the data characteristics and the study results. \n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the data characteristics:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- It includes multiple stimuli nested within individuals,\n- It includes multiple individuals,\n- Individuals differ in characteristics, such as age or hearing status,\n- Each judge makes only one comparison per stimulus pair, and comparisons are conducted by multiple judges,\n- Judges differ in characteristics, such as experience level,\n- Stimuli, individuals, and judges are selected using a (pseudo) random sampling algorithm,\n- Comparisons are assigned using a random comparison algorithm.\n:::\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the study results:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Individuals with different hearing statuses differ in their (latent) mean levels.\n- There is more unexplained variability between rather than within individuals (stimuli level)\n- No evidence of judges biases\n- Judges with different levels of experience did not differ in their (latent) mean levels.\n:::\n:::\n\n:::\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\nDiffering only in the replication seed, the study simulates **two datasets** using the following steps:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Simulate a *conceptual population* from a data-generating process of interest (see next slide) \n2. Simulate *two random samples* of stimuli, individual and judges (differing by replication seed)\n3. Simulate *two sets of random pair comparisons* (differing by replication seed)\n:::\n:::\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\n[Assumed data-generating process:]{style=\"font-size:80%;\"}\n\n::: {.fragment}\n\n::: {#fig-sim layout-ncol=2}\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n  \\text{with} & \\; \\text{general parameters:} \\\\\n  & \\beta_{XA} = 0 \\\\\n  & XI = \\{ XIc, XI[g=1], XI[g=2], XI[g=3] \\} \\\\\n  & \\beta_{XI} = \\{ \\beta_{XIc}, \\beta_{XI[g=1]}, \\beta_{XI[g=2]}, \\beta_{XI[g=3]} \\} = \\{ 0.1, 1, 0, -1\\} \\\\\n  & \\beta_{ZK} = 0 \\\\\n  & ZJ = \\{ ZJ[g=1], ZJ[g=2], ZJ[g=3] \\} \\\\\n  & \\beta_{ZJ} = \\{ \\beta_{ZJ[g=1]}, \\beta_{ZJ[g=2]}, \\beta_{ZJ[g=3]} \\} = \\{ 0, 0, 0\\} \\\\ \\\\\n  \\text{with} & \\; \\text{error parameters:}\\\\\n  & \\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix} ;\n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & p_{IA} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & p_{JK} \n  \\end{bmatrix} \\\\ \n  \\text{and} & \\\\\n  & s_{XI[g]} = 1 \\; \\forall g=\\{1,2,3\\} \\\\\n  & s_{ZJ} = \\{ s_{ZJ[g=1]}, s_{ZJ[g=2]}, s_{ZJ[g=3]} \\} = \\{ 0.5, 1, 1.5\\} \\\\\n  & p_{IA} = 0.2; \\quad p_{JK} = 0\n\\end{split}\n$$\n\nData-generating process for simulated CJ data, generative statistical model and parameter assumptions\n:::\n\n:::\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\n[In layman terms:]{style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:70%;\"}\n- No difference between stimuli characteristics $(\\beta_{XA})$,\n- Individual characteristics $(XI)$ consider one continuous variable and three groups,\n- There is a \"small\" but increasing effect from the continuous variable $(\\beta_{XIc})$ [@Cohen_1988; @Sawilowsky_2009]\n- There are \"very large\" differences in the (latent) mean of the individual' groups $(\\beta_{XI[g=1]}, \\beta_{XI[g=2]}, \\beta_{XI[g=3]})$ [@Cohen_1988; @Sawilowsky_2009],\n- No difference between judgment characteristics $(\\beta_{ZK})$, because judges only make one comparison,\n- Judges characteristics $(ZJ)$ consider three groups,\n- The are judges biases, but no differences between the mean bias of the judges' groups $(\\beta_{ZJ[g=1]}, \\beta_{ZJ[g=2]}, \\beta_{ZJ[g=3]})$,\n- Errors (residuals) are centered around zero with zero correlation among them $(\\boldsymbol{\\mu}, \\boldsymbol{Q})$,\n- Individual residual variability is the same across individual' groups $(s_{XI[g]})$,\n- Judges (bias) residual variability is different for different judges' groups, but they fulfill: $\\sum_{g=1}^{3} s_{ZJ[g]}/3 = 1$,\n- Stimuli remaining variability is less than individual variability $(p_{IA})$,\n- There is no judgment remaining variability $(p_{JK})$, because the judges only make one comparison.\n:::\n:::\n\n<!-- ######################################### -->\n\n---\n\n## 4.2 Bayesian estimation and analysis {style=\"font-size:80%;\"}\n\nThis section is **only relevant to the tutorial component** of the study. \n\n::: {.fragment style=\"font-size:80%;\"}\nThe tutorial offering detailed guidance on data simulation, model and prior specification, estimation, and interpretation using the software `R` and `Stan` using the Information-Theoretical model for CJ, will closely follow recommendations from:\n\n::: incremental \n1. The *Bayesian workflow* proposed by Gelman et al. [@Gelman_et_al_2020] \n2. The *WAMBS checklist* proposed by Depaoli et al. [@Depaoli_et_al_2017]\n:::\n\n:::\n\n<!-- ######################################### -->\n\n---\n\n## 4.3 Evaluation metrics {style=\"font-size:80%;\"}\n\nThis section is **only relevant to the model validation component** of the study. \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Using the two analytical methods on the first dataset, the model validation will compare:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- in-sample fit\n- out-of-sample fit\n- The general parameters' recovery between the two models\n- The error parameters' recovery between the two models\n- The traits of stimuli and individuals between the two models\n- The presence of judges biases and their estimates between the two models\n:::\n:::\n\n2. Predicting the second dataset with the two analytical methods will provide a measure of out-of-sample predictive accuracy\n\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 5. Results\n\n---\n\n## 5. Results {style=\"font-size:80%;\"}\n\n\n\n<!-- ######################################### -->\n\n# 6. Discussion\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n---\n\n## 6.2 Study limitations {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n# 7. Conclusion\n\n---\n\n## 7. Conclusion {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n---\n\n# References {style=\"font-size:80%;\"}\n\n:::{#refs style=\"font-size:80%;\"}\n\n:::\n","srcMarkdownNoYaml":"\n\n# 1. Introduction {style=\"font-size:80%;\"}\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nThe Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] offers a **simple method** for measuring traits and conducting statistical inference from comparative judgment (CJ) data [@Andrich_1978; @Pollitt_2012b]. [Its simplicity stems from two features:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. A reliance on an extensive set of simplifying assumptions about the traits, judges, and stimuli involved in CJ assessments [@Thurstone_1927b; @Bramley_2008],\n2. The use of ad hoc procedures to handle inferences, including hypothesis testing [@Pollitt_2012b].\n:::\n:::\n\n::: {.fragment}\nHowever, recent studies question:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Do these assumptions hold in modern CJ applications? [@Bramley_2008; @Kelly_et_al_2022; @Rivera_et_al_2025]\n- Do the ad hoc procedures effectively fulfill their intended analytical purpose? [@Kelly_et_al_2022; @Rivera_et_al_2025]\n:::\n:::\n:::\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nTo address these concerns, Rivera et al. [@Rivera_et_al_2025] proposed *The Information-Theoretical model for CJ*. \n\n[The approach extends the general form of Thurstone's law of comparative judgment [@Thurstone_1927a; @Thurstone_1927b], combining Thurstone's core theoretical principles with key CJ assessment design features.]{.fragment style=\"font-size:80%;\"}\n\n[This integration enables the development of models tailored to the assumed data-generating process of the CJ system under study, thus:]{.fragment style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Eliminating the need to rely on the simplifying assumptions of the BTL model,\n- Removing the dependence on ad hoc hypothesis-testing procedures.\n:::\n:::\n\n[Nevertheless, although approach has the potential to yield reliable trait estimates and accurate statistical inferences, **this promise still needs to be empirically tested**.]{.fragment style=\"font-size:80%;\"} \n\n<!-- ######################################### -->\n\n# 2. Research goals\n\n---\n\n## 2. Research goals {style=\"font-size:80%;\"}\n\nThus, this tutorial has two overarching goals:\n\n::: {.fragment style=\"font-size:80%;\"}\n1. **To show how apply the Information-Theoretical model for CJ to a simulated dataset**,\n\n    A **tutorial component**, offering detailed guidance on data simulation, model and prior specification, estimation, and interpretation using the software `R` and `Stan`.\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nOnce a *sufficiently trustworthy model* is found in goal 1,\n\n2. **Evaluate whether the approach yield reliable trait estimates and accurate statistical inferences**,\n\n    A **model validation component** benchmarked against the classical BTL analysis.\n:::\n\n<!-- ######################################### -->\n\n# 3. A tale of two analytical methods\n\n---\n\n## 3. A tale of two analytical methods {style=\"font-size:80%;\"}\n\nCJ data can be analyzed under two analytical approaches:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **The classical BTL analysis** [@Pollitt_2012a; @Pollitt_2012b]\n    \n    It applies several sequential methods to estimate (generate) the traits and conduct inferences,\n\n2. **The Information-Theoretical model for CJ** [@Rivera_et_al_2025]\n\n    It applies one systematic, integrated approach for the same two purposes.\n:::\n:::\n\n<!-- ######################################### -->\n\n---\n\n## 3.1 The classical BTL analysis {style=\"font-size:80%;\"}\n\nThis paradigm applies several sequential methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Apply the BTL model**,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli (mean and standard error)\n- To generate the model residuals\n:::\n:::\n\n2. **Generate summaries** or **apply (multilevel) regression** to the stimuli's trait (mean estimates),\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the trait of the stimuli at the individual level\n- To assess the variability and conduct inferences at the stimuli and individual levels\n- To calculate correlation with other methods (a way of \"concurrent validity\")\n:::\n:::\n\n3. **Generate summaries** or **apply (multilevel) regression** to the model residuals,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the remaining variability at the judges level (investigate bias)\n- To assess the remaining variability and conduct inferences about judges biases\n- To conduct *misfit* identification for stimuli, individuals, and judges\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n--- \n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nIn contrast, this paradigm applies one systematic, integrated approach to estimate traits and conduct inferences [@Rivera_et_al_2025]. [This approach can be expressed as a three-step procedure:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Start with the proposed general CJ structure, represented by a DAG and an SCM (see next slide),\n2. Adapt the structure to the assumed data-generating process of the CJ system under study,\n3. Develop a *bespoke* statistical model for the analysis of the CJ system (possible multiple models)\n:::\n:::\n\n::: {.fragment}\n\nWith these three steps a researcher can:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Estimate the traits of the stimuli and individuals (mean and standard error)\n- Assess the variability and conduct inferences at the stimuli and individual levels\n- Estimate the biases of the judges and judgments (mean and standard error)\n- Assess the variability and conduct inferences at the judgments and judges levels\n- Conduct *oulier* identification for stimuli, individuals, judgments, and judges (akin to *misfit* identification)\n:::\n:::\n\n:::\n\n--- \n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\n<!-- commands for d-separation -->\n\\newcommand{\\dsep}{\\:\\bot\\:}\n\\newcommand{\\ndsep}{\\:\\not\\bot\\:}\n\\newcommand{\\cond}{\\:|\\:}\n\nThe general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] takes the following form:\n\n::: {.fragment}\n\n::: {#fig-cj15 layout-ncol=2}\n\n![](/images/CJ_TM_15.png){width=100%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK} \n\\end{aligned}\n$$\n\nComparative judgment model. *Left panel* illustrates the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nLeading to the general probabilistic and statistical model:\n\n::: {.fragment}\n\n::: {#fig-cj16 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\ \n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, X_{IA}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J}, Z_{JK}, e_{JK} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{I} ) P( e_{IA} ) P( e_{J} ) P( e_{JK} ) \\\\ \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\nComparative judgment model, SCM, probabilistic and statistical model assuming different discriminal dispersions for the student's traits\n:::\n\n:::\n\n\n::: {.fragment}\n::: {style=\"font-size:80%;\"}\nWith the following constraints to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$ [@Depaoli_2021]: \n:::\n:::\n\n::: {.fragment}\n$$\n\\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix}; \\quad \n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & p_{IA} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & p_{JK} \n  \\end{bmatrix}; \\quad \n  \\sum_{g=1}^{2} s_{XI}[g]/2 = 1; \\quad\n  0< p_{IA} < 1; \\quad \n  \\sum_{g=1}^{3} s_{ZJ}[g]/3 = 1; \\quad\n  0< p_{JK} < 1\n$$ \n:::\n\n<!-- ######################################### -->\n\n# 4. Methods \n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\nTo achieve the two overarching goals of the study, the tutorial and model validation components, this study proceeds through the following steps:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Simulate **two replicable datasets** based on a CJ structure of interest,\n\n     $\\longrightarrow$ *Tutorial and model validation component* \n\n2.  Apply the Information-Theoretical Model for CJ to the **first dataset**,\n\n    $\\longrightarrow$ *Tutorial component*\n\n3.  Apply the classical BTL analysis to the **first dataset**,\n\n    $\\longrightarrow$ *Model validation component*\n\n4.  Compare parameter recovery, in-sample fit, and out-of-sample fit between the two models obtained in steps 2 and 3,\n\n    $\\longrightarrow$ *Model validation component*\n\n5.  Use the models obtained in steps 2 and 3 to predict outcomes in the **second dataset** and compare their out-of-sample predictive accuracy.\n\n    $\\longrightarrow$ *Model validation component*\n:::\n:::\n\n\n<!-- ######################################### -->\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\nThe dataset simulation is inspired by the analysis of Boonen et al. [@Boonen_et_al_2020], because of the data characteristics and the study results. \n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the data characteristics:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- It includes multiple stimuli nested within individuals,\n- It includes multiple individuals,\n- Individuals differ in characteristics, such as age or hearing status,\n- Each judge makes only one comparison per stimulus pair, and comparisons are conducted by multiple judges,\n- Judges differ in characteristics, such as experience level,\n- Stimuli, individuals, and judges are selected using a (pseudo) random sampling algorithm,\n- Comparisons are assigned using a random comparison algorithm.\n:::\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the study results:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Individuals with different hearing statuses differ in their (latent) mean levels.\n- There is more unexplained variability between rather than within individuals (stimuli level)\n- No evidence of judges biases\n- Judges with different levels of experience did not differ in their (latent) mean levels.\n:::\n:::\n\n:::\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\nDiffering only in the replication seed, the study simulates **two datasets** using the following steps:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Simulate a *conceptual population* from a data-generating process of interest (see next slide) \n2. Simulate *two random samples* of stimuli, individual and judges (differing by replication seed)\n3. Simulate *two sets of random pair comparisons* (differing by replication seed)\n:::\n:::\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\n[Assumed data-generating process:]{style=\"font-size:80%;\"}\n\n::: {.fragment}\n\n::: {#fig-sim layout-ncol=2}\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n  \\text{with} & \\; \\text{general parameters:} \\\\\n  & \\beta_{XA} = 0 \\\\\n  & XI = \\{ XIc, XI[g=1], XI[g=2], XI[g=3] \\} \\\\\n  & \\beta_{XI} = \\{ \\beta_{XIc}, \\beta_{XI[g=1]}, \\beta_{XI[g=2]}, \\beta_{XI[g=3]} \\} = \\{ 0.1, 1, 0, -1\\} \\\\\n  & \\beta_{ZK} = 0 \\\\\n  & ZJ = \\{ ZJ[g=1], ZJ[g=2], ZJ[g=3] \\} \\\\\n  & \\beta_{ZJ} = \\{ \\beta_{ZJ[g=1]}, \\beta_{ZJ[g=2]}, \\beta_{ZJ[g=3]} \\} = \\{ 0, 0, 0\\} \\\\ \\\\\n  \\text{with} & \\; \\text{error parameters:}\\\\\n  & \\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix} ;\n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & p_{IA} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & p_{JK} \n  \\end{bmatrix} \\\\ \n  \\text{and} & \\\\\n  & s_{XI[g]} = 1 \\; \\forall g=\\{1,2,3\\} \\\\\n  & s_{ZJ} = \\{ s_{ZJ[g=1]}, s_{ZJ[g=2]}, s_{ZJ[g=3]} \\} = \\{ 0.5, 1, 1.5\\} \\\\\n  & p_{IA} = 0.2; \\quad p_{JK} = 0\n\\end{split}\n$$\n\nData-generating process for simulated CJ data, generative statistical model and parameter assumptions\n:::\n\n:::\n\n---\n\n## 4.1 Dataset simulation {style=\"font-size:80%;\"}\n\n[In layman terms:]{style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:70%;\"}\n- No difference between stimuli characteristics $(\\beta_{XA})$,\n- Individual characteristics $(XI)$ consider one continuous variable and three groups,\n- There is a \"small\" but increasing effect from the continuous variable $(\\beta_{XIc})$ [@Cohen_1988; @Sawilowsky_2009]\n- There are \"very large\" differences in the (latent) mean of the individual' groups $(\\beta_{XI[g=1]}, \\beta_{XI[g=2]}, \\beta_{XI[g=3]})$ [@Cohen_1988; @Sawilowsky_2009],\n- No difference between judgment characteristics $(\\beta_{ZK})$, because judges only make one comparison,\n- Judges characteristics $(ZJ)$ consider three groups,\n- The are judges biases, but no differences between the mean bias of the judges' groups $(\\beta_{ZJ[g=1]}, \\beta_{ZJ[g=2]}, \\beta_{ZJ[g=3]})$,\n- Errors (residuals) are centered around zero with zero correlation among them $(\\boldsymbol{\\mu}, \\boldsymbol{Q})$,\n- Individual residual variability is the same across individual' groups $(s_{XI[g]})$,\n- Judges (bias) residual variability is different for different judges' groups, but they fulfill: $\\sum_{g=1}^{3} s_{ZJ[g]}/3 = 1$,\n- Stimuli remaining variability is less than individual variability $(p_{IA})$,\n- There is no judgment remaining variability $(p_{JK})$, because the judges only make one comparison.\n:::\n:::\n\n<!-- ######################################### -->\n\n---\n\n## 4.2 Bayesian estimation and analysis {style=\"font-size:80%;\"}\n\nThis section is **only relevant to the tutorial component** of the study. \n\n::: {.fragment style=\"font-size:80%;\"}\nThe tutorial offering detailed guidance on data simulation, model and prior specification, estimation, and interpretation using the software `R` and `Stan` using the Information-Theoretical model for CJ, will closely follow recommendations from:\n\n::: incremental \n1. The *Bayesian workflow* proposed by Gelman et al. [@Gelman_et_al_2020] \n2. The *WAMBS checklist* proposed by Depaoli et al. [@Depaoli_et_al_2017]\n:::\n\n:::\n\n<!-- ######################################### -->\n\n---\n\n## 4.3 Evaluation metrics {style=\"font-size:80%;\"}\n\nThis section is **only relevant to the model validation component** of the study. \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Using the two analytical methods on the first dataset, the model validation will compare:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- in-sample fit\n- out-of-sample fit\n- The general parameters' recovery between the two models\n- The error parameters' recovery between the two models\n- The traits of stimuli and individuals between the two models\n- The presence of judges biases and their estimates between the two models\n:::\n:::\n\n2. Predicting the second dataset with the two analytical methods will provide a measure of out-of-sample predictive accuracy\n\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 5. Results\n\n---\n\n## 5. Results {style=\"font-size:80%;\"}\n\n\n\n<!-- ######################################### -->\n\n# 6. Discussion\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n---\n\n## 6.2 Study limitations {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n# 7. Conclusion\n\n---\n\n## 7. Conclusion {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n---\n\n# References {style=\"font-size:80%;\"}\n\n:::{#refs style=\"font-size:80%;\"}\n\n:::\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["styles.css"],"output-file":"presentation.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.550","auto-stretch":true,"slideNumber":true,"chalkboard":true,"previewLinks":"auto","csl":"diabetologia.csl","logo":"images/logo-uantwerpen-sw-en-cmyk-pos.png","footer":"[Online manuscript (work in progress)](https://jriveraespejo.github.io/paper3_manuscript/)","title":"Bayesian modeling of comparative judgment data with `R` and `Stan`\n","author":[{"name":{"given":"Jose(ma)","family":"Rivera"},"orcid":"0000-0002-3088-2783","url":"https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/","email":"JoseManuel.RiveraEspejo@uantwerpen.be","corresponding":true,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Tine","family":"van Daal"},"orcid":"0000-0001-9398-9775","url":"https://www.uantwerpen.be/en/staff/tine-vandaal/","email":"tine.vandaal@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Sven","family":"De Maeyer"},"orcid":"0000-0003-2888-1631","url":"https://www.uantwerpen.be/en/staff/sven-demaeyer/","email":"sven.demaeyer@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Steven","family":"Gillis"},"orcid":null,"url":"https://www.uantwerpen.be/nl/personeel/steven-gillis/","email":"steven.gillis@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Linguistics","group":"Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)"}]}],"date":"last-modified","bibliography":["references.bib"],"title-slide-attributes":{"data-notes":"(to do)\n"}}}},"projectFormats":["revealjs"]}