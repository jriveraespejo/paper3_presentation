{"title":"Bayesian modeling of comparative judgment data with `R` and `Stan`","markdown":{"yaml":{"title":"Bayesian modeling of comparative judgment data with `R` and `Stan`\n","author":[{"name":{"given":"Jose(ma)","family":"Rivera"},"orcid":"0000-0002-3088-2783","url":"https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/","email":"JoseManuel.RiveraEspejo@uantwerpen.be","corresponding":true,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Tine","family":"van Daal"},"orcid":"0000-0001-9398-9775","url":"https://www.uantwerpen.be/en/staff/tine-vandaal/","email":"tine.vandaal@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Sven","family":"De Maeyer"},"orcid":"0000-0003-2888-1631","url":"https://www.uantwerpen.be/en/staff/sven-demaeyer/","email":"sven.demaeyer@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Steven","family":"Gillis"},"orcid":null,"url":"https://www.uantwerpen.be/nl/personeel/steven-gillis/","email":"steven.gillis@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Linguistics","group":"Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)"}]}],"date":"last-modified","bibliography":"references.bib","title-slide-attributes":{"data-notes":"(to do)\n"}},"headingText":"1. Introduction","headingAttr":{"id":"","classes":[],"keyvalue":[["style","font-size:80%;"]]},"containsRefs":true,"markdown":"\n\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nThe Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] offers a **simple method** for measuring traits and conducting statistical inference from comparative judgment (CJ) data [@Andrich_1978; @Pollitt_2012b]. \n\n[Its simplicity stems from two features:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. A reliance on an extensive set of simplifying assumptions about the traits, judges, and stimuli involved in CJ assessments [@Thurstone_1927b; @Bramley_2008],\n2. The use of ad hoc procedures to handle inferences, including hypothesis testing [@Pollitt_2012b].\n:::\n:::\n\n::: {.fragment}\nHowever, recent studies question whether:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- These assumptions hold in modern CJ applications? [@Bramley_2008; @Kelly_et_al_2022; @Rivera_et_al_2025]\n- The ad hoc procedures effectively fulfill their intended analytical purpose? [@Kelly_et_al_2022; @Rivera_et_al_2025]\n:::\n:::\n:::\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nTo address these concerns, Rivera et al. [@Rivera_et_al_2025] proposed *The Information-Theoretical model for CJ*. The approach,\n\n[1. Extends the general form of Thurstone's law of comparative judgment [@Thurstone_1927a; @Thurstone_1927b], combining Thurstone's core theoretical principles with key CJ assessment design features.]{.fragment style=\"font-size:80%;\"}\n\n[2. Enables the development of models tailored to the assumed data-generating process of the CJ system under study, thus:]{.fragment style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Eliminating the need to rely on the simplifying assumptions of the BTL model,\n- Removing the dependence on ad hoc hypothesis-testing procedures.\n:::\n:::\n\n[Nevertheless, although approach has the potential to yield reliable trait estimates and accurate statistical inferences, **this promise still needs to be empirically tested**.]{.fragment style=\"font-size:80%;\"} \n\n<!-- ######################################### -->\n\n# 2. Research goals\n\n---\n\n## 2. Research goals {style=\"font-size:80%;\"}\n\nThus, this study has **two overarching goals**:\n\n::: {.fragment style=\"font-size:80%;\"}\n1. *To show how apply the Information-Theoretical model for CJ to a simulated dataset*,\n\n    A **tutorial component**, offering detailed guidance on data simulation, prior and model specification, estimation, and interpretation using the software `R` and `Stan`.\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nOnce a *sufficiently trustworthy model* is found in goal 1,\n\n2. *Evaluate whether the approach yield reliable trait estimates and accurate statistical inferences*,\n\n    A **model validation component** benchmarked against the classical BTL analysis.\n:::\n\n<!-- ######################################### -->\n\n# 3. A tale of two analytical approaches {#sec-approaches}\n\n---\n\n## 3. A tale of two analytical approaches {style=\"font-size:80%;\"}\n\nCJ data can be analyzed under two analytical approaches:\n\n::: incremental \n1. *The classical BTL analysis* (hereafter, **CBTL analysis**) [@Pollitt_2012a; @Pollitt_2012b] ,\n    \n    which relies on a sequence of separate methods to estimate traits and draw inferences,\n\n2. *The Information-Theoretical model for CJ* (hereafter, **ITCJ analysis**) [@Rivera_et_al_2025],\n\n    which employs a single, systematic, and integrated approach for the same two purposes.\n:::\n\n<!-- ######################################### -->\n\n# 3.1 The CBTL analysis\n\n---\n\n## 3.1 The CBTL analysis {#sec-CBTL style=\"font-size:80%;\"}\n\nThis approach relies on a sequence of separate methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Apply the BTL model** to data, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli (mean and standard error)\n- To generate the model residuals\n:::\n:::\n\n2. **Generate summaries** or **apply (multilevel) regression** to the stimuli' mean trait estimates, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the trait of the stimuli at the individual level\n- To assess the variability and conduct inferences at the stimuli and individual levels\n- To calculate correlation with other methods (a way of \"concurrent validity\") or conduct inferences.\n:::\n:::\n\n3. **Generate summaries** or **apply (multilevel) regression** to the model residuals, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the remaining variability at the judges level or to investigate bias\n- To assess the remaining variability and conduct inferences about judges biases\n- To conduct inferences, including *misfit* identification, for stimuli, individuals, and judges\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n# 3.2 The ITCJ analysis\n\n--- \n\n## 3.2 The ITCJ analysis {#sec-ITCJ style=\"font-size:80%;\"}\n\nThis approach applies a single, systematic, and integrated approach to estimate traits and conduct inferences [@Rivera_et_al_2025]. In broad terms, the approach:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Begins with the general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] (see next slide),\n2. Adapts this structure to the assumed data-generating process of the CJ system under study,\n3. Develops one or more *bespoke* statistical models for analyzing the CJ system.\n4. Use the one or more statistical models to estimate traits and conduct inferences.\n:::\n:::\n\n::: {.fragment}\nWith these steps a researcher can:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Estimate the traits of the stimuli and individuals (full distribution)\n- Assess the variability and conduct inferences at the stimuli and individual levels\n- Estimate the biases of the judges and judgments (full distribution)\n- Assess the variability and conduct inferences at the judgments and judges levels\n- Conduct *oulier* identification for stimuli, individuals, judgments, and judges (akin to *misfit* identification)\n:::\n:::\n\n:::\n\n--- \n\n## 3.2 The ITCJ analysis {style=\"font-size:80%;\" #sec-3.2}\n\n<!-- commands for d-separation -->\n\\newcommand{\\dsep}{\\:\\bot\\:}\n\\newcommand{\\ndsep}{\\:\\not\\bot\\:}\n\\newcommand{\\cond}{\\:|\\:}\n\nThe general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] takes the following form:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj15 layout-ncol=2 }\n\n![](/figures/population_summary/CJ_TM_15.png){width=80%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK} \n\\end{aligned}\n$$\n\nComparative judgment model. *Left panel* illustrates the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nLeading to the general probabilistic and statistical model:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\ \n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, X_{IA}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J}, Z_{JK}, e_{JK} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{I} ) P( e_{IA} ) P( e_{J} ) P( e_{JK} ) \\\\ \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\nComparative judgment model, assuming different discriminal dispersions for traits. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model. \n:::\n\n:::\n\n\n::: {.fragment}\nWith the following constraints to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$ [@Depaoli_2021]: \n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16b}\n$$\n\\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix}; \\quad \n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & s_{A} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & s_{K} \n  \\end{bmatrix}; \\quad \n  \\sum_{g=1}^{3} s_{XI}[g]/3 = 1; \\quad\n  0< s_{A} < 1; \\quad \n  \\sum_{g=1}^{3} s_{ZJ}[g]/3 = 1; \\quad\n  0< s_{K} < 1\n$$ \n\nConstraints of the CJ model to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4. Methods \n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\nTo meet the tutorial and model validation goals, this study follows the Bayesian (research) workflow [@Depaoli_et_al_2017; @Neal_2020; @Gelman_et_al_2020; @Schad_et_al_2020; @Betancourt_2020; @McElreath_2024b; @McElreath_2024c]:\n\n::: {#fig-workflow}\n![](/figures/workflow.png){width=80%}\n\nBayesian (research) workflow.\n:::\n\n---\n\n## 4. Methods {#sec-methods style=\"font-size:80%;\"}\n\nSpecifically, the study follows these steps (overarching goals in parenthesis):\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n1. **Theory $\\rightarrow$ Estimand(s) $\\rightarrow$ Design** (*Tutorial and Model validation*)\n\n    Considering three steps: \n\n::: incremental \na. Define a CJ structure of interest and explicitly state its assumptions from relevant literature; \nb. Specify the estimand(s) of interest and provide formal definitions for each target parameter;\nc. Simulate a _synthetic conceptual population_ that reflects the defined structure and assumptions;\n:::\n\n2. **Design $\\rightarrow$ Sample** (*Tutorial and Model validation*)\n    \n    Generate _**two** synthetic_ random sample and comparison datasets from the conceptual population simulated in step $1$;\n\n3. **{Theory, Design, Estimand(s)} $\\rightarrow$ Estimator** (*Tutorial and Model validation*)\n\n    Specify models for analyzing the _**first** synthetic_ random comparison dataset using both the CBTL and the ITCJ analysis;\n    \n4. **Estimator $\\rightarrow$ Prior predictive** (*Tutorial*)\n\n    Perform prior predictive checks;\n:::\n:::\n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n5. **{Estimator, Sample} $\\rightarrow$ Estimate(s)** (*Tutorial and Model validation*)\n\n    Apply both the CBTL and ITCJ methods to the _**first** synthetic_ random comparison dataset;\n\n6. **Estimate(s) $\\rightarrow$ {Diagnostic, Post predictive}** (*Tutorial*)\n\n    Assess the quality of the models and estimate(s) in terms of stationarity, convergence, mixing, parameter recovery, in-sample fit, approximate out-of-sample fit, and in-sample predictive accuracy;\n    \n7. **{Diagnostic, Post predictive} $\\rightarrow$ Estimator** (*Tutorial*)\n\n    Incrementally refine the statistical model repeating steps 3–6 until a *sufficiently trustworthy model* is obtained according to the criteria outlined in step 6;\n\n8. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Effects $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate the *estimate(s)* of interest for the _**first** synthetic_ random comparison dataset using both the CBTL and ITCJ analysis, and interpret the results;\n    \n9. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Predictions $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate predictions for the _**second** synthetic comparison dataset_ using both the CBTL and ITCJ analysis, and compare their out-of-sample predictive accuracy.\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 4.1 From Theory to Design: Steps 1a-1c\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThe conceptual population simulation is based on the data characteristics and findings reported by Boonen et al. [@Boonen_et_al_2020]:\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the data characteristics, the study:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Includes multiple stimuli nested within multiple individuals,\n- Considers individuals with different characteristics (e.g., age, hearing status),\n- Assigns each judge to make only one comparison per stimulus pair,\n- Involves judges who differ in characteristics (e.g., experience level),\n- Selects stimuli, individuals, and judges using a (pseudo-)random sampling algorithm,\n- Involves multiple judges performing multiple comparisons, assigned through a random comparison algorithm.\n:::\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the study findings, the study report that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Individuals with different hearing statuses differ in both their average latent trait levels and their **variability**,\n- There is more unexplained variability between individuals than within individuals (i.e., at the stimulus level),\n- No evidence of systematic judge bias was found (although it was not tested but treated as a model assumption),\n- Judges' experience levels did not account for differences in mean latent traits between stimuli, but differences in their **variabilities** were not assessed.\n:::\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThus, adapting the general CJ structure proposed by Rivera et al.'s [@Rivera_et_al_2025] to the data characteristics reported by Boonen et al. [@Boonen_et_al_2020] leads to the following conceptual population data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj17 layout-ncol=2}\n\n![](/figures/data_summary/CJ_population_DAG.png){width=85%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA} \\}\n\\end{aligned}\n$$\n\nCJ data-generating process for the conceptual population. *Left panel* shows the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nMoreover, integrating the assumptions derived from Boonen et al. [@Boonen_et_al_2020] leads to the following statistical data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj18a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA} \\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{I} ) P( e_{IA} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nData-generating process for simulated CJ data. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n:::\n\n::: {.fragment}\nWith the following parameter assumptions:\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-cj18b layout-ncol=2 }\n\n$$\n\\begin{split}\nX_{I} &= \\{ X_{Ic}, X_{Id}[g=1], X_{Id}[g=2], X_{Id}[g=3] \\} \\\\\nZ_{J} &= \\{ Z_{Jd}[g=1], Z_{Jd}[g=2], Z_{Jd}[g=3] \\} \\\\\n\\beta_{XI} & = \\{ \\beta_{XIc}, \\beta_{XId[g=1]}, \\beta_{XId[g=2]}, \\beta_{XId[g=3]} \\} = \\{ 0.1, 1, 0, -1\\} \\\\\n\\beta_{ZJ} &= \\{ \\beta_{ZJd[g=1]}, \\beta_{ZJd[g=2]}, \\beta_{ZJd[g=3]} \\} = \\{ 0, 0, 0\\}\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{XI[g]} &= \\{ s_{XId[g=1]}, s_{XId[g=2]}, s_{XId[g=3]} \\} = \\{ 1.5, 0.75, 0.75\\} \\\\\ns_{ZJ} &= \\{ s_{ZJd[g=1]}, s_{ZJd[g=2]}, s_{ZJd[g=3]} \\} = \\{ 0.5, 1, 1.5\\} \\\\\ns_{A} &= 0.2 \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 \\\\\n    0 & s_{A} & 0 \\\\\n    0 & 0 & s_{ZJ} \n\\end{bmatrix}\n\\end{split}\n$$\n\nSimulating parameter assumptions.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nIn layman terms:\n\n::: incremental \n::: {style=\"font-size:60%;\"}\n- No stimuli characteristics $(X_{IA})$ are assumed to affect the comparisons;\n- Stimuli latent trait residual variability is smaller than average individual latent trait residual variability $(s_{A} = 0.2 < 1)$;\n- Individual characteristics $(X_{I})$ include a continuous variable $(X_{Ic})$ for the age of children, and a categorical variable with three levels representing hearing status groups: normal-hearing (NH, $X_{Id}[g=1]$), hearing-impaired with hearing aids (HI-HA, $X_{Id}[g=2]$), and hearing-impaired with cochlear implants (HI-CI, $X_{Id}[g=3]$) children;\n- There is a \"small\" [@Cohen_1988; @Sawilowsky_2009] but increasing effect of age $(\\beta_{XIc})$ on the mean latent trait of individuals;\n- There are \"very large\" [@Cohen_1988; @Sawilowsky_2009] differences in the mean latent trait across hearing status groups $(\\beta_{XId[g=1]} > \\beta_{XId[g=2]} > \\beta_{XId[g=3]})$;\n- Individual latent trait residual variability differs by groups, i.e., $s_{XId[g=1]} > s_{XId[g=2]} = s_{XId[g=3]}$, with $\\sum_{g=1}^{3} s_{XId[g]}/3 = 1$;\n- Judges make only one comparison; thus, there are no judgment-level characteristics $(Z_{JK})$, judgement-level effects $(\\beta_{ZJK})$, or residual judgment variability $(p_{JK})$;\n- Judges characteristics $(Z_{J})$ include a categorical variable with three levels representing judge groups: audiologist (AU, $Z_{Jd}[g=1]$), primary teachers (PT, $Z_{Jd}[g=2]$), and inexperienced listeners (IL, $Z_{Jd}[g=3]$);\n- Judges' mean latent biases across judge groups are equal to zero $(\\beta_{ZJd[g=1]}=\\beta_{ZJd[g=2]}=\\beta_{ZJd[g=3]}=0)$;\n- However, judges exhibit more or less bias depending on their experience, i.e., $(s_{ZJd[g=1]}=0.5) < (s_{ZJd[g=2]} = 1) < (s_{ZJd[g=3]} = 1.5)$, with $\\sum_{g=1}^{3} s_{ZJ[g]}/3 = 1$;\n- Residual latent errors $(\\boldsymbol{e})$ are centered around zero with zero correlation $(\\boldsymbol{\\mu}, \\boldsymbol{Q})$.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {#sec-pop_sim style=\"font-size:80%;\"}\n\nFrom the simulation parameters we can define the **_estimands_** of interest:\n\n::: incremental \n::: {style=\"font-size:65%;\"}\n- The conditioned expected change in the individuals' mean latent trait for one additional year of age $(\\beta_{XIc})$;\n- The conditioned expected differences in mean latent traits between NH and HI-HA children $(\\beta_{XId[g=1]} - \\beta_{XId[g=2]})$, NH and HI-CI children $(\\beta_{XId[g=1]} - \\beta_{XId[g=3]})$, and HI-HA versus HI-CI children $(\\beta_{XId[g=2]} - \\beta_{XId[g=3]})$;\n- The conditioned expected differences in mean latent bias between AU and PT judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]})$, AU and IL judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]})$, and PT and IL judges $(\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]})$;\n- The latent trait residual variability of NH, HI-HA, and HI-CI children, i.e., $s_{XId[g=1]}$, $s_{XId[g=2]}$, and $s_{XId[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent trait between NH and HI-HA children $(s_{XId[g=1]} - s_{XId[g=2]})$, NH and HI-CI children $(s_{XId[g=1]} - s_{XId[g=3]})$, and HI-HA versus HI-CI children $(s_{XId[g=2]} - s_{XId[g=3]})$;\n- The latent bias residual variability of AU, PT, and IL judges, i.e., $s_{ZJd[g=1]}$, $s_{ZJd[g=2]}$, and $s_{ZJd[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent bias between AU and PT judges $(s_{ZJd[g=1]} - s_{ZJd[g=2]})$, AU and IL judges $(s_{ZJd[g=1]} - s_{ZJd[g=3]})$, and PT and IL judges $(s_{ZJd[g=2]} - s_{ZJd[g=3]})$;\n- The residual variability of the stimuli latent trait $(s_{A})$;\n- Latent traits $T_{IA}$, $T_{I}$, and $B_{J}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4.2 From Design to Sample: Step 2\n\n---\n\n## 4.2 From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nDiffering only by replication seed, the study generates _**two** synthetic_ random sample and comparison datasets from the conceptual population in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms illustrated in @fig-cj17 sample size calculations were conducted (see @sec-AppA), and the following design was adopted:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- A sample of $54$ individuals, divided into three hearing status groups: $40$ NH $(X_{Id}[g=1])$, $7$ HI-HA $(X_{Id}[g=2])$, and $7$ HI-CI $(X_{Id}[g=3])$ children;\n- A sample of $10$ stimuli per individual;\n- A sample of $60$ judges, divided into three groups: $10$ AU $(Z_{Jd}[g=1])$, $10$ PT $(Z_{Jd}[g=2])$, and $40$ IL $(Z_{Jd}[g=3])$;\n- Judges conduct only one-comparison of the same stimulus pair (i.e., design is NOT a *repeated measures design* [@Lawson_2015, chap. 9.5])\n- Each stimulus is compared $20$ times in total against other stimuli, across all judges.\n:::\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nThe study applies two data analysis approaches for the simulated CJ data (as described in @sec-approaches):\n\n::: incremental \n1. *The CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b] ,\n2. *The ITCJ analysis* [@Rivera_et_al_2025],\n:::\n\n::: {.fragment}\nBoth approaches were conducted using `R` version 4.2.2 [@R_2015], with:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Additional `R` packages for data manipulation and visualization: `tidyverse` [@Wickham_et_al_2019], `igraph` [@Csardi_et_al_2006; @Csardi_et_al_2025], and `RColorBrewer` [@Neuwirth_2022];\n- Specific user-defined functions (`UDFs`) to facilitate data manipulation, visualization, model summarization, diagnostics, and prediction from the approaches (all are provided in the main document).\n:::\n:::\n\n:::\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Fits a BTL model** using the `BTm()` function from the `BradleyTerry2` package [@Turner_et_al_2012a; @Turner_et_al_2012b],\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli $(T_{IA})$\n- To generate the model residuals and conduct *misfit* analysis.\n:::\n:::\n\n2. **Fits a (multilevel) regression** to model residuals using the `brms` package [@Burkner_2017; @Burkner_2018],\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To test hypothesis of differences in mean residuals between groups of judges, i.e., $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]}$, $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]}$, and $\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]}$;\n- To assess the variability between- and within-judges, where the latter has **no direct equivalent parameter**, while former corresponds to $s_{ZJ}$$^{*}$.\n- To aggregate model residuals into judges biases $(B_{J})$ \n:::\n:::\n\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for judges, i.e., $s_{ZJ}$, versus multiple variability parameters defined by the experience of the judges, i.e., $s_{ZJd}$.\n:::\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **Fits a (multilevel) regression** to the stimuli' mean trait estimates, \n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the effect of age on the mean latent trait, i.e, $\\beta_{XIc}$\n- To test hypothesis of differences in mean latent traits between groups of children, i.e., $\\beta_{XId[g=1]} - \\beta_{XId[g=2]}$, $\\beta_{XId[g=1]} - \\beta_{XId[g=3]}$, and  $\\beta_{XId[g=2]} - \\beta_{XId[g=3]}$\n- To assess the variability within and between children, i.e., $s_{A}$ and $s_{XI}$$^{*}$, respectively\n- To aggregate stimuli traits into individual level $(T_{I})$ \n:::\n:::\n\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nNotably, **for each** `brms` model, **four** Markov chains of $4000$ iterations were run, each with distinct starting values. The first $2000$ iterations served as warm-up, and the remaining $2000$ were used as posterior samples (for a total of $8000$ posterior samples).\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for individuals, i.e., $s_{XI}$, versus multiple variability parameters defined by the individuals' groups, i.e., $s_{XId}$.\n:::\n\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nIn contrast, for the *ITCJ analysis* [@Rivera_et_al_2025], the study uses:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- `Stan` version 2.26.1 [@Stan_2020] and the interface package `cmdstanr` [@Gabry_et_al_2025] to fit a series of increasingly complex Bayesian ITCJ models,\n- Additional `R` packages for model summaries, predictions, and diagnostics: `loo` [@Vehtari_et_al_2024b], `posterior` [@Burkner_et_al_2024], and `bayesplot` [@Gabry_et_al_2019; @Gabry_et_al_2025].\n\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nNotably, **for each** Bayesian model, **four** Markov chains of $4000$ iterations were run, each with distinct starting values. The first $2000$ iterations served as warm-up, and the remaining $2000$ were used as posterior samples (for a total of $8000$ posterior samples).\n:::\n\n<!-- ######################################### -->\n\n# 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **_Stationarity, convergence, and mixing_** (for Bayesian models only), using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Graphical analyses, including trace plots, rank-normalized trace (trank) plots, autocorrelation function (ACF) plots, and comparison plots of prior to posterior distributions,\n- Diagnostic statistics, including the potential scale reduction factor statistics $(\\hat{R})$ with a cut-off value of $1.05$ [@Vehtari_et_al_2021a] and effective sample size statistics $(n_{\\text{eff}})$ [@Gelman_et_al_2014].\n:::\n:::\n\n2. **_Parameter recovery_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The graphical comparisons of \"true\" parameters values versus posterior estimates,\n- The parameter posterior Root Mean Squared Error $(\\text{RMSE})$, defined as follows:\n:::\n:::\n    \n:::\n:::\n\n::: {.fragment}\n$$\n\\text{RMSE}( \\boldsymbol{\\hat{\\theta}}, \\theta) = \\sqrt{ \\frac{1}{S} \\sum_{s=1}^{S} ( \\hat{\\theta}_{s} - \\theta )^2 }\n$$\n:::\n\n::: {.fragment style=\"font-size:64%;\"}\nwhere $\\boldsymbol{\\hat{\\theta}}$ is the vector of posterior samples associated with the \"true\" parameter $\\theta$, and $\\hat{\\theta}_{s}$ is the $s$-th sample out of a total of $S$ posterior draws.\n:::\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **_In-sample fit_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The deviance information criterion $(\\text{DIC})$ [@Spiegelhalter_et_al_2002]\n:::\n:::\n\n4. **_Approximate out-of-sample fit_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The widely applicable information criterion $(\\text{WAIC})$ [@Watanabe_2013] and its standard error $(\\text{SE}_{W})$, along with the differences in $\\text{WAIC}$ between models $(\\text{dWAIC} \\pm 1 \\cdot \\text{dSE}_{W})$\n- The Pareto Smoothing Importance Sampling criterion $(\\text{PSIS})$ [@Vehtari_et_al_2017; @Vehtari_et_al_2024a] and its standard error $(\\text{SE}_{P})$, along with the differences in $\\text{PSIS}$ between models $(\\text{dPSIS} \\pm 1 \\cdot \\text{dSE}_{P})$\n:::\n:::\n\n5. **_In-sample predictive accuracy_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Confusion matrix comparing expected posterior predictions $E( \\boldsymbol{\\hat{y}})$ with observed outcomes $\\boldsymbol{y}$ from the **_first_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n- (Multiple) confusion matrix comparing the posterior predictions $\\boldsymbol{\\hat{y}}_{s}$ with observed outcomes  $\\boldsymbol{y}$ from the **_first_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n:::\n:::\n\n:::\n:::\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n6. **_Out-of-sample predictive accuracy_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Confusion matrix comparing expected posterior predictions $E( \\boldsymbol{\\hat{y}})$ with observed outcomes $\\boldsymbol{y}$ from the **_second_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n- (Multiple) confusion matrix comparing the posterior predictions $\\boldsymbol{\\hat{y}}_{s}$ with observed outcomes  $\\boldsymbol{y}$ from the **_second_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n:::\n:::\n\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 5. Results\n\n---\n\n## 5. Results {style=\"font-size:80%;\"}\n\nIn this section, the study will:\n\n::: incremental \n1. Describe the _**first** synthetic_ random comparison dataset;\n2. Progress through the steps $3-7$ of the Bayesian (research) workflow, described in @sec-methods, using:\n\n::: incremental \n- The CBTL analysis, and \n- The ITCJ analysis\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 5.1 The first synthetic comparison dataset\n\n# 5.1.1 Data description\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of design, the dataset reveals that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most stimuli were compared $20$ times; only two stimuli (IDs $2$ and $3$) from individual $58$ were compared slightly fewer times due to random variation.\n- The stimuli comparison network indicates a random *balanced design* [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_comparisons layout-ncol=2}\n![](/figures/data_summary/stimuli_comparisons_bottom.png){width=60%}\n\n![](/figures/data_summary/stimuli_network.png){width=60%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals $(Is)$ and stimuli $(As)$. *Right panel* shows the stimuli comparison network.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nIn a similar manner, the data indicates:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most individuals were compared $200$ times ($20$ comparisons × $10$ stimuli each); only one individual (ID $58$) was compared slightly fewer times due to random design variation;\n- The connected component analysis [@Betancourt_2024] and individual comparison network indicates a fully connected network and a *balanced design* for individuals [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_comparisons layout-ncol=2}\n\n![](/figures/data_summary/individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/individual_network.png){width=55%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals. *Right panel* shows the individual comparison network.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nOn the other hand, the dataset shows:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges compare individuals with frequencies ranging from $0$ to $13$ comparisons;\n- Most judges completed $262$ comparisons, while a few completed $264$ due to random design variation.\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_comparisons layout-ncol=2}\n![](/figures/data_summary/judges2individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/judges_comparisons.png){width=90%}\n\nComparison design. *Left panel* shows the judges $(Js)$ versus the first $10$ individuals $(Is)$. *Right panel* shows the total number of judges' comparisons.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nMoreover,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges to individual comparison network indicates a fully connected network\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_individuals_comparisons}\n![](/figures/data_summary/judges_individuals_network.png){width=100%}\n\nBipartite graph of judges to individual comparison network.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of the comparison outcomes, we see some stimuli with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/stimuli_wins.png){width=70%}\n\nStimuli win rates.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nAggregated by individuals, we see some individuals with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins.png){width=70%}\n\nIndividual win rates.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nDivided by hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- It is harder to see average differences between the groups,\n- However, we can easily notice the different variability between them\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins_groups.png){width=100%}\n\nIndividual win rates per group. *Left panel* describe NH children. *Middle panel* describe HI-HA children. *Right panel* illustrate HI-CI children.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nHowever, no apparent relationship transpire between individual wins and age:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc.png){width=70%}\n\nIndividual win rates versus age.\n:::\n:::\n\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nConsidering the interaction of age and hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- We notice a slightly decreasing trend in HI-HA and HI-CI children, indicating that in those groups, older children are less likely to win in a comparison, but the results are not *unambiguous* (*Simpson's, Berkson's or another paradox*?).\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc_groups.png){width=100%}\n\nIndividual win rates.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5.1.2 Data modeling\n\n# 5.1.2.1 Data modeling: The CBTL analysis\n\n---\n\n## 5.1.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\n\n\n\n<!-- ######################################### -->\n\n# 5.1.2.2 Data modeling: The ITCJ analysis \n\n---\n\n## 5.1.2.2 Data modeling: The ITCJ analysis {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2 The second synthetic comparison dataset\n\n# 5.2.1 Data description\n\n---\n\n## 5.2.1 Data description {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2.2 From Estimands and Estimator to Effects and Predictions: Steps 8 and 9\n\n---\n\n## 5.2.2 From Estimands and Estimator to Effects and Predictions: Steps 8 and 9 {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2.2.1 The classical BTL analysis\n\n---\n\n## 5.2.2.1 The classical BTL analysis {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2.2.2 The Information-Theoretical model for CJ\n\n---\n\n## 5.2.2.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n\n# 6. Discussion\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n# 6.1 Future research directions\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 6.2 Study limitations\n\n---\n\n## 6.2 Study limitations {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n# 7. Conclusion\n\n---\n\n## 7. Conclusion {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n---\n\n# Appendix A - From Design to Sample: Step 2 {#sec-AppA}\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nDiffering only by replication seed, the study generates _**two** synthetic_ random sample and comparison datasets from the conceptual population in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms shown in @fig-cj17, sample size calculations were conducted assuming:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- That \"reaching\" one children from the HI-HA or HI-CI groups costs ten times $(10x)$ more that \"reaching\" one NH child.\n- Three criteria for individual sample size selection: (1) a minimum power to detect $\\beta_{XIc}$ of $80\\%$ $(1-\\beta)$, (2) a minimum power to detect differences in $bXId$ of $80\\%$ $(1-\\beta)$, and (3) a maximum efficiency possible, i.e., less and more balanced sample sizes are preferred.\n- That \"hiring\" one AU judge cost five times $(5x)$ as much as \"hiring\" an IL judge, while \"hiring\" one PT judge cost three times $(3x)$ as much as an IL judge.\n- Three criteria for judge sample size selection: (1) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject $\\beta_{ZJc} = 0$, (2) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject differences in $\\beta_{ZJd}$ equal to zero, and (3) maximum efficiency, i.e., less and more balanced sample sizes are preferred.\n:::\n:::\n\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_ss}\n![](/figures/sim_individual_sample_size.png){width=100%}\n\nIndividual's sample size calculation, considering requirements for Power, Efficiency and Cost.\n:::\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_ss}\n![](/figures/sim_judges_sample_size.png){width=100%}\n\nJudges's sample size calculation, considering requirements for Confidence, Efficiency and Cost.\n:::\n:::\n\n\n\n\n# Licence {style=\"font-size:80%;\"}\n\n---\n\n## Licence {style=\"font-size:80%;\"}\n\nAll the code that is original to this study and not attributed to any other authors is copyrighted by *Jose Manuel Rivera Espejo* and released under the New BSD (3-Clause) License: [https://opensource.org/license/BSD-3-Clause](https://opensource.org/license/BSD-3-Clause)\n\n<!-- ######################################### -->\n\n---\n\n# References {style=\"font-size:80%;\"}\n\n:::{#refs style=\"font-size:80%;\"}\n\n:::\n","srcMarkdownNoYaml":"\n\n# 1. Introduction {style=\"font-size:80%;\"}\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nThe Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] offers a **simple method** for measuring traits and conducting statistical inference from comparative judgment (CJ) data [@Andrich_1978; @Pollitt_2012b]. \n\n[Its simplicity stems from two features:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. A reliance on an extensive set of simplifying assumptions about the traits, judges, and stimuli involved in CJ assessments [@Thurstone_1927b; @Bramley_2008],\n2. The use of ad hoc procedures to handle inferences, including hypothesis testing [@Pollitt_2012b].\n:::\n:::\n\n::: {.fragment}\nHowever, recent studies question whether:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- These assumptions hold in modern CJ applications? [@Bramley_2008; @Kelly_et_al_2022; @Rivera_et_al_2025]\n- The ad hoc procedures effectively fulfill their intended analytical purpose? [@Kelly_et_al_2022; @Rivera_et_al_2025]\n:::\n:::\n:::\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nTo address these concerns, Rivera et al. [@Rivera_et_al_2025] proposed *The Information-Theoretical model for CJ*. The approach,\n\n[1. Extends the general form of Thurstone's law of comparative judgment [@Thurstone_1927a; @Thurstone_1927b], combining Thurstone's core theoretical principles with key CJ assessment design features.]{.fragment style=\"font-size:80%;\"}\n\n[2. Enables the development of models tailored to the assumed data-generating process of the CJ system under study, thus:]{.fragment style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Eliminating the need to rely on the simplifying assumptions of the BTL model,\n- Removing the dependence on ad hoc hypothesis-testing procedures.\n:::\n:::\n\n[Nevertheless, although approach has the potential to yield reliable trait estimates and accurate statistical inferences, **this promise still needs to be empirically tested**.]{.fragment style=\"font-size:80%;\"} \n\n<!-- ######################################### -->\n\n# 2. Research goals\n\n---\n\n## 2. Research goals {style=\"font-size:80%;\"}\n\nThus, this study has **two overarching goals**:\n\n::: {.fragment style=\"font-size:80%;\"}\n1. *To show how apply the Information-Theoretical model for CJ to a simulated dataset*,\n\n    A **tutorial component**, offering detailed guidance on data simulation, prior and model specification, estimation, and interpretation using the software `R` and `Stan`.\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nOnce a *sufficiently trustworthy model* is found in goal 1,\n\n2. *Evaluate whether the approach yield reliable trait estimates and accurate statistical inferences*,\n\n    A **model validation component** benchmarked against the classical BTL analysis.\n:::\n\n<!-- ######################################### -->\n\n# 3. A tale of two analytical approaches {#sec-approaches}\n\n---\n\n## 3. A tale of two analytical approaches {style=\"font-size:80%;\"}\n\nCJ data can be analyzed under two analytical approaches:\n\n::: incremental \n1. *The classical BTL analysis* (hereafter, **CBTL analysis**) [@Pollitt_2012a; @Pollitt_2012b] ,\n    \n    which relies on a sequence of separate methods to estimate traits and draw inferences,\n\n2. *The Information-Theoretical model for CJ* (hereafter, **ITCJ analysis**) [@Rivera_et_al_2025],\n\n    which employs a single, systematic, and integrated approach for the same two purposes.\n:::\n\n<!-- ######################################### -->\n\n# 3.1 The CBTL analysis\n\n---\n\n## 3.1 The CBTL analysis {#sec-CBTL style=\"font-size:80%;\"}\n\nThis approach relies on a sequence of separate methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Apply the BTL model** to data, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli (mean and standard error)\n- To generate the model residuals\n:::\n:::\n\n2. **Generate summaries** or **apply (multilevel) regression** to the stimuli' mean trait estimates, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the trait of the stimuli at the individual level\n- To assess the variability and conduct inferences at the stimuli and individual levels\n- To calculate correlation with other methods (a way of \"concurrent validity\") or conduct inferences.\n:::\n:::\n\n3. **Generate summaries** or **apply (multilevel) regression** to the model residuals, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the remaining variability at the judges level or to investigate bias\n- To assess the remaining variability and conduct inferences about judges biases\n- To conduct inferences, including *misfit* identification, for stimuli, individuals, and judges\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n# 3.2 The ITCJ analysis\n\n--- \n\n## 3.2 The ITCJ analysis {#sec-ITCJ style=\"font-size:80%;\"}\n\nThis approach applies a single, systematic, and integrated approach to estimate traits and conduct inferences [@Rivera_et_al_2025]. In broad terms, the approach:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Begins with the general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] (see next slide),\n2. Adapts this structure to the assumed data-generating process of the CJ system under study,\n3. Develops one or more *bespoke* statistical models for analyzing the CJ system.\n4. Use the one or more statistical models to estimate traits and conduct inferences.\n:::\n:::\n\n::: {.fragment}\nWith these steps a researcher can:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Estimate the traits of the stimuli and individuals (full distribution)\n- Assess the variability and conduct inferences at the stimuli and individual levels\n- Estimate the biases of the judges and judgments (full distribution)\n- Assess the variability and conduct inferences at the judgments and judges levels\n- Conduct *oulier* identification for stimuli, individuals, judgments, and judges (akin to *misfit* identification)\n:::\n:::\n\n:::\n\n--- \n\n## 3.2 The ITCJ analysis {style=\"font-size:80%;\" #sec-3.2}\n\n<!-- commands for d-separation -->\n\\newcommand{\\dsep}{\\:\\bot\\:}\n\\newcommand{\\ndsep}{\\:\\not\\bot\\:}\n\\newcommand{\\cond}{\\:|\\:}\n\nThe general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] takes the following form:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj15 layout-ncol=2 }\n\n![](/figures/population_summary/CJ_TM_15.png){width=80%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK} \n\\end{aligned}\n$$\n\nComparative judgment model. *Left panel* illustrates the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nLeading to the general probabilistic and statistical model:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\ \n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, X_{IA}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J}, Z_{JK}, e_{JK} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{I} ) P( e_{IA} ) P( e_{J} ) P( e_{JK} ) \\\\ \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\nComparative judgment model, assuming different discriminal dispersions for traits. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model. \n:::\n\n:::\n\n\n::: {.fragment}\nWith the following constraints to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$ [@Depaoli_2021]: \n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16b}\n$$\n\\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix}; \\quad \n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & s_{A} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & s_{K} \n  \\end{bmatrix}; \\quad \n  \\sum_{g=1}^{3} s_{XI}[g]/3 = 1; \\quad\n  0< s_{A} < 1; \\quad \n  \\sum_{g=1}^{3} s_{ZJ}[g]/3 = 1; \\quad\n  0< s_{K} < 1\n$$ \n\nConstraints of the CJ model to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4. Methods \n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\nTo meet the tutorial and model validation goals, this study follows the Bayesian (research) workflow [@Depaoli_et_al_2017; @Neal_2020; @Gelman_et_al_2020; @Schad_et_al_2020; @Betancourt_2020; @McElreath_2024b; @McElreath_2024c]:\n\n::: {#fig-workflow}\n![](/figures/workflow.png){width=80%}\n\nBayesian (research) workflow.\n:::\n\n---\n\n## 4. Methods {#sec-methods style=\"font-size:80%;\"}\n\nSpecifically, the study follows these steps (overarching goals in parenthesis):\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n1. **Theory $\\rightarrow$ Estimand(s) $\\rightarrow$ Design** (*Tutorial and Model validation*)\n\n    Considering three steps: \n\n::: incremental \na. Define a CJ structure of interest and explicitly state its assumptions from relevant literature; \nb. Specify the estimand(s) of interest and provide formal definitions for each target parameter;\nc. Simulate a _synthetic conceptual population_ that reflects the defined structure and assumptions;\n:::\n\n2. **Design $\\rightarrow$ Sample** (*Tutorial and Model validation*)\n    \n    Generate _**two** synthetic_ random sample and comparison datasets from the conceptual population simulated in step $1$;\n\n3. **{Theory, Design, Estimand(s)} $\\rightarrow$ Estimator** (*Tutorial and Model validation*)\n\n    Specify models for analyzing the _**first** synthetic_ random comparison dataset using both the CBTL and the ITCJ analysis;\n    \n4. **Estimator $\\rightarrow$ Prior predictive** (*Tutorial*)\n\n    Perform prior predictive checks;\n:::\n:::\n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n5. **{Estimator, Sample} $\\rightarrow$ Estimate(s)** (*Tutorial and Model validation*)\n\n    Apply both the CBTL and ITCJ methods to the _**first** synthetic_ random comparison dataset;\n\n6. **Estimate(s) $\\rightarrow$ {Diagnostic, Post predictive}** (*Tutorial*)\n\n    Assess the quality of the models and estimate(s) in terms of stationarity, convergence, mixing, parameter recovery, in-sample fit, approximate out-of-sample fit, and in-sample predictive accuracy;\n    \n7. **{Diagnostic, Post predictive} $\\rightarrow$ Estimator** (*Tutorial*)\n\n    Incrementally refine the statistical model repeating steps 3–6 until a *sufficiently trustworthy model* is obtained according to the criteria outlined in step 6;\n\n8. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Effects $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate the *estimate(s)* of interest for the _**first** synthetic_ random comparison dataset using both the CBTL and ITCJ analysis, and interpret the results;\n    \n9. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Predictions $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate predictions for the _**second** synthetic comparison dataset_ using both the CBTL and ITCJ analysis, and compare their out-of-sample predictive accuracy.\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 4.1 From Theory to Design: Steps 1a-1c\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThe conceptual population simulation is based on the data characteristics and findings reported by Boonen et al. [@Boonen_et_al_2020]:\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the data characteristics, the study:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Includes multiple stimuli nested within multiple individuals,\n- Considers individuals with different characteristics (e.g., age, hearing status),\n- Assigns each judge to make only one comparison per stimulus pair,\n- Involves judges who differ in characteristics (e.g., experience level),\n- Selects stimuli, individuals, and judges using a (pseudo-)random sampling algorithm,\n- Involves multiple judges performing multiple comparisons, assigned through a random comparison algorithm.\n:::\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the study findings, the study report that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Individuals with different hearing statuses differ in both their average latent trait levels and their **variability**,\n- There is more unexplained variability between individuals than within individuals (i.e., at the stimulus level),\n- No evidence of systematic judge bias was found (although it was not tested but treated as a model assumption),\n- Judges' experience levels did not account for differences in mean latent traits between stimuli, but differences in their **variabilities** were not assessed.\n:::\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThus, adapting the general CJ structure proposed by Rivera et al.'s [@Rivera_et_al_2025] to the data characteristics reported by Boonen et al. [@Boonen_et_al_2020] leads to the following conceptual population data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj17 layout-ncol=2}\n\n![](/figures/data_summary/CJ_population_DAG.png){width=85%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA} \\}\n\\end{aligned}\n$$\n\nCJ data-generating process for the conceptual population. *Left panel* shows the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nMoreover, integrating the assumptions derived from Boonen et al. [@Boonen_et_al_2020] leads to the following statistical data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj18a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA} \\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{I} ) P( e_{IA} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nData-generating process for simulated CJ data. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n:::\n\n::: {.fragment}\nWith the following parameter assumptions:\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-cj18b layout-ncol=2 }\n\n$$\n\\begin{split}\nX_{I} &= \\{ X_{Ic}, X_{Id}[g=1], X_{Id}[g=2], X_{Id}[g=3] \\} \\\\\nZ_{J} &= \\{ Z_{Jd}[g=1], Z_{Jd}[g=2], Z_{Jd}[g=3] \\} \\\\\n\\beta_{XI} & = \\{ \\beta_{XIc}, \\beta_{XId[g=1]}, \\beta_{XId[g=2]}, \\beta_{XId[g=3]} \\} = \\{ 0.1, 1, 0, -1\\} \\\\\n\\beta_{ZJ} &= \\{ \\beta_{ZJd[g=1]}, \\beta_{ZJd[g=2]}, \\beta_{ZJd[g=3]} \\} = \\{ 0, 0, 0\\}\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{XI[g]} &= \\{ s_{XId[g=1]}, s_{XId[g=2]}, s_{XId[g=3]} \\} = \\{ 1.5, 0.75, 0.75\\} \\\\\ns_{ZJ} &= \\{ s_{ZJd[g=1]}, s_{ZJd[g=2]}, s_{ZJd[g=3]} \\} = \\{ 0.5, 1, 1.5\\} \\\\\ns_{A} &= 0.2 \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 \\\\\n    0 & s_{A} & 0 \\\\\n    0 & 0 & s_{ZJ} \n\\end{bmatrix}\n\\end{split}\n$$\n\nSimulating parameter assumptions.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nIn layman terms:\n\n::: incremental \n::: {style=\"font-size:60%;\"}\n- No stimuli characteristics $(X_{IA})$ are assumed to affect the comparisons;\n- Stimuli latent trait residual variability is smaller than average individual latent trait residual variability $(s_{A} = 0.2 < 1)$;\n- Individual characteristics $(X_{I})$ include a continuous variable $(X_{Ic})$ for the age of children, and a categorical variable with three levels representing hearing status groups: normal-hearing (NH, $X_{Id}[g=1]$), hearing-impaired with hearing aids (HI-HA, $X_{Id}[g=2]$), and hearing-impaired with cochlear implants (HI-CI, $X_{Id}[g=3]$) children;\n- There is a \"small\" [@Cohen_1988; @Sawilowsky_2009] but increasing effect of age $(\\beta_{XIc})$ on the mean latent trait of individuals;\n- There are \"very large\" [@Cohen_1988; @Sawilowsky_2009] differences in the mean latent trait across hearing status groups $(\\beta_{XId[g=1]} > \\beta_{XId[g=2]} > \\beta_{XId[g=3]})$;\n- Individual latent trait residual variability differs by groups, i.e., $s_{XId[g=1]} > s_{XId[g=2]} = s_{XId[g=3]}$, with $\\sum_{g=1}^{3} s_{XId[g]}/3 = 1$;\n- Judges make only one comparison; thus, there are no judgment-level characteristics $(Z_{JK})$, judgement-level effects $(\\beta_{ZJK})$, or residual judgment variability $(p_{JK})$;\n- Judges characteristics $(Z_{J})$ include a categorical variable with three levels representing judge groups: audiologist (AU, $Z_{Jd}[g=1]$), primary teachers (PT, $Z_{Jd}[g=2]$), and inexperienced listeners (IL, $Z_{Jd}[g=3]$);\n- Judges' mean latent biases across judge groups are equal to zero $(\\beta_{ZJd[g=1]}=\\beta_{ZJd[g=2]}=\\beta_{ZJd[g=3]}=0)$;\n- However, judges exhibit more or less bias depending on their experience, i.e., $(s_{ZJd[g=1]}=0.5) < (s_{ZJd[g=2]} = 1) < (s_{ZJd[g=3]} = 1.5)$, with $\\sum_{g=1}^{3} s_{ZJ[g]}/3 = 1$;\n- Residual latent errors $(\\boldsymbol{e})$ are centered around zero with zero correlation $(\\boldsymbol{\\mu}, \\boldsymbol{Q})$.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {#sec-pop_sim style=\"font-size:80%;\"}\n\nFrom the simulation parameters we can define the **_estimands_** of interest:\n\n::: incremental \n::: {style=\"font-size:65%;\"}\n- The conditioned expected change in the individuals' mean latent trait for one additional year of age $(\\beta_{XIc})$;\n- The conditioned expected differences in mean latent traits between NH and HI-HA children $(\\beta_{XId[g=1]} - \\beta_{XId[g=2]})$, NH and HI-CI children $(\\beta_{XId[g=1]} - \\beta_{XId[g=3]})$, and HI-HA versus HI-CI children $(\\beta_{XId[g=2]} - \\beta_{XId[g=3]})$;\n- The conditioned expected differences in mean latent bias between AU and PT judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]})$, AU and IL judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]})$, and PT and IL judges $(\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]})$;\n- The latent trait residual variability of NH, HI-HA, and HI-CI children, i.e., $s_{XId[g=1]}$, $s_{XId[g=2]}$, and $s_{XId[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent trait between NH and HI-HA children $(s_{XId[g=1]} - s_{XId[g=2]})$, NH and HI-CI children $(s_{XId[g=1]} - s_{XId[g=3]})$, and HI-HA versus HI-CI children $(s_{XId[g=2]} - s_{XId[g=3]})$;\n- The latent bias residual variability of AU, PT, and IL judges, i.e., $s_{ZJd[g=1]}$, $s_{ZJd[g=2]}$, and $s_{ZJd[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent bias between AU and PT judges $(s_{ZJd[g=1]} - s_{ZJd[g=2]})$, AU and IL judges $(s_{ZJd[g=1]} - s_{ZJd[g=3]})$, and PT and IL judges $(s_{ZJd[g=2]} - s_{ZJd[g=3]})$;\n- The residual variability of the stimuli latent trait $(s_{A})$;\n- Latent traits $T_{IA}$, $T_{I}$, and $B_{J}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4.2 From Design to Sample: Step 2\n\n---\n\n## 4.2 From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nDiffering only by replication seed, the study generates _**two** synthetic_ random sample and comparison datasets from the conceptual population in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms illustrated in @fig-cj17 sample size calculations were conducted (see @sec-AppA), and the following design was adopted:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- A sample of $54$ individuals, divided into three hearing status groups: $40$ NH $(X_{Id}[g=1])$, $7$ HI-HA $(X_{Id}[g=2])$, and $7$ HI-CI $(X_{Id}[g=3])$ children;\n- A sample of $10$ stimuli per individual;\n- A sample of $60$ judges, divided into three groups: $10$ AU $(Z_{Jd}[g=1])$, $10$ PT $(Z_{Jd}[g=2])$, and $40$ IL $(Z_{Jd}[g=3])$;\n- Judges conduct only one-comparison of the same stimulus pair (i.e., design is NOT a *repeated measures design* [@Lawson_2015, chap. 9.5])\n- Each stimulus is compared $20$ times in total against other stimuli, across all judges.\n:::\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nThe study applies two data analysis approaches for the simulated CJ data (as described in @sec-approaches):\n\n::: incremental \n1. *The CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b] ,\n2. *The ITCJ analysis* [@Rivera_et_al_2025],\n:::\n\n::: {.fragment}\nBoth approaches were conducted using `R` version 4.2.2 [@R_2015], with:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Additional `R` packages for data manipulation and visualization: `tidyverse` [@Wickham_et_al_2019], `igraph` [@Csardi_et_al_2006; @Csardi_et_al_2025], and `RColorBrewer` [@Neuwirth_2022];\n- Specific user-defined functions (`UDFs`) to facilitate data manipulation, visualization, model summarization, diagnostics, and prediction from the approaches (all are provided in the main document).\n:::\n:::\n\n:::\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Fits a BTL model** using the `BTm()` function from the `BradleyTerry2` package [@Turner_et_al_2012a; @Turner_et_al_2012b],\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli $(T_{IA})$\n- To generate the model residuals and conduct *misfit* analysis.\n:::\n:::\n\n2. **Fits a (multilevel) regression** to model residuals using the `brms` package [@Burkner_2017; @Burkner_2018],\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To test hypothesis of differences in mean residuals between groups of judges, i.e., $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]}$, $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]}$, and $\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]}$;\n- To assess the variability between- and within-judges, where the latter has **no direct equivalent parameter**, while former corresponds to $s_{ZJ}$$^{*}$.\n- To aggregate model residuals into judges biases $(B_{J})$ \n:::\n:::\n\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for judges, i.e., $s_{ZJ}$, versus multiple variability parameters defined by the experience of the judges, i.e., $s_{ZJd}$.\n:::\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **Fits a (multilevel) regression** to the stimuli' mean trait estimates, \n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the effect of age on the mean latent trait, i.e, $\\beta_{XIc}$\n- To test hypothesis of differences in mean latent traits between groups of children, i.e., $\\beta_{XId[g=1]} - \\beta_{XId[g=2]}$, $\\beta_{XId[g=1]} - \\beta_{XId[g=3]}$, and  $\\beta_{XId[g=2]} - \\beta_{XId[g=3]}$\n- To assess the variability within and between children, i.e., $s_{A}$ and $s_{XI}$$^{*}$, respectively\n- To aggregate stimuli traits into individual level $(T_{I})$ \n:::\n:::\n\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nNotably, **for each** `brms` model, **four** Markov chains of $4000$ iterations were run, each with distinct starting values. The first $2000$ iterations served as warm-up, and the remaining $2000$ were used as posterior samples (for a total of $8000$ posterior samples).\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for individuals, i.e., $s_{XI}$, versus multiple variability parameters defined by the individuals' groups, i.e., $s_{XId}$.\n:::\n\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches and software of step 5 {style=\"font-size:80%;\"}\n\nIn contrast, for the *ITCJ analysis* [@Rivera_et_al_2025], the study uses:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- `Stan` version 2.26.1 [@Stan_2020] and the interface package `cmdstanr` [@Gabry_et_al_2025] to fit a series of increasingly complex Bayesian ITCJ models,\n- Additional `R` packages for model summaries, predictions, and diagnostics: `loo` [@Vehtari_et_al_2024b], `posterior` [@Burkner_et_al_2024], and `bayesplot` [@Gabry_et_al_2019; @Gabry_et_al_2025].\n\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nNotably, **for each** Bayesian model, **four** Markov chains of $4000$ iterations were run, each with distinct starting values. The first $2000$ iterations served as warm-up, and the remaining $2000$ were used as posterior samples (for a total of $8000$ posterior samples).\n:::\n\n<!-- ######################################### -->\n\n# 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **_Stationarity, convergence, and mixing_** (for Bayesian models only), using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Graphical analyses, including trace plots, rank-normalized trace (trank) plots, autocorrelation function (ACF) plots, and comparison plots of prior to posterior distributions,\n- Diagnostic statistics, including the potential scale reduction factor statistics $(\\hat{R})$ with a cut-off value of $1.05$ [@Vehtari_et_al_2021a] and effective sample size statistics $(n_{\\text{eff}})$ [@Gelman_et_al_2014].\n:::\n:::\n\n2. **_Parameter recovery_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The graphical comparisons of \"true\" parameters values versus posterior estimates,\n- The parameter posterior Root Mean Squared Error $(\\text{RMSE})$, defined as follows:\n:::\n:::\n    \n:::\n:::\n\n::: {.fragment}\n$$\n\\text{RMSE}( \\boldsymbol{\\hat{\\theta}}, \\theta) = \\sqrt{ \\frac{1}{S} \\sum_{s=1}^{S} ( \\hat{\\theta}_{s} - \\theta )^2 }\n$$\n:::\n\n::: {.fragment style=\"font-size:64%;\"}\nwhere $\\boldsymbol{\\hat{\\theta}}$ is the vector of posterior samples associated with the \"true\" parameter $\\theta$, and $\\hat{\\theta}_{s}$ is the $s$-th sample out of a total of $S$ posterior draws.\n:::\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **_In-sample fit_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The deviance information criterion $(\\text{DIC})$ [@Spiegelhalter_et_al_2002]\n:::\n:::\n\n4. **_Approximate out-of-sample fit_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The widely applicable information criterion $(\\text{WAIC})$ [@Watanabe_2013] and its standard error $(\\text{SE}_{W})$, along with the differences in $\\text{WAIC}$ between models $(\\text{dWAIC} \\pm 1 \\cdot \\text{dSE}_{W})$\n- The Pareto Smoothing Importance Sampling criterion $(\\text{PSIS})$ [@Vehtari_et_al_2017; @Vehtari_et_al_2024a] and its standard error $(\\text{SE}_{P})$, along with the differences in $\\text{PSIS}$ between models $(\\text{dPSIS} \\pm 1 \\cdot \\text{dSE}_{P})$\n:::\n:::\n\n5. **_In-sample predictive accuracy_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Confusion matrix comparing expected posterior predictions $E( \\boldsymbol{\\hat{y}})$ with observed outcomes $\\boldsymbol{y}$ from the **_first_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n- (Multiple) confusion matrix comparing the posterior predictions $\\boldsymbol{\\hat{y}}_{s}$ with observed outcomes  $\\boldsymbol{y}$ from the **_first_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n:::\n:::\n\n:::\n:::\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n6. **_Out-of-sample predictive accuracy_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Confusion matrix comparing expected posterior predictions $E( \\boldsymbol{\\hat{y}})$ with observed outcomes $\\boldsymbol{y}$ from the **_second_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n- (Multiple) confusion matrix comparing the posterior predictions $\\boldsymbol{\\hat{y}}_{s}$ with observed outcomes  $\\boldsymbol{y}$ from the **_second_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,\n:::\n:::\n\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 5. Results\n\n---\n\n## 5. Results {style=\"font-size:80%;\"}\n\nIn this section, the study will:\n\n::: incremental \n1. Describe the _**first** synthetic_ random comparison dataset;\n2. Progress through the steps $3-7$ of the Bayesian (research) workflow, described in @sec-methods, using:\n\n::: incremental \n- The CBTL analysis, and \n- The ITCJ analysis\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 5.1 The first synthetic comparison dataset\n\n# 5.1.1 Data description\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of design, the dataset reveals that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most stimuli were compared $20$ times; only two stimuli (IDs $2$ and $3$) from individual $58$ were compared slightly fewer times due to random variation.\n- The stimuli comparison network indicates a random *balanced design* [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_comparisons layout-ncol=2}\n![](/figures/data_summary/stimuli_comparisons_bottom.png){width=60%}\n\n![](/figures/data_summary/stimuli_network.png){width=60%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals $(Is)$ and stimuli $(As)$. *Right panel* shows the stimuli comparison network.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nIn a similar manner, the data indicates:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most individuals were compared $200$ times ($20$ comparisons × $10$ stimuli each); only one individual (ID $58$) was compared slightly fewer times due to random design variation;\n- The connected component analysis [@Betancourt_2024] and individual comparison network indicates a fully connected network and a *balanced design* for individuals [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_comparisons layout-ncol=2}\n\n![](/figures/data_summary/individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/individual_network.png){width=55%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals. *Right panel* shows the individual comparison network.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nOn the other hand, the dataset shows:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges compare individuals with frequencies ranging from $0$ to $13$ comparisons;\n- Most judges completed $262$ comparisons, while a few completed $264$ due to random design variation.\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_comparisons layout-ncol=2}\n![](/figures/data_summary/judges2individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/judges_comparisons.png){width=90%}\n\nComparison design. *Left panel* shows the judges $(Js)$ versus the first $10$ individuals $(Is)$. *Right panel* shows the total number of judges' comparisons.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nMoreover,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges to individual comparison network indicates a fully connected network\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_individuals_comparisons}\n![](/figures/data_summary/judges_individuals_network.png){width=100%}\n\nBipartite graph of judges to individual comparison network.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of the comparison outcomes, we see some stimuli with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/stimuli_wins.png){width=70%}\n\nStimuli win rates.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nAggregated by individuals, we see some individuals with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins.png){width=70%}\n\nIndividual win rates.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nDivided by hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- It is harder to see average differences between the groups,\n- However, we can easily notice the different variability between them\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins_groups.png){width=100%}\n\nIndividual win rates per group. *Left panel* describe NH children. *Middle panel* describe HI-HA children. *Right panel* illustrate HI-CI children.\n:::\n:::\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nHowever, no apparent relationship transpire between individual wins and age:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc.png){width=70%}\n\nIndividual win rates versus age.\n:::\n:::\n\n\n---\n\n## 5.1.1 Data description {style=\"font-size:80%;\"}\n\nConsidering the interaction of age and hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- We notice a slightly decreasing trend in HI-HA and HI-CI children, indicating that in those groups, older children are less likely to win in a comparison, but the results are not *unambiguous* (*Simpson's, Berkson's or another paradox*?).\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc_groups.png){width=100%}\n\nIndividual win rates.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5.1.2 Data modeling\n\n# 5.1.2.1 Data modeling: The CBTL analysis\n\n---\n\n## 5.1.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\n\n\n\n<!-- ######################################### -->\n\n# 5.1.2.2 Data modeling: The ITCJ analysis \n\n---\n\n## 5.1.2.2 Data modeling: The ITCJ analysis {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2 The second synthetic comparison dataset\n\n# 5.2.1 Data description\n\n---\n\n## 5.2.1 Data description {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2.2 From Estimands and Estimator to Effects and Predictions: Steps 8 and 9\n\n---\n\n## 5.2.2 From Estimands and Estimator to Effects and Predictions: Steps 8 and 9 {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2.2.1 The classical BTL analysis\n\n---\n\n## 5.2.2.1 The classical BTL analysis {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 5.2.2.2 The Information-Theoretical model for CJ\n\n---\n\n## 5.2.2.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n\n# 6. Discussion\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n# 6.1 Future research directions\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n# 6.2 Study limitations\n\n---\n\n## 6.2 Study limitations {style=\"font-size:80%;\"}\n\n\n<!-- ######################################### -->\n\n# 7. Conclusion\n\n---\n\n## 7. Conclusion {style=\"font-size:80%;\"}\n\n<!-- ######################################### -->\n\n---\n\n# Appendix A - From Design to Sample: Step 2 {#sec-AppA}\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nDiffering only by replication seed, the study generates _**two** synthetic_ random sample and comparison datasets from the conceptual population in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms shown in @fig-cj17, sample size calculations were conducted assuming:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- That \"reaching\" one children from the HI-HA or HI-CI groups costs ten times $(10x)$ more that \"reaching\" one NH child.\n- Three criteria for individual sample size selection: (1) a minimum power to detect $\\beta_{XIc}$ of $80\\%$ $(1-\\beta)$, (2) a minimum power to detect differences in $bXId$ of $80\\%$ $(1-\\beta)$, and (3) a maximum efficiency possible, i.e., less and more balanced sample sizes are preferred.\n- That \"hiring\" one AU judge cost five times $(5x)$ as much as \"hiring\" an IL judge, while \"hiring\" one PT judge cost three times $(3x)$ as much as an IL judge.\n- Three criteria for judge sample size selection: (1) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject $\\beta_{ZJc} = 0$, (2) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject differences in $\\beta_{ZJd}$ equal to zero, and (3) maximum efficiency, i.e., less and more balanced sample sizes are preferred.\n:::\n:::\n\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_ss}\n![](/figures/sim_individual_sample_size.png){width=100%}\n\nIndividual's sample size calculation, considering requirements for Power, Efficiency and Cost.\n:::\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_ss}\n![](/figures/sim_judges_sample_size.png){width=100%}\n\nJudges's sample size calculation, considering requirements for Confidence, Efficiency and Cost.\n:::\n:::\n\n\n\n\n# Licence {style=\"font-size:80%;\"}\n\n---\n\n## Licence {style=\"font-size:80%;\"}\n\nAll the code that is original to this study and not attributed to any other authors is copyrighted by *Jose Manuel Rivera Espejo* and released under the New BSD (3-Clause) License: [https://opensource.org/license/BSD-3-Clause](https://opensource.org/license/BSD-3-Clause)\n\n<!-- ######################################### -->\n\n---\n\n# References {style=\"font-size:80%;\"}\n\n:::{#refs style=\"font-size:80%;\"}\n\n:::\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["styles.css"],"output-file":"presentation.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.550","auto-stretch":true,"slideNumber":true,"chalkboard":true,"previewLinks":"auto","csl":"diabetologia.csl","logo":"figures/logo-uantwerpen-sw-en-cmyk-pos.png","footer":"[Online manuscript (work in progress)](https://jriveraespejo.github.io/paper3_manuscript/)","title":"Bayesian modeling of comparative judgment data with `R` and `Stan`\n","author":[{"name":{"given":"Jose(ma)","family":"Rivera"},"orcid":"0000-0002-3088-2783","url":"https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/","email":"JoseManuel.RiveraEspejo@uantwerpen.be","corresponding":true,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Tine","family":"van Daal"},"orcid":"0000-0001-9398-9775","url":"https://www.uantwerpen.be/en/staff/tine-vandaal/","email":"tine.vandaal@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Sven","family":"De Maeyer"},"orcid":"0000-0003-2888-1631","url":"https://www.uantwerpen.be/en/staff/sven-demaeyer/","email":"sven.demaeyer@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Steven","family":"Gillis"},"orcid":null,"url":"https://www.uantwerpen.be/nl/personeel/steven-gillis/","email":"steven.gillis@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Linguistics","group":"Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)"}]}],"date":"last-modified","bibliography":["references.bib"],"title-slide-attributes":{"data-notes":"(to do)\n"}}}},"projectFormats":["revealjs"]}