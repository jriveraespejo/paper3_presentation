{"title":"Finding CJ: The modeling of comparative judgment data with `R` (and `Stan`)","markdown":{"yaml":{"title":"Finding CJ: The modeling of comparative judgment data with `R` (and `Stan`)\n","author":[{"name":{"given":"Jose(ma)","family":"Rivera"},"orcid":"0000-0002-3088-2783","url":"https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/","email":"JoseManuel.RiveraEspejo@uantwerpen.be","corresponding":true,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Tine","family":"van Daal"},"orcid":"0000-0001-9398-9775","url":"https://www.uantwerpen.be/en/staff/tine-vandaal/","email":"tine.vandaal@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Sven","family":"De Maeyer"},"orcid":"0000-0003-2888-1631","url":"https://www.uantwerpen.be/en/staff/sven-demaeyer/","email":"sven.demaeyer@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Steven","family":"Gillis"},"orcid":null,"url":"https://www.uantwerpen.be/nl/personeel/steven-gillis/","email":"steven.gillis@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Linguistics","group":"Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)"}]}],"date":"last-modified","bibliography":"references.bib","title-slide-attributes":{"data-notes":"(to do)\n"}},"headingText":"1. Introduction","headingAttr":{"id":"","classes":[],"keyvalue":[["style","font-size:80%;"]]},"containsRefs":true,"markdown":"\n\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nThe Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] offers a **simple method** for measuring traits and conducting statistical inference from comparative judgment (CJ) data [@Andrich_1978; @Pollitt_2012b]. \n\n[Its simplicity stems from two features:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. A reliance on an extensive set of simplifying assumptions about the traits, judges, and stimuli involved in CJ assessments [@Thurstone_1927b; @Bramley_2008],\n2. The use of ad hoc procedures to handle inferences, including hypothesis testing [@Pollitt_2012b].\n:::\n:::\n\n::: {.fragment}\nHowever, recent studies question whether:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- These assumptions hold in modern CJ applications? [@Bramley_2008; @Kelly_et_al_2022; @Rivera_et_al_2025]\n- The ad hoc procedures effectively fulfill their intended analytical purpose? [@Kelly_et_al_2022; @Rivera_et_al_2025]\n:::\n:::\n:::\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nTo address these concerns, Rivera et al. [@Rivera_et_al_2025] proposed *The Information-Theoretical model for CJ*. The approach,\n\n[1. Extends the general form of Thurstone's law of comparative judgment [@Thurstone_1927a; @Thurstone_1927b], combining Thurstone's core theoretical principles with key CJ assessment design features.]{.fragment style=\"font-size:80%;\"}\n\n[2. Enables the development of models tailored to the assumed data-generating process of the CJ system under study, thus:]{.fragment style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Eliminating the need to rely on the simplifying assumptions of the BTL model,\n- Removing the dependence on ad hoc hypothesis-testing procedures.\n:::\n:::\n\n[Nevertheless, although approach has the potential to yield reliable trait estimates and accurate statistical inferences, **this promise still needs to be empirically tested**.]{.fragment style=\"font-size:80%;\"} \n\n<!-- ######################################### -->\n\n# 2. Research goals\n\n---\n\n## 2. Research goals {style=\"font-size:80%;\"}\n\nThus, this study has **two overarching goals**:\n\n::: {.fragment style=\"font-size:80%;\"}\n1. To show how apply the Information-Theoretical model for CJ to a simulated dataset,\n\n    A **tutorial component**, offering detailed guidance on data simulation, prior and model specification, estimation, and interpretation using the software `R` and `Stan`.\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nOnce a *sufficiently trustworthy model* is found in goal 1,\n\n2. Evaluate whether the approach yield accurate and reliable trait estimates and inference parameters,\n\n    A **model validation component** benchmarked against the classical BTL analysis.\n:::\n\n<!-- ######################################### -->\n\n# 3. A tale of two analytical approaches {#sec-approaches}\n\n---\n\n## 3. A tale of two analytical approaches {style=\"font-size:80%;\"}\n\nCJ data can be analyzed under two analytical approaches:\n\n::: incremental \n1. *The classical BTL analysis* (hereafter, **CBTL analysis**) [@Pollitt_2012a; @Pollitt_2012b],\n    \n    which relies on a sequence of separate methods to estimate traits and draw inferences,\n\n2. *The Information-Theoretical model for CJ* (hereafter, **ITCJ analysis**) [@Rivera_et_al_2025],\n\n    which employs a single, systematic, and integrated approach for the same two purposes.\n:::\n\n<!-- ######################################### -->\n\n# 3.1 The CBTL analysis\n\n---\n\n## 3.1 The CBTL analysis {#sec-CBTL style=\"font-size:80%;\"}\n\nThis approach relies on a sequence of separate methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]. Specifically, the *CBTL analysis*:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Apply the BTL model** to data, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli (mean and standard error)\n- To generate the model residuals and conduct *misfit* analysis\n:::\n:::\n\n2. **Generate summaries** or **apply (multilevel) regression** to the stimuli' mean trait estimates, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the trait of the stimuli at the individual level\n- To separate the variability in between- and within-individuals \n- To summarize or conduct inferences at the level of stimuli and individuals\n:::\n:::\n\n3. **Generate summaries** or **apply (multilevel) regression** to the model residuals, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the remaining variability at the judges level\n- To separate the remaining variability in between- and within-judges \n- To summarize or conduct inferences at the level of judges, including the investigation of bias\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n# 3.2 The ITCJ analysis\n\n--- \n\n## 3.2 The ITCJ analysis {#sec-ITCJ style=\"font-size:80%;\"}\n\nThis approach applies a single, systematic, and integrated approach to estimate traits and conduct inferences [@Rivera_et_al_2025]. In broad terms, the *ITCJ analysis*:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Begins with the general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] (see next slide),\n2. Adapts this structure to the assumed data-generating process of the CJ system under study,\n3. Develops one or more *bespoke* statistical models for analyzing the CJ system.\n4. Use the one (or more) statistical model(s) to estimate traits and conduct inferences.\n:::\n:::\n\n::: {.fragment}\nWith these steps a researcher can:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Estimate the traits of the stimuli and individuals (full distribution)\n- Assess the variability and conduct inferences at the stimuli and individual levels\n- Estimate the biases of the judges and judgments (full distribution)\n- Assess the variability and conduct inferences at the judgments and judges levels\n- Conduct *outlier* identification for stimuli, individuals, judgments, and judges\n:::\n:::\n\n:::\n\n--- \n\n## 3.2 The ITCJ analysis {style=\"font-size:80%;\" #sec-3.2}\n\n<!-- commands for d-separation -->\n\\newcommand{\\dsep}{\\:\\bot\\:}\n\\newcommand{\\ndsep}{\\:\\not\\bot\\:}\n\\newcommand{\\cond}{\\:|\\:}\n\nThe general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] takes the following form:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj15 layout-ncol=2 }\n\n![](/figures/population_summary/CJ_TM_15.png){width=80%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK} \n\\end{aligned}\n$$\n\nComparative judgment model. *Left panel* illustrates the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nLeading to the general probabilistic and statistical model:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\ \n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}, e_{JK} \\} \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{JK} \\} \\\\\n  e_{J} & \\dsep e_{JK}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, X_{IA}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J}, Z_{JK}, e_{JK} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} ) P( e_{JK} ) \\\\ \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\nComparative judgment model, assuming different discriminal dispersions for traits. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model. \n:::\n\n:::\n\n\n::: {.fragment}\nWith the following constraints to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$ [@Depaoli_2021]: \n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16b}\n$$\n\\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix}; \\quad \n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & s_{A} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & s_{K} \n  \\end{bmatrix}; \\quad \n  \\sum_{g=1}^{3} s_{XI}[g]/3 = 1; \\quad\n  0< s_{A} < 1; \\quad \n  \\sum_{g=1}^{3} s_{ZJ}[g]/3 = 1; \\quad\n  0< s_{K} < 1\n$$ \n\nConstraints of the CJ model to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4. Methods \n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\nTo meet the tutorial and model validation goals, this study follows the Bayesian (research) workflow [@Depaoli_et_al_2017; @Neal_2020; @Gelman_et_al_2020; @Schad_et_al_2020; @Betancourt_2020; @McElreath_2024b; @McElreath_2024c]:\n\n::: {#fig-workflow}\n![](/figures/workflow.png){width=80%}\n\nBayesian (research) workflow.\n:::\n\n---\n\n## 4. Methods {#sec-methods style=\"font-size:80%;\"}\n\nSpecifically, the study follows these steps (overarching goals in parenthesis):\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n1. **Theory $\\rightarrow$ Estimand(s) $\\rightarrow$ Design** (*Tutorial and Model validation*)\n\n    Considering three steps: \n\n::: incremental \na. Define a CJ structure of interest and explicitly state its assumptions from relevant literature; \nb. Specify the estimand(s) of interest and provide formal definitions for each target parameter;\nc. Simulate a _synthetic conceptual population_ that reflects the defined structure and assumptions;\n:::\n\n2. **Design $\\rightarrow$ Sample** (*Tutorial and Model validation*)\n    \n    Generate a synthetic random sample and comparison datasets from the conceptual population simulated in step $1$;\n\n3. **{Theory, Design, Estimand(s)} $\\rightarrow$ Estimator** (*Tutorial and Model validation*)\n\n    Specify models for analyzing the synthetic random comparison dataset using both the CBTL and the ITCJ analysis;\n    \n4. **Estimator $\\rightarrow$ Prior predictive** (*Tutorial*)\n\n    Perform prior predictive checks;\n:::\n:::\n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n5. **{Estimator, Sample} $\\rightarrow$ Estimate(s)** (*Tutorial and Model validation*)\n\n    Apply both the CBTL and ITCJ methods to the synthetic random comparison dataset;\n\n6. **Estimate(s) $\\rightarrow$ {Diagnostic, Post predictive}** (*Tutorial*)\n\n    Assess the quality of the models and estimate(s) in terms of stationarity, convergence, mixing, parameter recovery, in-sample predictive accuracy, and approximate out-of-sample fit;\n    \n7. **{Diagnostic, Post predictive} $\\rightarrow$ Estimator** (*Tutorial*)\n\n    Incrementally refine the statistical model repeating steps 3–6 until a *sufficiently trustworthy model* is obtained according to the criteria outlined in step 6;\n\n8. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Effects $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate the *estimate(s)* of interest for the synthetic random comparison dataset using both the CBTL and ITCJ analysis, and interpret the results;\n    \n9. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Predictions $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate predictions for the synthetic comparison dataset using both the CBTL and ITCJ analysis, and compare their in-sample predictive accuracy, and approximate out-of-sample fit.\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 4.1 From Theory to Design: Steps 1a-1c\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThe conceptual population simulation is based on the data characteristics and findings reported by Boonen et al. [@Boonen_et_al_2020]:\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the data characteristics, the study:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Includes multiple stimuli nested within multiple individuals,\n- Considers individuals with different characteristics (e.g., age, hearing status),\n- Assigns each judge to make only one comparison per stimulus pair,\n- Involves judges who differ in characteristics (e.g., experience level),\n- Selects stimuli, individuals, and judges using a (pseudo-)random sampling algorithm,\n- Involves multiple judges performing multiple comparisons, assigned through a random comparison algorithm.\n:::\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the study findings, the study report that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Individuals with different hearing statuses differ in both their average latent trait levels and their **variability**,\n- There is more unexplained variability between individuals than within individuals (i.e., at the stimulus level),\n- No evidence of systematic judge bias was found (although it was not tested but treated as a model assumption),\n- Judges' experience levels did not account for differences in mean latent traits between stimuli, but differences in their **variabilities** were not assessed.\n:::\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThus, adapting the general CJ structure proposed by Rivera et al.'s [@Rivera_et_al_2025] to the data characteristics reported by Boonen et al. [@Boonen_et_al_2020] leads to the following conceptual population data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj17 layout-ncol=2}\n\n![](/figures/population_summary/CJ_population_DAG.png){width=85%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J} \\} \\\\\n  e_{I} & \\dsep \\{ e_{J} \\}\n\\end{aligned}\n$$\n\nCJ data-generating process for the conceptual population. *Left panel* shows the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nMoreover, integrating the assumptions derived from Boonen et al. [@Boonen_et_al_2020] leads to the following statistical data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj18a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J} \\} \\\\\n  e_{I} & \\dsep \\{ e_{J} \\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nData-generating process for simulated CJ data. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n:::\n\n::: {.fragment}\nWith the following parameter assumptions:\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-cj18b layout-ncol=2 }\n\n$$\n\\begin{split}\nX_{I} &= \\{ X_{Ic}, X_{Id}[g=1], X_{Id}[g=2], X_{Id}[g=3] \\} \\\\\nZ_{J} &= \\{ Z_{Jd}[g=1], Z_{Jd}[g=2], Z_{Jd}[g=3] \\} \\\\\n\\beta_{XI} & = \\{ \\beta_{XIc}, \\beta_{XId[g=1]}, \\beta_{XId[g=2]}, \\beta_{XId[g=3]} \\} = \\{ 0.1, 1, 0, -1\\} \\\\\n\\beta_{ZJ} &= \\{ \\beta_{ZJd[g=1]}, \\beta_{ZJd[g=2]}, \\beta_{ZJd[g=3]} \\} = \\{ 0, 0, 0\\}\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{XI[g]} &= \\{ s_{XId[g=1]}, s_{XId[g=2]}, s_{XId[g=3]} \\} = \\{ 1.5, 0.75, 0.75\\} \\\\\ns_{ZJ} &= \\{ s_{ZJd[g=1]}, s_{ZJd[g=2]}, s_{ZJd[g=3]} \\} = \\{ 0.5, 1, 1.5\\} \\\\\ns_{A} &= 0.2 \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 \\\\\n    0 & s_{A} & 0 \\\\\n    0 & 0 & s_{ZJ} \n\\end{bmatrix}\n\\end{split}\n$$\n\nSimulating parameter assumptions.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nIn layman terms:\n\n::: incremental \n::: {style=\"font-size:60%;\"}\n- No stimuli characteristics $(X_{IA})$ are assumed to affect the comparisons;\n- Stimuli latent trait residual variability is smaller than average individual latent trait residual variability $(s_{A} = 0.2 < 1)$;\n- Individual characteristics $(X_{I})$ include a continuous variable $(X_{Ic})$ for the age of children, and a categorical variable with three levels representing hearing status groups: normal-hearing (NH, $X_{Id}[g=1]$), hearing-impaired with hearing aids (HI-HA, $X_{Id}[g=2]$), and hearing-impaired with cochlear implants (HI-CI, $X_{Id}[g=3]$) children;\n- There is a \"small\" [@Cohen_1988; @Sawilowsky_2009] but increasing effect of age $(\\beta_{XIc})$ on the mean latent trait of individuals;\n- There are \"very large\" [@Cohen_1988; @Sawilowsky_2009] differences in the mean latent trait across hearing status groups $(\\beta_{XId[g=1]} > \\beta_{XId[g=2]} > \\beta_{XId[g=3]})$;\n- Individual latent trait residual variability differs by groups, i.e., $s_{XId[g=1]} > s_{XId[g=2]} = s_{XId[g=3]}$, with $\\sum_{g=1}^{3} s_{XId[g]}/3 = 1$;\n- Judges make only one comparison; thus, there are no judgment-level characteristics $(Z_{JK})$, judgement-level effects $(\\beta_{ZJK})$, or residual judgment variability $(p_{JK})$;\n- Judges characteristics $(Z_{J})$ include a categorical variable with three levels representing judge groups: audiologist (AU, $Z_{Jd}[g=1]$), primary teachers (PT, $Z_{Jd}[g=2]$), and inexperienced listeners (IL, $Z_{Jd}[g=3]$);\n- Judges' mean latent biases across judge groups are equal to zero $(\\beta_{ZJd[g=1]}=\\beta_{ZJd[g=2]}=\\beta_{ZJd[g=3]}=0)$;\n- However, judges exhibit more or less bias depending on their experience, i.e., $(s_{ZJd[g=1]}=0.5) < (s_{ZJd[g=2]} = 1) < (s_{ZJd[g=3]} = 1.5)$, with $\\sum_{g=1}^{3} s_{ZJ[g]}/3 = 1$;\n- Residual latent errors $(\\boldsymbol{e})$ are centered around zero with zero correlation $(\\boldsymbol{\\mu}, \\boldsymbol{Q})$.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {#sec-pop_sim style=\"font-size:80%;\"}\n\nFrom the simulation parameters, we can also define the **_estimands_** of interest:\n\n::: incremental \n::: {style=\"font-size:65%;\"}\n- The conditioned expected change in the individuals' mean latent trait for one additional year of age $(\\beta_{XIc})$;\n- The conditioned expected differences in mean latent traits between NH and HI-HA children $(\\beta_{XId[g=1]} - \\beta_{XId[g=2]})$, NH and HI-CI children $(\\beta_{XId[g=1]} - \\beta_{XId[g=3]})$, and HI-HA versus HI-CI children $(\\beta_{XId[g=2]} - \\beta_{XId[g=3]})$;\n- The conditioned expected differences in mean latent bias between AU and PT judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]})$, AU and IL judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]})$, and PT and IL judges $(\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]})$;\n- The latent trait residual variability of NH, HI-HA, and HI-CI children, i.e., $s_{XId[g=1]}$, $s_{XId[g=2]}$, and $s_{XId[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent trait between NH and HI-HA children $(s_{XId[g=1]} - s_{XId[g=2]})$, NH and HI-CI children $(s_{XId[g=1]} - s_{XId[g=3]})$, and HI-HA versus HI-CI children $(s_{XId[g=2]} - s_{XId[g=3]})$;\n- The latent bias residual variability of AU, PT, and IL judges, i.e., $s_{ZJd[g=1]}$, $s_{ZJd[g=2]}$, and $s_{ZJd[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent bias between AU and PT judges $(s_{ZJd[g=1]} - s_{ZJd[g=2]})$, AU and IL judges $(s_{ZJd[g=1]} - s_{ZJd[g=3]})$, and PT and IL judges $(s_{ZJd[g=2]} - s_{ZJd[g=3]})$;\n- The residual variability of the stimuli latent trait $(s_{A})$;\n- Latent traits $T_{IA}$, $T_{I}$, and $B_{J}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4.2 From Design to Sample: Step 2\n\n---\n\n## 4.2 From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nWe generate a synthetic random sample and comparison datasets from the conceptual population in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms illustrated in @fig-cj17, sample size calculations were conducted (see @sec-AppA), and the following design was adopted:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- A sample of $54$ individuals, divided into three hearing status groups: $40$ NH $(X_{Id}[g=1])$, $7$ HI-HA $(X_{Id}[g=2])$, and $7$ HI-CI $(X_{Id}[g=3])$ children;\n- A sample of $10$ stimuli per individual;\n- A sample of $60$ judges, divided into three groups: $10$ AU $(Z_{Jd}[g=1])$, $10$ PT $(Z_{Jd}[g=2])$, and $40$ IL $(Z_{Jd}[g=3])$;\n- Judges conduct only one-comparison of the same stimulus pair (i.e., design is NOT a *repeated measures design* [@Lawson_2015, chap. 9.5])\n- Each stimulus is compared $20$ times in total against other stimuli, across all judges.\n:::\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 4.3 From Estimator and Sample to Estimate(s): The analysis approaches in step 5\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches in step 5 {style=\"font-size:80%;\"}\n\nThe study applies two data analysis approaches for the simulated CJ data (as described in @sec-approaches):\n\n::: incremental \n1. *The CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b],\n2. *The ITCJ analysis* [@Rivera_et_al_2025]\n:::\n\n:::{.fragment}\nBoth analysis are conducted using `R` version 4.2.2 [@R_2015], with:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Additional `R` packages for data manipulation and visualization: `tidyverse` [@Wickham_et_al_2019], `igraph` [@Csardi_et_al_2006; @Csardi_et_al_2025], and `RColorBrewer` [@Neuwirth_2022];\n- Specific user-defined functions (`UDFs`) to facilitate data manipulation, visualization, model summarization, diagnostics, and prediction from the approaches (all are provided in the main document).\n:::\n:::\n:::\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches in step 5 {style=\"font-size:80%;\"}\n\nNotably, **each** `brms` multilevel regression model within the *CBTL analysis* and **each** Bayesian model within the *ITCJ analysis* were estimated using:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- **Four** Markov chains of $4000$ iterations, each with distinct starting values, where the first $2000$ iterations served as warm-up, and the remaining $2000$ were used as posterior samples (for a total of $8000$ posterior samples).\n::: \n:::\n\n\n# 4.3.1 From Estimator and Sample to Estimate(s): The CBTL analysis in step 5\n\n---\n\n## 4.3.1 From Estimator and Sample to Estimate(s): The CBTL analysis in step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Fits a BTL model** using the `BTm()` function from the `BradleyTerry2` package [@Turner_et_al_2012a; @Turner_et_al_2012b],\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli $(\\text{ability}_{i,a})$\n- To generate the model residuals $(\\text{res}_{j,a,b})$ and conduct *misfit* analysis.\n:::\n:::\n\n2. **Fits a multilevel regression** on the residuals using the `brms` package [@Burkner_2017; @Burkner_2018],\n    \n    $\\text{res}_{j,a,b} \\sim -1 + ZJd + (1 | Js)$\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To test hypothesis of differences in mean residuals between groups of judges, i.e., $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]}$, $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]}$, and $\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]}$;\n- To assess the variability within- and between-judges $(1 | Js)$, where the former has **no direct equivalent parameter**, while latter corresponds to $s_{ZJ}$$^{*}$.\n- To aggregate model residuals into judges biases $(B_{J})$ \n:::\n:::\n\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for judges, i.e., $s_{ZJ}$, versus multiple variability parameters defined by the experience of the judges, i.e., $s_{ZJd}$.\n:::\n\n---\n\n## 4.3.1 From Estimator and Sample to Estimate(s): The CBTL analysis in step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **Fits a multilevel regression** on the stimulus' trait estimates with the `brms` package [@Burkner_2017; @Burkner_2018], \n    \n    $\\text{ability}_{i,a} \\sim -1 + XIc + XId + (1 | Is)$\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the effect of age on the mean latent trait, i.e, $\\beta_{XIc}$\n- To test hypothesis of differences in mean latent traits between groups of children, i.e., $\\beta_{XId[g=1]} - \\beta_{XId[g=2]}$, $\\beta_{XId[g=1]} - \\beta_{XId[g=3]}$, and  $\\beta_{XId[g=2]} - \\beta_{XId[g=3]}$\n- To assess the variability within and between children $(1 | Is)$, corresponding to the parameters $s_{A}$ and $s_{XI}$$^{*}$, respectively\n- To aggregate stimuli traits into individual level $(T_{I})$ \n:::\n:::\n\n:::\n:::\n\n::: {.fragment}\nPrior selection for the multilevel regression models in Steps $2$ and $3$ relied on **prior predictive checks**, the results of which are presented in @sec-results.\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for individuals, i.e., $s_{XI}$, versus multiple variability parameters defined by the individuals' groups, i.e., $s_{XId}$. \n:::\n\n# 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models style=\"font-size:80%;\"}\n\nIn contrast, the *ITCJ analysis* [@Rivera_et_al_2025], fits six $(6)$ increasingly complex CJ models, using:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- `Stan` version 2.26.1 [@Stan_2020] with its interface package `cmdstanr` [@Gabry_et_al_2025],\n- Additional `R` packages for model summaries, predictions, and diagnostics: `loo` [@Vehtari_et_al_2024b], `posterior` [@Burkner_et_al_2024], and `bayesplot` [@Gabry_et_al_2019; @Gabry_et_al_2025].\n:::\n:::\n\n::: {.fragment}\nSimilarly, prior selection for the six ITCJ models relied on **prior predictive checks**, the results of which are presented in @sec-results.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models1 style=\"font-size:80%;\"}\n\nThe **first model** only considers the stimulus' traits$^{*}$. \n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj41 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(e_{IA}) \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid e_{IA} ) \\\\\n  & P( e_{IA} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = e_{IA} \\\\\n  e_{IA} & \\sim \\text{Normal}( 0, s_{A} )\n\\end{aligned}\n$$\n\nFirst ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n$$\n\\begin{split}\ns_{A} & \\sim \\text{Exponential}( 1/5 )\n\\end{split}\n$$\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to Step $1$ of the *CBTL analysis*, but with a different prior.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models2 style=\"font-size:80%;\"}\n\nBuilding on the first, the **second model** integrates the *hierarchical structural component* that captures the nesting structure of stimulus within individuals$^{*}$.\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj42 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(e_{I}) \\\\\n  e_{IA} & \\dsep e_{I}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid e_{I} ) \\\\\n  & P( e_{IA} ) P( e_{I} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nSecond ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1\n\\end{bmatrix}\n\\end{split}\n$$\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, without covariates for the individuals.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models3 style=\"font-size:80%;\"}\n\nExtending the second, the **third model** integrates covariates into the *structural component* to account for factors that may affect individual traits$^{*}$. \n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj43 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(XI, e_{I}) \\\\\n  e_{IA} & \\dsep e_{I}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid XI, e_{I} ) \\\\\n  & P( e_{IA} ) P( e_{I} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nThird ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n::: {layout-ncol=2}\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1 \n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, with covariates for the individuals.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models4 style=\"font-size:80%;\"}\n\nAlso building upon the second, but in contrast to the third, the **fourth model** only incorporates judges' biases$^{*}$.\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj44 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{J}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(e_{I}) \\\\\n  B_{J} & := f_{B}(e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{J} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid e_{I} ) \\\\\n  & P( B_{J} \\mid e_{J} ) \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{J}[j]\\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = e_{I} \\\\\n  B_{J} & = e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nFourth ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, without any covariates for individuals or judges. However, technically this is **no** longer a BTL model.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models5 style=\"font-size:80%;\"}\n\nCombining the 3rd and 4th, the **fifth model** integrates covariates to account for factors that may affect individual traits and judge biases$^{*}$:\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj45 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(XI, e_{I}) \\\\\n  B_{J} & := f_{B}(ZJ, e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid XI, e_{I} ) \\\\\n  & P( B_{J} \\mid ZJ, e_{J} ) \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nFifth ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n::: {layout-ncol=2}\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\\n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3); \\\\\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n\n:::\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, with covariates for individuals and judges. However, this is **no** longer a BTL model.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models6 style=\"font-size:80%;\"}\n\nLastly, building upon the fifth, the **sixth model** accounts for differences in the variability of individual traits and judge biases$^{*}$,\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj45 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(XI, e_{I}) \\\\\n  B_{J} & := f_{B}(ZJ, e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid XI, e_{I} ) \\\\\n  & P( B_{J} \\mid ZJ, e_{J} ) \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nSixth ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n::: {layout-ncol=2}\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3);\n\\end{split}\n$$\n\n$$\n\\begin{split}\nhs_{I} &\\sim \\text{Dirichlet}(5, GI) \\; \\rightarrow \\; s_{XI} = GI \\cdot hs_{I}; \\\\\nhs_{J} &\\sim \\text{Dirichlet}(5, GJ); \\; \\rightarrow \\; s_{ZJ} = GJ \\cdot hs_{I}; \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix}; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0      & 0 \\\\\n    0     & s_{XI} & 0 \\\\\n    0     & 0      & s_{ZJ}\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ There is no equivalent in the CJ literature.\n:::\n\n<!-- ######################################### -->\n\n# 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **_Stationarity, convergence, and mixing_** (for `brms` and Bayesian models only), using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Graphical analyses, including trace plots, rank-normalized trace plots, autocorrelation function (ACF) plots, and comparison plots of prior to posterior distributions,\n- Diagnostic statistics, including the potential scale reduction factor statistics $(\\hat{R})$ with a cut-off value of $1.05$ [@Vehtari_et_al_2021a] and effective sample size statistics $(n_{\\text{eff}})$ [@Gelman_et_al_2014].\n:::\n:::\n\n2. **_Parameter recovery_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The graphical comparisons of \"true\" parameters values versus posterior estimates,\n- The parameter posterior Root Mean Squared Error $(\\text{RMSE})$, defined as follows:\n:::\n:::\n    \n:::\n:::\n\n::: {.fragment}\n$$\n\\text{RMSE}( \\boldsymbol{\\hat{\\theta}}, \\theta) = \\sqrt{ \\frac{1}{S} \\sum_{s=1}^{S} ( \\hat{\\theta}_{s} - \\theta )^2 }\n$$\n:::\n\n::: {.fragment style=\"font-size:64%;\"}\nwhere $\\boldsymbol{\\hat{\\theta}}$ is the vector of posterior samples associated with the \"true\" parameter $\\theta$, and $\\hat{\\theta}_{s}$ is the $s$-th sample out of a total of $S$ posterior draws.\n:::\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **_In-sample predictive accuracy_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Confusion matrix comparing expected posterior predictions $E(\\boldsymbol{\\hat{y}})$ with observed outcomes $\\boldsymbol{y}$ from the **first** synthetic dataset, aggregated and non-aggregated across stimuli and individuals.\n- Multiple confusion matrices comparing posterior samples $\\boldsymbol{\\hat{y}}_{s}$ with observed outcomes $\\boldsymbol{y}$ from the **first** synthetic dataset, aggregated and non-aggregated across stimuli and individuals.\n:::\n:::\n\n4. **_Approximate out-of-sample fit_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The Pareto Smoothing Importance Sampling criterion $(\\text{PSIS})$ [@Vehtari_et_al_2017; @Vehtari_et_al_2024a].\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5. Results {#sec-results}\n\n---\n\n## 5. Results {style=\"font-size:80%;\"}\n\nIn this section, the study will:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Describe the synthetic random comparison dataset;\n2. Progress through the steps $3-7$ of the Bayesian (research) workflow, described in @sec-methods, using:\n\n::: incremental \n- The *CBTL analysis*, and \n- The *ITCJ analysis*\n:::\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5.1 Data description\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of design, the dataset reveals that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most stimuli were compared $20$ times; only two stimuli (IDs $2$ and $3$) from individual $58$ were compared slightly fewer times due to random variation.\n- The stimuli comparison network indicates a random *balanced design* [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_comparisons layout-ncol=2}\n![](/figures/data_summary/stimuli_comparisons_bottom.png){width=60%}\n\n![](/figures/data_summary/stimuli_network.png){width=60%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals $(Is)$ and stimuli $(As)$. *Right panel* shows the stimuli comparison network.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nIn a similar manner, the data indicates:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most individuals were compared $200$ times ($20$ comparisons × $10$ stimuli each); only one individual (ID $58$) was compared slightly fewer times due to random design variation;\n- The connected component analysis [@Betancourt_2024] and individual comparison network indicates a fully connected network and a *balanced design* for individuals [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_comparisons layout-ncol=2}\n\n![](/figures/data_summary/individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/individual_network.png){width=55%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals. *Right panel* shows the individual comparison network.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nOn the other hand, the dataset shows:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges compare individuals with frequencies ranging from $0$ to $13$ comparisons;\n- Most judges completed $262$ comparisons, while a few completed $264$ due to random design variation.\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_comparisons layout-ncol=2}\n![](/figures/data_summary/judges2individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/judges_comparisons.png){width=90%}\n\nComparison design. *Left panel* shows the judges $(Js)$ versus the first $10$ individuals $(Is)$. *Right panel* shows the total number of judges' comparisons.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nMoreover,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges to individual comparison network indicates a fully connected network\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_individuals_comparisons}\n![](/figures/data_summary/judges_individuals_network.png){width=100%}\n\nBipartite graph of judges to individual comparison network.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of the comparison outcomes, we see some stimuli with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/stimuli_wins.png){width=70%}\n\nStimuli win rates.\n:::\n:::\n\n:::{.notes}\n- One stimulus has win almost all comparisons, $\\text{IA}[6,7]$\n- Two stimuli has loss all comparisons, $\\text{IA}[5,2]$ and $\\text{IA}[45,3]$\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nAggregated by individuals, we see some individuals with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins.png){width=70%}\n\nIndividual win rates.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nDivided by hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- It is harder to see average differences between the groups,\n- However, we can easily notice the different variability between them\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins_groups.png){width=100%}\n\nIndividual win rates per group. *Left panel* describe NH children. *Middle panel* describe HI-HA children. *Right panel* illustrate HI-CI children.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nHowever, no apparent relationship transpire between individual wins and age:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc.png){width=70%}\n\nIndividual win rates versus age.\n:::\n:::\n\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nConsidering the interaction of age and hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- We notice a slightly decreasing trend in HI-HA and HI-CI children, indicating that in those groups, older children are less likely to win in a comparison, but the results are not *unambiguous* (*Simpson's, Berkson's or another paradox*?).\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc_groups.png){width=100%}\n\nIndividual win rates.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5.2 Data modeling\n\n# 5.2.1 Data modeling: The CBTL analysis\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nFirst, the BTL model is applied to the data to estimate the stimuli traits.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe initial model fit indicates that,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The BTL model struggles to accurately estimate traits for certain **'extreme' stimuli**,\n- It recovers the stimuli traits **reasonably well**, though with some downward bias,\n- The purpose and diagnostic value of the *misfit* analysis **remain unclear**.\n:::\n:::\n\n::: {#fig-CBTL_stimuli_trait1_2}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_stimuli_trait_comparison_plot1_2.png){width=50%}\n\n\n*CBTL analysis*, first BTL model fit. *Left panel* shows the trait estimates for all stimuli. *Right panel* shows the trait estimates for non-extreme stimuli.\n:::\n\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThe purpose and diagnostic value of the *misfit* analysis **remain unclear**:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-data_preference}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_preference_order.png){width=70%}\n\n\nStimuli \"Preference\" Analysis, identifying comparative wins and losses. *Blue circles* represent wins, *red X's* indicate losses. The diagonal line maps cases where the same stimulus appears on both the x- and y-axes. Stimuli are ordered from best (top) to worst (bottom) performing stimuli based on its true trait value.\n:::\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **multilevel regression** on the residuals (Step $2$) has the following specification,\n$$\n\\begin{split}\nbrm(& \\; \\text{data} \\; &= & d, \\\\\n& \\; \\text{family} \\; &= & gaussian, \\\\\n& \\; \\text{formula} \\; &= & res ~ -1 + ZJd + (1 | Js), \\\\\n& \\; \\text{prior} \\; &= c(& \\; \\text{prior}( \\; normal(0, 0.3), \\text{class}=b, \\text{coef}=ZJd1 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.3), \\text{class}=b, \\text{coef}=ZJd2 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.3), \\text{class}=b, \\text{coef}=ZJd3 ), \\\\\n& & & \\; \\text{prior}( \\; exponential(50), \\text{class}=sd ), \\\\ \n& & & \\; \\text{prior}( \\; exponential(25), \\text{class}=sigma )\n\\end{split}\n$$\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges' mean latent biases across groups are assigned **weakly informative priors**, reflecting no directional preference in group-level means, i.e., $\\beta_{ZJd[g=1]} = \\beta_{ZJd[g=2]} = \\beta_{ZJd[g=3]} \\sim normal(0, 0.3)$,\n- Due to the $[-1,1]$ range in the residuals [@Pollitt_2012a, pp. 164; @Pollitt_2012b, pp. 289], the between-judge residual variability $(sd)$ is assigned a **highly informative exponential prior** with an average of $\\lambda_{1}^{-1}=50^{-1}$ and a variance of $\\lambda_{1}^{-2}=50^{-2}$. This reflects the **strong belief** in the absence of systematic judges biases,\n- For similar reasons, the within-judge residual variability $(sigma)$ is assigned a **highly informative exponential prior** with an average of $\\lambda_{2}^{-1}=25^{-1}$ and a variance of $\\lambda_{2}^{-2}=25^{-2}$. This reflects the expectation of a greater (though still narrow) unexplained residual variability unrelated to systematic judge biases, i.e., $\\lambda_{1}^{-1} < \\lambda_{2}^{-1}$\n:::\n:::\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-CBTL_judge_prior}\n\n![](/figures/CBTL_analysis/cropped/3_1_CBTL_judge_trait_prior1.png){width=50%}\n\n*CBTL analysis*, prior predictive check for multilevel regression model on the residuals.\n:::\n\n:::\n\n::: {.notes}\n- Predictions still extend beyond the observed data range, despite the **highly informative priors** for the between-judge $(sd)$ and within-judge $(sigma)$ residual variability.\n- Although **more informative priors** could constrain the range even more, the current priors are sufficient given the size of the residuals data, that is, the data will overcome the priors.\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nAfter testing four prior specifications, the **multilevel regression** for stimuli traits (Step $3$) follows,\n$$\n\\begin{split}\nbrm(& \\; \\text{data} \\; &= & d, \\\\\n& \\; \\text{family} \\; &= & gaussian, \\\\\n& \\; \\text{formula} \\; &= & ability ~ -1 + XIc + XId + (1 | Is), \\\\\n& \\; \\text{prior} \\; &= c(& \\; \\text{prior}( \\; normal(0, 0.05), \\text{class}=b, \\text{coef}=XIc ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.5), \\text{class}=b, \\text{coef}=XId1 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.5), \\text{class}=b, \\text{coef}=XId2 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.5), \\text{class}=b, \\text{coef}=XId3 ), \\\\\n& & & \\; \\text{prior}( \\; exponential(1), \\text{class}=sd ), \\\\ \n& & & \\; \\text{prior}( \\; exponential(5), \\text{class}=sigma )\n\\end{split}\n$$\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- **No directional preference** is assumed for the effects of age and hearing status on individuals’ mean latent traits; thus, weakly informative priors are set for $\\beta_{XIc}$ and $\\beta_{ZJd[g=1]} = \\beta_{ZJd[g=2]} = \\beta_{ZJd[g=3]}$,\n- Between-individual residual variability $(sd)$ is assigned a **weakly informative exponential prior** with an average of $\\lambda_{1}^{-1}=1$ and a variance of $\\lambda_{1}^{-1}=1$. This reflects the **mild belief** that individuals systematic variability is 'around' one,\n- Within-individual (between-stimuli) residual variability $(sigma)$ is assigned a **weakly informative exponential prior** with an average of $\\lambda_{2}^{-1}=5^{-1}$ and a variance of $\\lambda_{2}^{-2}=5^{-2}$. This reflects the expectation of less between-stimuli versus between-individuals variability, i.e., $\\lambda_{1}^{-1} > \\lambda_{2}^{-1}$\n:::\n:::\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-CBTL_individual_prior}\n![](/figures/CBTL_analysis/cropped/3_1_CBTL_stimuli_trait_prior2.png){width=50%}\n\n*CBTL analysis*, prior predictive check for multilevel regression model on the estimated stimuli traits.\n:::\n\n:::\n\n::: {.notes}\n- Predictions capture the most likely range of the data, without trying to accommodate the 'extreme' estimates.\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-CBTL_diagnostics layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_individual_parameters_trace.png){width=100%}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_individual_parameters_rank.png){width=100%}\n\n*CBTL analysis*, example of multilevel regression parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are in the vicinity of $1$, and none is above $1.05$\n- Only $bZJd[3]$ has a $n_{eff} < 1000$, the rest have $n_{eff} > 1300$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-CBTL_recovery1}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery1.png){width=50%}\n\n*CBTL analysis*, parameter recovery for all steps. *Top right panel* include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n::: {.notes}\n- Extreme stimuli traits does not allow to see the trend of recovery\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-CBTL_recovery2}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=50%}\n\n*CBTL analysis*, parameter recovery for all steps. *Top right panel* does not include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n::: {.notes}\n- Individual traits are biased\n- Almost no recovery of judges biases\n- Not so good estimation for betas and sigmas\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-CBTL_rmse1}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse1.png){width=50%}\n\n*CBTL analysis*, RMSE for all steps. *Top right panel* include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n:::\n\n::: {style=\"font-size:80%;\"}\n\n::: {#fig-CBTL_rmse2}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=50%}\n\n*CBTL analysis*, RMSE for all steps. *Top right panel* include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-CBTL_posterior_pred1}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=50%}\n\n*CBTL analysis*, posterior predictive for confusion matrix based only on Step $1$. Posterior simulations assume normality of stimuli traits by Central Limit Theorem (CLT).\n:::\n\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-CBTL_posterior_pred2}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=50%}\n\n*CBTL analysis*, posterior predictive for stimuli wins based only on Step $1$. Posterior simulations assume normality of stimuli traits by Central Limit Theorem (CLT).\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-CBTL_posterior_pred3}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=50%}\n\n*CBTL analysis*, posterior predictive for individual wins based only on Step $1$. Posterior simulations assume normality of stimuli traits by Central Limit Theorem (CLT).\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nFourth, we check if the models still shows signs of 'trouble'.\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-CBTL_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_judges_influential.png){width=70%}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=70%}\n\n*CBTL analysis*, influential points based on Steps $2$ and $3$. *Left panel* shows the points identified in the residuals analysis. *Right panel* shows the points identified in the stimuli traits analysis.\n:::\n\n:::\n\n::: {.notes}\n- On a second misfit identification, no misfit stimuli is in the group of influential points\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2 Data modeling: The ITCJ analyses \n\n# 5.2.2.1 Data modeling: The ITCJ analysis 1 \n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models1, the **first** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = e_{IA} \\\\\n  e_{IA} & \\sim \\text{Normal}( 0, s_{A} )\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\ns_{A} & \\sim \\text{Exponential}( 1/5 )\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The between-stimuli variability $(s_{A})$ is assigned a **non-informative exponential prior** with an average of $\\lambda^{-1}=5$ and a variance of $\\lambda^{-2}=5^{2}$. This reflects the lack of any expectation regarding the between-stimuli variability.\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to Step $1$ of the *CBTL analysis*, but with a different prior.\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ1_priors layout-ncol=2 loyout-nrow=2}\n\n![](/figures/ITCJ_analysis/cropped/4_1_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_1_ITCJ_prior_individual.png){width=75%}\n\nFirst *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nSecond, we fit the **first** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ1_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_stimuli_trait_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_stimuli_trait_rank.png){width=100%}\n\nFirst *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nSecond, we fit the **first** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ1_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the first *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nSecond, we fit the **first** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ1_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the first *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ1_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ1_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.1.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ1_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.1.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ1_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.2 Data modeling: The ITCJ analysis 2\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models2, the **second** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Between-individual variability is assumed to be equal to $1$. Thus, the prior distribution is used to define the scale of individual latent traits, as it is required in latent variable models [@Depaoli_2021].\n- The within-individual (between-stimuli) variability $(s_{A})$ is assigned a **weakly informative Beta-proportion prior** with an average of $\\mu=0.5$ and a 'sample size' of $M=5$. This reflects the expectation that the stimuli are more homogeneous than the individuals [@Lawson_2015].\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, without covariates for the individuals.\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n\n![](/figures/ITCJ_analysis/cropped/4_2_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_1_ITCJ_prior_individual.png){width=75%}\n\nSecond *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_individual_trait_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_individual_trait_rank.png){width=100%}\n\nSecond *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the second *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the second *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.3 Data modeling: The ITCJ analysis 3\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models3, the **third** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1 \n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The effects of age and the hearing status groups on the mean latent trait of individuals has the same **weakly informative prior** as in the *CBTL analysis*,\n- Between- and within-individual (between-stimuli) variability has the same prior as the previous ITCJ model.\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, with covariates for the individuals.\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n![](/figures/ITCJ_analysis/cropped/4_3_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_1_ITCJ_prior_individual.png){width=75%}\n\nThird *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_betas_sigmas_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_betas_sigmas__rank.png){width=100%}\n\nThird *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nSecond, we fit the **third** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the third *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nSecond, we fit the **third** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the third *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.4 Data modeling: The ITCJ analysis 4\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models4, the **fourth** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{J}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(e_{I}) \\\\\n  B_{J} & := f_{B}(e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Between- and within-individual (between-stimuli) variability has the same prior as the previous ITCJ models,\n- Between-judge variability is assumed to be equal to $1$. Thus, the prior distribution is used to define the scale of judges latent biases, as it is required in latent variable models [@Depaoli_2021].\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, without any covariates for individuals or judges. However, technically this is **no** longer a BTL model.\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n![](/figures/ITCJ_analysis/cropped/4_4_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_1_ITCJ_prior_individual.png){width=75%}\n\nFourth *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_judge_bias_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_judge_bias_rank.png){width=100%}\n\nFourth *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fourth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fourth *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fourth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.5 Data modeling: The ITCJ analysis 5\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models5, the **fifth** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\\n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3); \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The effects of age and the hearing status groups on the mean latent trait of individuals has the same **weakly informative prior** as in the *CBTL analysis*,\n- The effects of judges groups on the mean latent bias has the same **weakly informative prior** as in the *CBTL analysis*,\n- Between- and within-individual (between-stimuli) variability has the same prior as the previous ITCJ models,\n- Between-judge variability has the same prior as the previous ITCJ models.\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, with covariates for individuals and judges. However, this is **no** longer a BTL model.\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n![](/figures/ITCJ_analysis/cropped/4_5_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_1_ITCJ_prior_individual.png){width=75%}\n\nFifth *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_betas_sigmas_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_betas_sigmas__rank){width=100%}\n\nFifth *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fifth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fifth *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fifth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.6 Data modeling: The ITCJ analysis 6\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models6, the **sixth** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3); \\\\\nhs_{I} &\\sim \\text{Dirichlet}(5, GI) \\; \\rightarrow \\; s_{XI} = GI \\cdot hs_{I}; \\\\\nhs_{J} &\\sim \\text{Dirichlet}(5, GJ); \\; \\rightarrow \\; s_{ZJ} = GJ \\cdot hs_{I}; \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix}; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0      & 0 \\\\\n    0     & s_{XI} & 0 \\\\\n    0     & 0      & s_{ZJ}\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The effects of age and the hearing status groups on the mean latent trait of individuals has the same **weakly informative prior** as in the *CBTL analysis*,\n- The effects of judges groups on the mean latent bias has the same **weakly informative prior** as in the *CBTL analysis*,\n- Within-individual (between-stimuli) variability has the same prior as the previous ITCJ models.\n- Between-individual and between-judges variability are now constraint to add to one (i.e., a simplex) across hearing status and judges groups, respectively. This requirement is enforced through a *weakly informative Dirichlet prior*. \n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model has no equivalent in the current CJ literature.\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n\n![](/figures/ITCJ_analysis/cropped/4_6_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_1_ITCJ_prior_individual.png){width=75%}\n\nSixth *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_betas_sigmas_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_betas_sigmas__rank){width=100%}\n\nSixth *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nSecond, we fit the **sixth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the sixth *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nSecond, we fit the **sixth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 5.3 Model comparison\n\n--- \n\n## 5.3 Model comparison {style=\"font-size:80%;\"}\n\nFinally, we compare the approximate out-of-sample fit for all *ITCJ models*.\n\n::: {style=\"font-size:80%;\"}\nThe **approximate out-of-sample fit comparison** indicates that, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- There is a clear difference in between ITCJ models $1-3$ (Bayesian *equivalent* of the BTL model) and ITCJ models $4-6$, which account for judges' biases, even considering the parameter penalty!,\n- ITCJ model $4$ and $5$ show similar performance, this implies that adding covariates to model $4$ (model $5$) does not substantially improves its approximate out-of-sample fit,\n- ITCJ model $6$ has the best relative approximate out-of-sample fit.\n:::\n:::\n\n::: {#fig-model_comparison}\n\n![](/figures/ITCJ_analysis/cropped/5_ITCJ_model_comparison.png){width=70%}\n\n*ITCJ analysis*, model comparison. *Left panel* shows all models. *Right panel* shows a smaller set of models.\n:::\n:::\n\n---\n\n## 5.3 Model comparison {style=\"font-size:80%;\"}\n\n```{r}\n#| echo: false\n#| output: false\nlibrerias = c('tidyverse','gt')\nsapply(librerias, require, character.only=T)\n\ndir = '/home/josema/Desktop/1. Work/1 research/PhD Antwerp/#thesis/paper3/paper3_presentation'\n\nvar_int = c('variable','value','mean','median','sd','q5','q95','rmse') \n# ROPE_lower, ROPE_upper, ROPE_prec\n```\n\nAlso, we compare and interpret the parameter estimates: \n\n```{r}\n#| echo: false\n#| output: false\nparam_CBTL = read.csv( \n  file = file.path( dir,'summaries','3_2_CBTL_estimated_parameter.csv' ) )\n# param_CBTL[,-1] = round( param_CBTL[,-1], 3)\nparam_CBTL\n\nidx1 = with( param_CBTL, str_detect(variable,' - ') )\nidx2 = with( param_CBTL, \n             str_detect(variable,'^TIA') |\n               str_detect(variable,'^TI') | \n               str_detect(variable,'^BJ') )\n\nparam_ITCJ = read.csv( \n  file = file.path( dir,'summaries','4_6_2_ITCJ_estimated_parameter.csv' ) )\nparam_ITCJ[,-1] = round( param_ITCJ[,-1], 3)\n\nidx3 = with( param_ITCJ, str_detect(variable,' - ') )\nidx4 = with( param_ITCJ, \n            str_detect(variable,'^TIA') |\n              str_detect(variable,'^TI') | \n              str_detect(variable,'^BJ') )\n```\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-parameter_estimates1 layout-ncol=2}\n\n```{r}\nparam_CBTL[!(idx1 | idx2), var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Parameter table\" ) |>\n  tab_footnote(\n    footnote = 'No equivalent parameter in original simulation.',\n    locations = cells_body(columns=1, rows=10) )\n```\n\n```{r}\nparam_ITCJ[!(idx3 | idx4), var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Parameter table\" )\n```\n\nParameter estimates. *Left table* reports the *CBTL analysis*. *Right table* reports the *ITCJ analysis*, model $6$.\n:::\n\n:::\n\n---\n\n## 5.3 Model comparison {style=\"font-size:80%;\"}\n\nAlso, we compare and interpret the parameter estimates: \n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-parameter_estimates2 layout-ncol=2}\n\n```{r}\nparam_CBTL[idx1, var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Contrast table\" )\n```\n\n```{r}\nparam_ITCJ[idx3, var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Contrast table\" )\n```\n\nContrast estimates. *Left table* reports the *CBTL analysis*. *Right table* reports the *ITCJ analysis*, model $6$.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n\n# 6. Discussion\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nThis study fulfills its **two overarching goals**, that is,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Showing how apply the *ITCJ model* to a simulated dataset,\n\n    A **tutorial component**, offering detailed guidance on data simulation, prior and model specification, estimation, and interpretation using the software `R` and `Stan`.\n\n2. Evaluating whether the approach yield accurate and reliable trait estimates and inference parameters,\n\n    A **model validation component** benchmarked against the *CBTL analysis*.\n:::\n:::\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nThe *CBTL analysis* results provide preliminary evidence that,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Researchers **cannot** treat \"sample-freeness\" as an inherent property of the BTL model, contrary to previous beliefs [@Bramley_2008; @Andrich_1978]. Instead, the property depends on the specific data under analysis.\n\n- When judges exhibit bias, the *CBTL analysis* **fails** to capture the complexity of the traits [@Thurstone_1927a; @Andrich_1978; @Bramley_2008; @Kelly_et_al_2022], producing **inaccurate and unreliable** estimates [@Ackerman_1989; @Zimmerman_1994; @McElreath_2020; @Hoyle_et_al_2023]. This limitation is particularly evident in the estimation of inference parameters and judges' biases.\n\n- The common CJ practice of separating trait estimation from hypothesis testing [@Casalicchio_et_al_2015; @Bramley_et_al_2019; @Boonen_et_al_2020; @Bouwer_et_al_2023; @vanDaal_et_al_2017; @Jones_et_al_2019; @Gijsen_et_al_2021], **introduces bias and reduces the reliability** of inferences [@McElreath_2020; @Kline_et_al_2023; @Hoyle_et_al_2023].\n\n- The BTL model is **overconfident** when predicting comparison outcomes, as shown by the posterior predictive checks based on the expected values.\n:::\n:::\n\n--- \n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nMoreover, the *CBTL analysis* results also provide preliminary evidence that,\n\n::: incremental \n::: {style=\"font-size:78%;\"}\n- Despite its **statistical definition** as an *outlier* detection tool [@Rivera_et_al_2025], *misfit* analysis **fail** to detect 'extreme' cases;\n\n- Despite its **conceptual definition** as a \"lack-of-consensus\" identification tool [@Pollitt_2012a; @Pollitt_2012b], *misfit* analysis **does not consistently classify all** stimuli, judges or individual exhibiting consensus or lack of consensus (see @fig-data_preference);\n\n    [ **Note:** The definition of consensus aligns with the microeconomics' concept of transitivity, that is, if $A \\succ B \\succ C$, then $A \\succ C$ [@Regenwetter_et_al_2011]. As Pollit [@Pollitt_2012a] explains: \"If a portfolio's WMS exceeds the criterion of mean plus two standard deviations, this means the judges did not judge it consistently, some considering it ‘better’ than others did. Significant portfolio misfit indicates a specific difference between judges in how they would **_rank order_** the portfolios, arising from a difference in how they understand or value the trait they are trying to assess.\" ]{style=\"font-size:80%;\"}\n\n- In fact, as show in this study, simple features of the data-generating process can produce lack of consensus or transitivity. For example, $\\text{IA}[6,3] \\succ \\text{IA}[6,7] \\succ \\text{IA}[31,6]$, but $\\text{IA}[31,6] \\succ \\text{IA}[6,3]$ (see @fig-data_preference);\n\n- Then, as expected, **excluding** *misfitting* stimuli and judges in a second model fit [@Pollitt_2012a; @Pollitt_2012b] **does not** improve trait estimation nor inferences, as the model continues to struggle with **'extreme' stimuli** and unmodeled data features.\n:::\n:::\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nIn contrast, results from the ITCJ analysis indicate that,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The frequentist BTL model and its *equivalent* Bayesian ITCJ models (models $1-3$) show **similar insufficient fit**; however, the ITCJ models exhibit a slightly better recovery performance due to the regularizing influence of **weakly informative priors** (see parameter recovery and RMSE plots).\n\n    [ **Note:** ITCJ models $1-3$ can be estimated with the `BTm()` function; however, the practice is largely absent in the current CJ literature. ]{style=\"font-size:80%;\"}\n    \n- Incorporating the hierarchical structure of stimuli and accounting for judges' biases (ITCJ model $4$) **improves** the prediction of comparison outcomes by up to $10$ percentage points in the overall True Positives (TP) and True Negatives (TN), as indicated by posterior predictive checks, more than including covariates in the model (model $3$).\n- Expanding the model to include the hierarchical structure of stimuli, judges' biases, heterogeneity in discriminal dispersions, and measurement error in inferences (ITCJ model $6$) **enhances both** the accuracy and reliability of all trait estimates and inference parameters. \n- ITCJ model $6$ enables to test other inferences not available under the *CBTL analysis* \n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 6.1 Future research directions\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\nBuilding upon Rivera et al. [@Rivera_et_al_2025], **four** research avenues deserve attention.\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Sampling and comparison mechanisms,\n\n    This study used random sampling and comparison algorithms. Future work should assess how alternative sampling strategies and comparison algorithms affect the accuracy and reliability of trait estimates and inference parameters, e.g., \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- what happens when data is not randomly sampled or when comparison are not random? \n- is the Adaptive Comparative Judgment (ACJ) algorithm random or non-random?\n:::\n:::\n\n2. Validity of *'misfit'* analysis,\n\n    Preliminary evidence in this study suggest that *'misfit'* analysis often miss classifies or fails to classify cases. Future work should then determine, e.g., \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- what *'misfit'* analysis actually diagnose? \n- are its conceptual and statistical definitions aligned? \n- does the analysis function as an *outlier* detection tool? \n- does it holds real analytical value in the CJ workflow?\n:::\n:::\n    \n:::\n:::\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\nBuilding upon Rivera et al. [@Rivera_et_al_2025], **four** research avenues deserve attention.\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. Sources of judges biases,\n\n    Evidence from this study indicates that researchers need to move beyond the traditional BTL model, explicitly integrating judges' biases in CJ analyses. This opens the door for future studies to investigate which factors influence these biases. For instance, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- do gender, age, culture, income, education, training, or expertise affect judges' biases?, \n- how many stimuli/individuals and judges are needed to support specific inferences?\n:::\n:::\n\n4. Prospective power and replication studies!\n\n    Considering the preliminary evidence of this study, \n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- in any random sample, what is the probability that at least one judge is biased?\n- if that probability is not low, how confident can researchers be that their CJ data are free of judges' biases? \n:::\n:::\n\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 6.2 Study limitations\n\n---\n\n## 6.2 Study limitations {style=\"font-size:80%;\"}\n\nDespite the relevance of its results, this study has some limitations:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The empirical test of the *ITCJ analyses* relies on a single, *'small'* simulated dataset,\n- The assessment of out-of-sample fit depends on approximate measures, such as PSIS, \n- The analysis did not use additional variables from the simulated data to evaluate the models' ability to not reject null hypotheses when the null is true (except for judges' groups),\n- The study did not explicitly design or plan the evaluation of the *misfit* analysis properties.\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 7. Conclusion\n\n---\n\n## 7. Conclusion {style=\"font-size:80%;\"}\n\nThis study achieves its **two main goals**, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. It provides a practical tutorial in `R` and `Stan` on how to apply the *ITCJ analysis* to a CJ data, \n2. It validates the model's ability to produce accurate and reliable trait estimates and inference parameters compared to the *CBTL analysis*.\n:::\n:::\n\n:::{.fragment }\nThe results of the study indicates that,\n\n::: incremental \n:::{style=\"font-size:80%;\"}\n- Researchers should move beyond the *CBTL analysis* toward a more systematic, integrated approach for trait estimation and inference, as exemplified by the *ITCJ analysis* [@Rivera_et_al_2025]. \n\n- There are several promising directions for future research.\n:::\n:::\n:::\n\n<!-- ######################################### -->\n\n# Licence {style=\"font-size:80%;\"}\n\n---\n\n## Licence {style=\"font-size:80%;\"}\n\nAll the code that is original to this study and not attributed to any other authors is copyrighted by [Jose Manuel Rivera Espejo](https://orcid.org/0000-0002-3088-2783) and released under the new [BSD-3-Clause](https://opensource.org/license/BSD-3-Clause) license. \n\n<!-- ######################################### -->\n\n# Appendix A - From Design to Sample: Step 2 {#sec-AppA}\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nThe study generates a synthetic random sample and comparison datasets from the conceptual population simulated in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms shown in @fig-cj17, sample size calculations were conducted assuming:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- That \"reaching\" one children from the HI-HA or HI-CI groups costs ten times $(10x)$ more that \"reaching\" one NH child.\n- Three criteria for individual sample size selection: (1) a minimum power to detect $\\beta_{XIc}$ of $80\\%$ $(1-\\beta)$, (2) a minimum power to detect differences in $bXId$ of $80\\%$ $(1-\\beta)$, and (3) a maximum efficiency possible, i.e., less and more balanced sample sizes are preferred.\n- That \"hiring\" one AU judge cost five times $(5x)$ as much as \"hiring\" an IL judge, while \"hiring\" one PT judge cost three times $(3x)$ as much as an IL judge.\n- Three criteria for judge sample size selection: (1) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject $\\beta_{ZJc} = 0$, (2) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject differences in $\\beta_{ZJd}$ equal to zero, and (3) maximum efficiency, i.e., less and more balanced sample sizes are preferred.\n:::\n:::\n\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_ss}\n![](/figures/population_summary/sim_individual_sample_size.png){width=100%}\n\nIndividual's sample size calculation, considering requirements for Power, Efficiency and Cost.\n:::\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_ss}\n![](/figures/population_summary/sim_judges_sample_size.png){width=100%}\n\nJudges's sample size calculation, considering requirements for Confidence, Efficiency and Cost.\n:::\n:::\n\n---\n\n# References {style=\"font-size:80%;\"}\n\n:::{#refs style=\"font-size:80%;\"}\n\n:::\n","srcMarkdownNoYaml":"\n\n# 1. Introduction {style=\"font-size:80%;\"}\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nThe Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] offers a **simple method** for measuring traits and conducting statistical inference from comparative judgment (CJ) data [@Andrich_1978; @Pollitt_2012b]. \n\n[Its simplicity stems from two features:]{.fragment}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. A reliance on an extensive set of simplifying assumptions about the traits, judges, and stimuli involved in CJ assessments [@Thurstone_1927b; @Bramley_2008],\n2. The use of ad hoc procedures to handle inferences, including hypothesis testing [@Pollitt_2012b].\n:::\n:::\n\n::: {.fragment}\nHowever, recent studies question whether:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- These assumptions hold in modern CJ applications? [@Bramley_2008; @Kelly_et_al_2022; @Rivera_et_al_2025]\n- The ad hoc procedures effectively fulfill their intended analytical purpose? [@Kelly_et_al_2022; @Rivera_et_al_2025]\n:::\n:::\n:::\n\n---\n\n## 1. Introduction {style=\"font-size:80%;\"}\n\nTo address these concerns, Rivera et al. [@Rivera_et_al_2025] proposed *The Information-Theoretical model for CJ*. The approach,\n\n[1. Extends the general form of Thurstone's law of comparative judgment [@Thurstone_1927a; @Thurstone_1927b], combining Thurstone's core theoretical principles with key CJ assessment design features.]{.fragment style=\"font-size:80%;\"}\n\n[2. Enables the development of models tailored to the assumed data-generating process of the CJ system under study, thus:]{.fragment style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Eliminating the need to rely on the simplifying assumptions of the BTL model,\n- Removing the dependence on ad hoc hypothesis-testing procedures.\n:::\n:::\n\n[Nevertheless, although approach has the potential to yield reliable trait estimates and accurate statistical inferences, **this promise still needs to be empirically tested**.]{.fragment style=\"font-size:80%;\"} \n\n<!-- ######################################### -->\n\n# 2. Research goals\n\n---\n\n## 2. Research goals {style=\"font-size:80%;\"}\n\nThus, this study has **two overarching goals**:\n\n::: {.fragment style=\"font-size:80%;\"}\n1. To show how apply the Information-Theoretical model for CJ to a simulated dataset,\n\n    A **tutorial component**, offering detailed guidance on data simulation, prior and model specification, estimation, and interpretation using the software `R` and `Stan`.\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nOnce a *sufficiently trustworthy model* is found in goal 1,\n\n2. Evaluate whether the approach yield accurate and reliable trait estimates and inference parameters,\n\n    A **model validation component** benchmarked against the classical BTL analysis.\n:::\n\n<!-- ######################################### -->\n\n# 3. A tale of two analytical approaches {#sec-approaches}\n\n---\n\n## 3. A tale of two analytical approaches {style=\"font-size:80%;\"}\n\nCJ data can be analyzed under two analytical approaches:\n\n::: incremental \n1. *The classical BTL analysis* (hereafter, **CBTL analysis**) [@Pollitt_2012a; @Pollitt_2012b],\n    \n    which relies on a sequence of separate methods to estimate traits and draw inferences,\n\n2. *The Information-Theoretical model for CJ* (hereafter, **ITCJ analysis**) [@Rivera_et_al_2025],\n\n    which employs a single, systematic, and integrated approach for the same two purposes.\n:::\n\n<!-- ######################################### -->\n\n# 3.1 The CBTL analysis\n\n---\n\n## 3.1 The CBTL analysis {#sec-CBTL style=\"font-size:80%;\"}\n\nThis approach relies on a sequence of separate methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]. Specifically, the *CBTL analysis*:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Apply the BTL model** to data, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli (mean and standard error)\n- To generate the model residuals and conduct *misfit* analysis\n:::\n:::\n\n2. **Generate summaries** or **apply (multilevel) regression** to the stimuli' mean trait estimates, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the trait of the stimuli at the individual level\n- To separate the variability in between- and within-individuals \n- To summarize or conduct inferences at the level of stimuli and individuals\n:::\n:::\n\n3. **Generate summaries** or **apply (multilevel) regression** to the model residuals, e.g.,\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To aggregate the remaining variability at the judges level\n- To separate the remaining variability in between- and within-judges \n- To summarize or conduct inferences at the level of judges, including the investigation of bias\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n# 3.2 The ITCJ analysis\n\n--- \n\n## 3.2 The ITCJ analysis {#sec-ITCJ style=\"font-size:80%;\"}\n\nThis approach applies a single, systematic, and integrated approach to estimate traits and conduct inferences [@Rivera_et_al_2025]. In broad terms, the *ITCJ analysis*:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Begins with the general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] (see next slide),\n2. Adapts this structure to the assumed data-generating process of the CJ system under study,\n3. Develops one or more *bespoke* statistical models for analyzing the CJ system.\n4. Use the one (or more) statistical model(s) to estimate traits and conduct inferences.\n:::\n:::\n\n::: {.fragment}\nWith these steps a researcher can:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Estimate the traits of the stimuli and individuals (full distribution)\n- Assess the variability and conduct inferences at the stimuli and individual levels\n- Estimate the biases of the judges and judgments (full distribution)\n- Assess the variability and conduct inferences at the judgments and judges levels\n- Conduct *outlier* identification for stimuli, individuals, judgments, and judges\n:::\n:::\n\n:::\n\n--- \n\n## 3.2 The ITCJ analysis {style=\"font-size:80%;\" #sec-3.2}\n\n<!-- commands for d-separation -->\n\\newcommand{\\dsep}{\\:\\bot\\:}\n\\newcommand{\\ndsep}{\\:\\not\\bot\\:}\n\\newcommand{\\cond}{\\:|\\:}\n\nThe general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] takes the following form:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj15 layout-ncol=2 }\n\n![](/figures/population_summary/CJ_TM_15.png){width=80%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{IA}, e_{JK} \\} \\\\\n  e_{J} & \\dsep \\{ e_{IA}, e_{JK} \\} \\\\\n  e_{IA} & \\dsep e_{JK} \n\\end{aligned}\n$$\n\nComparative judgment model. *Left panel* illustrates the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 3.2 The Information-Theoretical model for CJ {style=\"font-size:80%;\"}\n\nLeading to the general probabilistic and statistical model:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\ \n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}, e_{JK} \\} \\\\\n  e_{I} & \\dsep \\{ e_{J}, e_{JK} \\} \\\\\n  e_{J} & \\dsep e_{JK}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, X_{IA}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{JK} \\mid B_{J}, Z_{JK}, e_{JK} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} ) P( e_{JK} ) \\\\ \\\\ \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + \\beta_{XA} X_{IA} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{JK} & = B_{J} + \\beta_{ZK} Z_{JK} + e_{JK} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V} \\\\ \\\\\n\\end{aligned}\n$$\n\nComparative judgment model, assuming different discriminal dispersions for traits. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model. \n:::\n\n:::\n\n\n::: {.fragment}\nWith the following constraints to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$ [@Depaoli_2021]: \n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj16b}\n$$\n\\boldsymbol{\\mu} = [0, 0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \n  \\end{bmatrix}; \\quad \n  \\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 & 0 \\\\\n    0 & s_{A} & 0 & 0 \\\\\n    0 & 0 & s_{ZJ} & 0 \\\\\n    0 & 0 & 0 & s_{K} \n  \\end{bmatrix}; \\quad \n  \\sum_{g=1}^{3} s_{XI}[g]/3 = 1; \\quad\n  0< s_{A} < 1; \\quad \n  \\sum_{g=1}^{3} s_{ZJ}[g]/3 = 1; \\quad\n  0< s_{K} < 1\n$$ \n\nConstraints of the CJ model to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4. Methods \n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\nTo meet the tutorial and model validation goals, this study follows the Bayesian (research) workflow [@Depaoli_et_al_2017; @Neal_2020; @Gelman_et_al_2020; @Schad_et_al_2020; @Betancourt_2020; @McElreath_2024b; @McElreath_2024c]:\n\n::: {#fig-workflow}\n![](/figures/workflow.png){width=80%}\n\nBayesian (research) workflow.\n:::\n\n---\n\n## 4. Methods {#sec-methods style=\"font-size:80%;\"}\n\nSpecifically, the study follows these steps (overarching goals in parenthesis):\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n1. **Theory $\\rightarrow$ Estimand(s) $\\rightarrow$ Design** (*Tutorial and Model validation*)\n\n    Considering three steps: \n\n::: incremental \na. Define a CJ structure of interest and explicitly state its assumptions from relevant literature; \nb. Specify the estimand(s) of interest and provide formal definitions for each target parameter;\nc. Simulate a _synthetic conceptual population_ that reflects the defined structure and assumptions;\n:::\n\n2. **Design $\\rightarrow$ Sample** (*Tutorial and Model validation*)\n    \n    Generate a synthetic random sample and comparison datasets from the conceptual population simulated in step $1$;\n\n3. **{Theory, Design, Estimand(s)} $\\rightarrow$ Estimator** (*Tutorial and Model validation*)\n\n    Specify models for analyzing the synthetic random comparison dataset using both the CBTL and the ITCJ analysis;\n    \n4. **Estimator $\\rightarrow$ Prior predictive** (*Tutorial*)\n\n    Perform prior predictive checks;\n:::\n:::\n\n---\n\n## 4. Methods {style=\"font-size:80%;\"}\n\n::: incremental \n::: {style=\"font-size:75%;\"}\n5. **{Estimator, Sample} $\\rightarrow$ Estimate(s)** (*Tutorial and Model validation*)\n\n    Apply both the CBTL and ITCJ methods to the synthetic random comparison dataset;\n\n6. **Estimate(s) $\\rightarrow$ {Diagnostic, Post predictive}** (*Tutorial*)\n\n    Assess the quality of the models and estimate(s) in terms of stationarity, convergence, mixing, parameter recovery, in-sample predictive accuracy, and approximate out-of-sample fit;\n    \n7. **{Diagnostic, Post predictive} $\\rightarrow$ Estimator** (*Tutorial*)\n\n    Incrementally refine the statistical model repeating steps 3–6 until a *sufficiently trustworthy model* is obtained according to the criteria outlined in step 6;\n\n8. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Effects $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate the *estimate(s)* of interest for the synthetic random comparison dataset using both the CBTL and ITCJ analysis, and interpret the results;\n    \n9. **Estimator $\\rightarrow$ Estimate(s) $\\rightarrow$ Predictions $\\leftarrow$ Estimand(s)** (*Model validation*)\n\n    Generate predictions for the synthetic comparison dataset using both the CBTL and ITCJ analysis, and compare their in-sample predictive accuracy, and approximate out-of-sample fit.\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 4.1 From Theory to Design: Steps 1a-1c\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThe conceptual population simulation is based on the data characteristics and findings reported by Boonen et al. [@Boonen_et_al_2020]:\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the data characteristics, the study:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Includes multiple stimuli nested within multiple individuals,\n- Considers individuals with different characteristics (e.g., age, hearing status),\n- Assigns each judge to make only one comparison per stimulus pair,\n- Involves judges who differ in characteristics (e.g., experience level),\n- Selects stimuli, individuals, and judges using a (pseudo-)random sampling algorithm,\n- Involves multiple judges performing multiple comparisons, assigned through a random comparison algorithm.\n:::\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nRegarding the study findings, the study report that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Individuals with different hearing statuses differ in both their average latent trait levels and their **variability**,\n- There is more unexplained variability between individuals than within individuals (i.e., at the stimulus level),\n- No evidence of systematic judge bias was found (although it was not tested but treated as a model assumption),\n- Judges' experience levels did not account for differences in mean latent traits between stimuli, but differences in their **variabilities** were not assessed.\n:::\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nThus, adapting the general CJ structure proposed by Rivera et al.'s [@Rivera_et_al_2025] to the data characteristics reported by Boonen et al. [@Boonen_et_al_2020] leads to the following conceptual population data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj17 layout-ncol=2}\n\n![](/figures/population_summary/CJ_population_DAG.png){width=85%}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J} \\} \\\\\n  e_{I} & \\dsep \\{ e_{J} \\}\n\\end{aligned}\n$$\n\nCJ data-generating process for the conceptual population. *Left panel* shows the DAG. *Right panel * depicts the associated SCM.\n:::\n\n:::\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nMoreover, integrating the assumptions derived from Boonen et al. [@Boonen_et_al_2020] leads to the following statistical data-generating process:\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-cj18a layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(X_{I}, e_{I}) \\\\\n  B_{J} & := f_{B}(Z_{J}, e_{J}) \\\\ \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J} \\} \\\\\n  e_{I} & \\dsep \\{ e_{J} \\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{JK} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid X_{I}, e_{I} ) \\\\\n  & P( B_{J} \\mid Z_{J}, e_{J} ) \\\\ \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{JK}[j,k] \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XI} X_{I} + e_{I} \\\\\n  B_{J} & = \\beta_{ZJ} Z_{J} + e_{J} \\\\ \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nData-generating process for simulated CJ data. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n:::\n\n::: {.fragment}\nWith the following parameter assumptions:\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-cj18b layout-ncol=2 }\n\n$$\n\\begin{split}\nX_{I} &= \\{ X_{Ic}, X_{Id}[g=1], X_{Id}[g=2], X_{Id}[g=3] \\} \\\\\nZ_{J} &= \\{ Z_{Jd}[g=1], Z_{Jd}[g=2], Z_{Jd}[g=3] \\} \\\\\n\\beta_{XI} & = \\{ \\beta_{XIc}, \\beta_{XId[g=1]}, \\beta_{XId[g=2]}, \\beta_{XId[g=3]} \\} = \\{ 0.1, 1, 0, -1\\} \\\\\n\\beta_{ZJ} &= \\{ \\beta_{ZJd[g=1]}, \\beta_{ZJd[g=2]}, \\beta_{ZJd[g=3]} \\} = \\{ 0, 0, 0\\}\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{XI[g]} &= \\{ s_{XId[g=1]}, s_{XId[g=2]}, s_{XId[g=3]} \\} = \\{ 1.5, 0.75, 0.75\\} \\\\\ns_{ZJ} &= \\{ s_{ZJd[g=1]}, s_{ZJd[g=2]}, s_{ZJd[g=3]} \\} = \\{ 0.5, 1, 1.5\\} \\\\\ns_{A} &= 0.2 \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\quad \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{XI} & 0 & 0 \\\\\n    0 & s_{A} & 0 \\\\\n    0 & 0 & s_{ZJ} \n\\end{bmatrix}\n\\end{split}\n$$\n\nSimulating parameter assumptions.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {style=\"font-size:80%;\"}\n\nIn layman terms:\n\n::: incremental \n::: {style=\"font-size:60%;\"}\n- No stimuli characteristics $(X_{IA})$ are assumed to affect the comparisons;\n- Stimuli latent trait residual variability is smaller than average individual latent trait residual variability $(s_{A} = 0.2 < 1)$;\n- Individual characteristics $(X_{I})$ include a continuous variable $(X_{Ic})$ for the age of children, and a categorical variable with three levels representing hearing status groups: normal-hearing (NH, $X_{Id}[g=1]$), hearing-impaired with hearing aids (HI-HA, $X_{Id}[g=2]$), and hearing-impaired with cochlear implants (HI-CI, $X_{Id}[g=3]$) children;\n- There is a \"small\" [@Cohen_1988; @Sawilowsky_2009] but increasing effect of age $(\\beta_{XIc})$ on the mean latent trait of individuals;\n- There are \"very large\" [@Cohen_1988; @Sawilowsky_2009] differences in the mean latent trait across hearing status groups $(\\beta_{XId[g=1]} > \\beta_{XId[g=2]} > \\beta_{XId[g=3]})$;\n- Individual latent trait residual variability differs by groups, i.e., $s_{XId[g=1]} > s_{XId[g=2]} = s_{XId[g=3]}$, with $\\sum_{g=1}^{3} s_{XId[g]}/3 = 1$;\n- Judges make only one comparison; thus, there are no judgment-level characteristics $(Z_{JK})$, judgement-level effects $(\\beta_{ZJK})$, or residual judgment variability $(p_{JK})$;\n- Judges characteristics $(Z_{J})$ include a categorical variable with three levels representing judge groups: audiologist (AU, $Z_{Jd}[g=1]$), primary teachers (PT, $Z_{Jd}[g=2]$), and inexperienced listeners (IL, $Z_{Jd}[g=3]$);\n- Judges' mean latent biases across judge groups are equal to zero $(\\beta_{ZJd[g=1]}=\\beta_{ZJd[g=2]}=\\beta_{ZJd[g=3]}=0)$;\n- However, judges exhibit more or less bias depending on their experience, i.e., $(s_{ZJd[g=1]}=0.5) < (s_{ZJd[g=2]} = 1) < (s_{ZJd[g=3]} = 1.5)$, with $\\sum_{g=1}^{3} s_{ZJ[g]}/3 = 1$;\n- Residual latent errors $(\\boldsymbol{e})$ are centered around zero with zero correlation $(\\boldsymbol{\\mu}, \\boldsymbol{Q})$.\n:::\n:::\n\n\n---\n\n## 4.1 From Theory to Design: Steps 1a-1c {#sec-pop_sim style=\"font-size:80%;\"}\n\nFrom the simulation parameters, we can also define the **_estimands_** of interest:\n\n::: incremental \n::: {style=\"font-size:65%;\"}\n- The conditioned expected change in the individuals' mean latent trait for one additional year of age $(\\beta_{XIc})$;\n- The conditioned expected differences in mean latent traits between NH and HI-HA children $(\\beta_{XId[g=1]} - \\beta_{XId[g=2]})$, NH and HI-CI children $(\\beta_{XId[g=1]} - \\beta_{XId[g=3]})$, and HI-HA versus HI-CI children $(\\beta_{XId[g=2]} - \\beta_{XId[g=3]})$;\n- The conditioned expected differences in mean latent bias between AU and PT judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]})$, AU and IL judges $(\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]})$, and PT and IL judges $(\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]})$;\n- The latent trait residual variability of NH, HI-HA, and HI-CI children, i.e., $s_{XId[g=1]}$, $s_{XId[g=2]}$, and $s_{XId[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent trait between NH and HI-HA children $(s_{XId[g=1]} - s_{XId[g=2]})$, NH and HI-CI children $(s_{XId[g=1]} - s_{XId[g=3]})$, and HI-HA versus HI-CI children $(s_{XId[g=2]} - s_{XId[g=3]})$;\n- The latent bias residual variability of AU, PT, and IL judges, i.e., $s_{ZJd[g=1]}$, $s_{ZJd[g=2]}$, and $s_{ZJd[g=3]}$, respectively;\n- The conditioned expected differences in residual variability of the latent bias between AU and PT judges $(s_{ZJd[g=1]} - s_{ZJd[g=2]})$, AU and IL judges $(s_{ZJd[g=1]} - s_{ZJd[g=3]})$, and PT and IL judges $(s_{ZJd[g=2]} - s_{ZJd[g=3]})$;\n- The residual variability of the stimuli latent trait $(s_{A})$;\n- Latent traits $T_{IA}$, $T_{I}$, and $B_{J}$.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 4.2 From Design to Sample: Step 2\n\n---\n\n## 4.2 From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nWe generate a synthetic random sample and comparison datasets from the conceptual population in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms illustrated in @fig-cj17, sample size calculations were conducted (see @sec-AppA), and the following design was adopted:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- A sample of $54$ individuals, divided into three hearing status groups: $40$ NH $(X_{Id}[g=1])$, $7$ HI-HA $(X_{Id}[g=2])$, and $7$ HI-CI $(X_{Id}[g=3])$ children;\n- A sample of $10$ stimuli per individual;\n- A sample of $60$ judges, divided into three groups: $10$ AU $(Z_{Jd}[g=1])$, $10$ PT $(Z_{Jd}[g=2])$, and $40$ IL $(Z_{Jd}[g=3])$;\n- Judges conduct only one-comparison of the same stimulus pair (i.e., design is NOT a *repeated measures design* [@Lawson_2015, chap. 9.5])\n- Each stimulus is compared $20$ times in total against other stimuli, across all judges.\n:::\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 4.3 From Estimator and Sample to Estimate(s): The analysis approaches in step 5\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches in step 5 {style=\"font-size:80%;\"}\n\nThe study applies two data analysis approaches for the simulated CJ data (as described in @sec-approaches):\n\n::: incremental \n1. *The CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b],\n2. *The ITCJ analysis* [@Rivera_et_al_2025]\n:::\n\n:::{.fragment}\nBoth analysis are conducted using `R` version 4.2.2 [@R_2015], with:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Additional `R` packages for data manipulation and visualization: `tidyverse` [@Wickham_et_al_2019], `igraph` [@Csardi_et_al_2006; @Csardi_et_al_2025], and `RColorBrewer` [@Neuwirth_2022];\n- Specific user-defined functions (`UDFs`) to facilitate data manipulation, visualization, model summarization, diagnostics, and prediction from the approaches (all are provided in the main document).\n:::\n:::\n:::\n\n---\n\n## 4.3 From Estimator and Sample to Estimate(s): The analysis approaches in step 5 {style=\"font-size:80%;\"}\n\nNotably, **each** `brms` multilevel regression model within the *CBTL analysis* and **each** Bayesian model within the *ITCJ analysis* were estimated using:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- **Four** Markov chains of $4000$ iterations, each with distinct starting values, where the first $2000$ iterations served as warm-up, and the remaining $2000$ were used as posterior samples (for a total of $8000$ posterior samples).\n::: \n:::\n\n\n# 4.3.1 From Estimator and Sample to Estimate(s): The CBTL analysis in step 5\n\n---\n\n## 4.3.1 From Estimator and Sample to Estimate(s): The CBTL analysis in step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **Fits a BTL model** using the `BTm()` function from the `BradleyTerry2` package [@Turner_et_al_2012a; @Turner_et_al_2012b],\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the traits of the stimuli $(\\text{ability}_{i,a})$\n- To generate the model residuals $(\\text{res}_{j,a,b})$ and conduct *misfit* analysis.\n:::\n:::\n\n2. **Fits a multilevel regression** on the residuals using the `brms` package [@Burkner_2017; @Burkner_2018],\n    \n    $\\text{res}_{j,a,b} \\sim -1 + ZJd + (1 | Js)$\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To test hypothesis of differences in mean residuals between groups of judges, i.e., $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=2]}$, $\\beta_{ZJd[g=1]} - \\beta_{ZJd[g=3]}$, and $\\beta_{ZJd[g=2]} - \\beta_{ZJd[g=3]}$;\n- To assess the variability within- and between-judges $(1 | Js)$, where the former has **no direct equivalent parameter**, while latter corresponds to $s_{ZJ}$$^{*}$.\n- To aggregate model residuals into judges biases $(B_{J})$ \n:::\n:::\n\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for judges, i.e., $s_{ZJ}$, versus multiple variability parameters defined by the experience of the judges, i.e., $s_{ZJd}$.\n:::\n\n---\n\n## 4.3.1 From Estimator and Sample to Estimate(s): The CBTL analysis in step 5 {style=\"font-size:80%;\"}\n\nSpecifically, the *CBTL analysis* [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023; @Thwaites_et_al_2024]:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **Fits a multilevel regression** on the stimulus' trait estimates with the `brms` package [@Burkner_2017; @Burkner_2018], \n    \n    $\\text{ability}_{i,a} \\sim -1 + XIc + XId + (1 | Is)$\n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- To estimate the effect of age on the mean latent trait, i.e, $\\beta_{XIc}$\n- To test hypothesis of differences in mean latent traits between groups of children, i.e., $\\beta_{XId[g=1]} - \\beta_{XId[g=2]}$, $\\beta_{XId[g=1]} - \\beta_{XId[g=3]}$, and  $\\beta_{XId[g=2]} - \\beta_{XId[g=3]}$\n- To assess the variability within and between children $(1 | Is)$, corresponding to the parameters $s_{A}$ and $s_{XI}$$^{*}$, respectively\n- To aggregate stimuli traits into individual level $(T_{I})$ \n:::\n:::\n\n:::\n:::\n\n::: {.fragment}\nPrior selection for the multilevel regression models in Steps $2$ and $3$ relied on **prior predictive checks**, the results of which are presented in @sec-results.\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ By model assumptions, the CBTL analysis only considers one variability parameter for individuals, i.e., $s_{XI}$, versus multiple variability parameters defined by the individuals' groups, i.e., $s_{XId}$. \n:::\n\n# 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models style=\"font-size:80%;\"}\n\nIn contrast, the *ITCJ analysis* [@Rivera_et_al_2025], fits six $(6)$ increasingly complex CJ models, using:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- `Stan` version 2.26.1 [@Stan_2020] with its interface package `cmdstanr` [@Gabry_et_al_2025],\n- Additional `R` packages for model summaries, predictions, and diagnostics: `loo` [@Vehtari_et_al_2024b], `posterior` [@Burkner_et_al_2024], and `bayesplot` [@Gabry_et_al_2019; @Gabry_et_al_2025].\n:::\n:::\n\n::: {.fragment}\nSimilarly, prior selection for the six ITCJ models relied on **prior predictive checks**, the results of which are presented in @sec-results.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models1 style=\"font-size:80%;\"}\n\nThe **first model** only considers the stimulus' traits$^{*}$. \n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj41 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(e_{IA}) \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid e_{IA} ) \\\\\n  & P( e_{IA} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = e_{IA} \\\\\n  e_{IA} & \\sim \\text{Normal}( 0, s_{A} )\n\\end{aligned}\n$$\n\nFirst ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n$$\n\\begin{split}\ns_{A} & \\sim \\text{Exponential}( 1/5 )\n\\end{split}\n$$\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to Step $1$ of the *CBTL analysis*, but with a different prior.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models2 style=\"font-size:80%;\"}\n\nBuilding on the first, the **second model** integrates the *hierarchical structural component* that captures the nesting structure of stimulus within individuals$^{*}$.\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj42 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(e_{I}) \\\\\n  e_{IA} & \\dsep e_{I}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid e_{I} ) \\\\\n  & P( e_{IA} ) P( e_{I} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nSecond ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1\n\\end{bmatrix}\n\\end{split}\n$$\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, without covariates for the individuals.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models3 style=\"font-size:80%;\"}\n\nExtending the second, the **third model** integrates covariates into the *structural component* to account for factors that may affect individual traits$^{*}$. \n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj43 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(XI, e_{I}) \\\\\n  e_{IA} & \\dsep e_{I}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid XI, e_{I} ) \\\\\n  & P( e_{IA} ) P( e_{I} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nThird ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n::: {layout-ncol=2}\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1 \n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, with covariates for the individuals.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models4 style=\"font-size:80%;\"}\n\nAlso building upon the second, but in contrast to the third, the **fourth model** only incorporates judges' biases$^{*}$.\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj44 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{J}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(e_{I}) \\\\\n  B_{J} & := f_{B}(e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA}, B_{J} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid e_{I} ) \\\\\n  & P( B_{J} \\mid e_{J} ) \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) + B_{J}[j]\\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = e_{I} \\\\\n  B_{J} & = e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nFourth ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, without any covariates for individuals or judges. However, technically this is **no** longer a BTL model.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models5 style=\"font-size:80%;\"}\n\nCombining the 3rd and 4th, the **fifth model** integrates covariates to account for factors that may affect individual traits and judge biases$^{*}$:\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj45 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(XI, e_{I}) \\\\\n  B_{J} & := f_{B}(ZJ, e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid XI, e_{I} ) \\\\\n  & P( B_{J} \\mid ZJ, e_{J} ) \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nFifth ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n::: {layout-ncol=2}\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\\n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3); \\\\\n\\end{split}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n\n:::\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, with covariates for individuals and judges. However, this is **no** longer a BTL model.\n:::\n\n---\n\n## 4.3.2 From Estimator and Sample to Estimate(s): The ITCJ analysis in step 5 {#sec-ITCJ_models6 style=\"font-size:80%;\"}\n\nLastly, building upon the fifth, the **sixth model** accounts for differences in the variability of individual traits and judge biases$^{*}$,\n\n::: {.fragment style=\"font-size:90%;\"}\n\n::: {#fig-cj45 layout-ncol=3}\n\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(XI, e_{I}) \\\\\n  B_{J} & := f_{B}(ZJ, e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  & P( O_{R} \\mid D_{R}, S, C ) \\\\\n  & P( D_{R} \\mid T_{IA} ) \\\\\n  & P( T_{IA} \\mid T_{I}, e_{IA} ) \\\\\n  & P( T_{I} \\mid XI, e_{I} ) \\\\\n  & P( B_{J} \\mid ZJ, e_{J} ) \\\\\n  & P( e_{IA} ) P( e_{I} ) P( e_{J} )\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\nSixth ITCJ model. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.\n:::\n\n::: {layout-ncol=2}\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3);\n\\end{split}\n$$\n\n$$\n\\begin{split}\nhs_{I} &\\sim \\text{Dirichlet}(5, GI) \\; \\rightarrow \\; s_{XI} = GI \\cdot hs_{I}; \\\\\nhs_{J} &\\sim \\text{Dirichlet}(5, GJ); \\; \\rightarrow \\; s_{ZJ} = GJ \\cdot hs_{I}; \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix}; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0      & 0 \\\\\n    0     & s_{XI} & 0 \\\\\n    0     & 0      & s_{ZJ}\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ There is no equivalent in the CJ literature.\n:::\n\n<!-- ######################################### -->\n\n# 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. **_Stationarity, convergence, and mixing_** (for `brms` and Bayesian models only), using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Graphical analyses, including trace plots, rank-normalized trace plots, autocorrelation function (ACF) plots, and comparison plots of prior to posterior distributions,\n- Diagnostic statistics, including the potential scale reduction factor statistics $(\\hat{R})$ with a cut-off value of $1.05$ [@Vehtari_et_al_2021a] and effective sample size statistics $(n_{\\text{eff}})$ [@Gelman_et_al_2014].\n:::\n:::\n\n2. **_Parameter recovery_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The graphical comparisons of \"true\" parameters values versus posterior estimates,\n- The parameter posterior Root Mean Squared Error $(\\text{RMSE})$, defined as follows:\n:::\n:::\n    \n:::\n:::\n\n::: {.fragment}\n$$\n\\text{RMSE}( \\boldsymbol{\\hat{\\theta}}, \\theta) = \\sqrt{ \\frac{1}{S} \\sum_{s=1}^{S} ( \\hat{\\theta}_{s} - \\theta )^2 }\n$$\n:::\n\n::: {.fragment style=\"font-size:64%;\"}\nwhere $\\boldsymbol{\\hat{\\theta}}$ is the vector of posterior samples associated with the \"true\" parameter $\\theta$, and $\\hat{\\theta}_{s}$ is the $s$-th sample out of a total of $S$ posterior draws.\n:::\n\n---\n\n## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style=\"font-size:80%;\"}\n\nThe study assess the quality of the models and estimate(s) in terms of:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. **_In-sample predictive accuracy_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Confusion matrix comparing expected posterior predictions $E(\\boldsymbol{\\hat{y}})$ with observed outcomes $\\boldsymbol{y}$ from the **first** synthetic dataset, aggregated and non-aggregated across stimuli and individuals.\n- Multiple confusion matrices comparing posterior samples $\\boldsymbol{\\hat{y}}_{s}$ with observed outcomes $\\boldsymbol{y}$ from the **first** synthetic dataset, aggregated and non-aggregated across stimuli and individuals.\n:::\n:::\n\n4. **_Approximate out-of-sample fit_**, using\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The Pareto Smoothing Importance Sampling criterion $(\\text{PSIS})$ [@Vehtari_et_al_2017; @Vehtari_et_al_2024a].\n:::\n:::\n\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5. Results {#sec-results}\n\n---\n\n## 5. Results {style=\"font-size:80%;\"}\n\nIn this section, the study will:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Describe the synthetic random comparison dataset;\n2. Progress through the steps $3-7$ of the Bayesian (research) workflow, described in @sec-methods, using:\n\n::: incremental \n- The *CBTL analysis*, and \n- The *ITCJ analysis*\n:::\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5.1 Data description\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of design, the dataset reveals that:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most stimuli were compared $20$ times; only two stimuli (IDs $2$ and $3$) from individual $58$ were compared slightly fewer times due to random variation.\n- The stimuli comparison network indicates a random *balanced design* [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_comparisons layout-ncol=2}\n![](/figures/data_summary/stimuli_comparisons_bottom.png){width=60%}\n\n![](/figures/data_summary/stimuli_network.png){width=60%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals $(Is)$ and stimuli $(As)$. *Right panel* shows the stimuli comparison network.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nIn a similar manner, the data indicates:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Most individuals were compared $200$ times ($20$ comparisons × $10$ stimuli each); only one individual (ID $58$) was compared slightly fewer times due to random design variation;\n- The connected component analysis [@Betancourt_2024] and individual comparison network indicates a fully connected network and a *balanced design* for individuals [@Lawson_2015, chap. 7.4].\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_comparisons layout-ncol=2}\n\n![](/figures/data_summary/individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/individual_network.png){width=55%}\n\nComparison design. *Left panel* shows the number of comparisons for individuals. *Right panel* shows the individual comparison network.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nOn the other hand, the dataset shows:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges compare individuals with frequencies ranging from $0$ to $13$ comparisons;\n- Most judges completed $262$ comparisons, while a few completed $264$ due to random design variation.\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_comparisons layout-ncol=2}\n![](/figures/data_summary/judges2individuals_comparisons.png){width=60%}\n\n![](/figures/data_summary/judges_comparisons.png){width=90%}\n\nComparison design. *Left panel* shows the judges $(Js)$ versus the first $10$ individuals $(Is)$. *Right panel* shows the total number of judges' comparisons.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nMoreover,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges to individual comparison network indicates a fully connected network\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_individuals_comparisons}\n![](/figures/data_summary/judges_individuals_network.png){width=100%}\n\nBipartite graph of judges to individual comparison network.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nIn terms of the comparison outcomes, we see some stimuli with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/stimuli_wins.png){width=70%}\n\nStimuli win rates.\n:::\n:::\n\n:::{.notes}\n- One stimulus has win almost all comparisons, $\\text{IA}[6,7]$\n- Two stimuli has loss all comparisons, $\\text{IA}[5,2]$ and $\\text{IA}[45,3]$\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nAggregated by individuals, we see some individuals with higher win rates than others:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins.png){width=70%}\n\nIndividual win rates.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nDivided by hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- It is harder to see average differences between the groups,\n- However, we can easily notice the different variability between them\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_wins_groups.png){width=100%}\n\nIndividual win rates per group. *Left panel* describe NH children. *Middle panel* describe HI-HA children. *Right panel* illustrate HI-CI children.\n:::\n:::\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nHowever, no apparent relationship transpire between individual wins and age:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc.png){width=70%}\n\nIndividual win rates versus age.\n:::\n:::\n\n\n---\n\n## 5.1 Data description {style=\"font-size:80%;\"}\n\nConsidering the interaction of age and hearing status groups, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- We notice a slightly decreasing trend in HI-HA and HI-CI children, indicating that in those groups, older children are less likely to win in a comparison, but the results are not *unambiguous* (*Simpson's, Berkson's or another paradox*?).\n:::\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-stimuli_wins}\n![](/figures/data_summary/individual_winsVSXIc_groups.png){width=100%}\n\nIndividual win rates.\n:::\n:::\n\n<!-- ######################################### -->\n\n# 5.2 Data modeling\n\n# 5.2.1 Data modeling: The CBTL analysis\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nFirst, the BTL model is applied to the data to estimate the stimuli traits.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe initial model fit indicates that,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The BTL model struggles to accurately estimate traits for certain **'extreme' stimuli**,\n- It recovers the stimuli traits **reasonably well**, though with some downward bias,\n- The purpose and diagnostic value of the *misfit* analysis **remain unclear**.\n:::\n:::\n\n::: {#fig-CBTL_stimuli_trait1_2}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_stimuli_trait_comparison_plot1_2.png){width=50%}\n\n\n*CBTL analysis*, first BTL model fit. *Left panel* shows the trait estimates for all stimuli. *Right panel* shows the trait estimates for non-extreme stimuli.\n:::\n\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThe purpose and diagnostic value of the *misfit* analysis **remain unclear**:\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-data_preference}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_preference_order.png){width=70%}\n\n\nStimuli \"Preference\" Analysis, identifying comparative wins and losses. *Blue circles* represent wins, *red X's* indicate losses. The diagonal line maps cases where the same stimulus appears on both the x- and y-axes. Stimuli are ordered from best (top) to worst (bottom) performing stimuli based on its true trait value.\n:::\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **multilevel regression** on the residuals (Step $2$) has the following specification,\n$$\n\\begin{split}\nbrm(& \\; \\text{data} \\; &= & d, \\\\\n& \\; \\text{family} \\; &= & gaussian, \\\\\n& \\; \\text{formula} \\; &= & res ~ -1 + ZJd + (1 | Js), \\\\\n& \\; \\text{prior} \\; &= c(& \\; \\text{prior}( \\; normal(0, 0.3), \\text{class}=b, \\text{coef}=ZJd1 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.3), \\text{class}=b, \\text{coef}=ZJd2 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.3), \\text{class}=b, \\text{coef}=ZJd3 ), \\\\\n& & & \\; \\text{prior}( \\; exponential(50), \\text{class}=sd ), \\\\ \n& & & \\; \\text{prior}( \\; exponential(25), \\text{class}=sigma )\n\\end{split}\n$$\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Judges' mean latent biases across groups are assigned **weakly informative priors**, reflecting no directional preference in group-level means, i.e., $\\beta_{ZJd[g=1]} = \\beta_{ZJd[g=2]} = \\beta_{ZJd[g=3]} \\sim normal(0, 0.3)$,\n- Due to the $[-1,1]$ range in the residuals [@Pollitt_2012a, pp. 164; @Pollitt_2012b, pp. 289], the between-judge residual variability $(sd)$ is assigned a **highly informative exponential prior** with an average of $\\lambda_{1}^{-1}=50^{-1}$ and a variance of $\\lambda_{1}^{-2}=50^{-2}$. This reflects the **strong belief** in the absence of systematic judges biases,\n- For similar reasons, the within-judge residual variability $(sigma)$ is assigned a **highly informative exponential prior** with an average of $\\lambda_{2}^{-1}=25^{-1}$ and a variance of $\\lambda_{2}^{-2}=25^{-2}$. This reflects the expectation of a greater (though still narrow) unexplained residual variability unrelated to systematic judge biases, i.e., $\\lambda_{1}^{-1} < \\lambda_{2}^{-1}$\n:::\n:::\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-CBTL_judge_prior}\n\n![](/figures/CBTL_analysis/cropped/3_1_CBTL_judge_trait_prior1.png){width=50%}\n\n*CBTL analysis*, prior predictive check for multilevel regression model on the residuals.\n:::\n\n:::\n\n::: {.notes}\n- Predictions still extend beyond the observed data range, despite the **highly informative priors** for the between-judge $(sd)$ and within-judge $(sigma)$ residual variability.\n- Although **more informative priors** could constrain the range even more, the current priors are sufficient given the size of the residuals data, that is, the data will overcome the priors.\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nAfter testing four prior specifications, the **multilevel regression** for stimuli traits (Step $3$) follows,\n$$\n\\begin{split}\nbrm(& \\; \\text{data} \\; &= & d, \\\\\n& \\; \\text{family} \\; &= & gaussian, \\\\\n& \\; \\text{formula} \\; &= & ability ~ -1 + XIc + XId + (1 | Is), \\\\\n& \\; \\text{prior} \\; &= c(& \\; \\text{prior}( \\; normal(0, 0.05), \\text{class}=b, \\text{coef}=XIc ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.5), \\text{class}=b, \\text{coef}=XId1 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.5), \\text{class}=b, \\text{coef}=XId2 ), \\\\\n& & & \\; \\text{prior}( \\; normal(0, 0.5), \\text{class}=b, \\text{coef}=XId3 ), \\\\\n& & & \\; \\text{prior}( \\; exponential(1), \\text{class}=sd ), \\\\ \n& & & \\; \\text{prior}( \\; exponential(5), \\text{class}=sigma )\n\\end{split}\n$$\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- **No directional preference** is assumed for the effects of age and hearing status on individuals’ mean latent traits; thus, weakly informative priors are set for $\\beta_{XIc}$ and $\\beta_{ZJd[g=1]} = \\beta_{ZJd[g=2]} = \\beta_{ZJd[g=3]}$,\n- Between-individual residual variability $(sd)$ is assigned a **weakly informative exponential prior** with an average of $\\lambda_{1}^{-1}=1$ and a variance of $\\lambda_{1}^{-1}=1$. This reflects the **mild belief** that individuals systematic variability is 'around' one,\n- Within-individual (between-stimuli) residual variability $(sigma)$ is assigned a **weakly informative exponential prior** with an average of $\\lambda_{2}^{-1}=5^{-1}$ and a variance of $\\lambda_{2}^{-2}=5^{-2}$. This reflects the expectation of less between-stimuli versus between-individuals variability, i.e., $\\lambda_{1}^{-1} > \\lambda_{2}^{-1}$\n:::\n:::\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nBefore proceeding to Steps $2$ and $3$, we need specify the appropriate **priors**:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-CBTL_individual_prior}\n![](/figures/CBTL_analysis/cropped/3_1_CBTL_stimuli_trait_prior2.png){width=50%}\n\n*CBTL analysis*, prior predictive check for multilevel regression model on the estimated stimuli traits.\n:::\n\n:::\n\n::: {.notes}\n- Predictions capture the most likely range of the data, without trying to accommodate the 'extreme' estimates.\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-CBTL_diagnostics layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_individual_parameters_trace.png){width=100%}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_individual_parameters_rank.png){width=100%}\n\n*CBTL analysis*, example of multilevel regression parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are in the vicinity of $1$, and none is above $1.05$\n- Only $bZJd[3]$ has a $n_{eff} < 1000$, the rest have $n_{eff} > 1300$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-CBTL_recovery1}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery1.png){width=50%}\n\n*CBTL analysis*, parameter recovery for all steps. *Top right panel* include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n::: {.notes}\n- Extreme stimuli traits does not allow to see the trend of recovery\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-CBTL_recovery2}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=50%}\n\n*CBTL analysis*, parameter recovery for all steps. *Top right panel* does not include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n::: {.notes}\n- Individual traits are biased\n- Almost no recovery of judges biases\n- Not so good estimation for betas and sigmas\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-CBTL_rmse1}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse1.png){width=50%}\n\n*CBTL analysis*, RMSE for all steps. *Top right panel* include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nSecond, we use the refitted BTL model (without *misfits*) and the specified priors to fit the models in Steps $2$ and $3$, completing the *CBTL analysis*.\n\n::: {style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n:::\n\n::: {style=\"font-size:80%;\"}\n\n::: {#fig-CBTL_rmse2}\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=50%}\n\n*CBTL analysis*, RMSE for all steps. *Top right panel* include the 'extreme' estimates for the stimuli traits. \n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-CBTL_posterior_pred1}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=50%}\n\n*CBTL analysis*, posterior predictive for confusion matrix based only on Step $1$. Posterior simulations assume normality of stimuli traits by Central Limit Theorem (CLT).\n:::\n\n:::\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-CBTL_posterior_pred2}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=50%}\n\n*CBTL analysis*, posterior predictive for stimuli wins based only on Step $1$. Posterior simulations assume normality of stimuli traits by Central Limit Theorem (CLT).\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-CBTL_posterior_pred3}\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=50%}\n\n*CBTL analysis*, posterior predictive for individual wins based only on Step $1$. Posterior simulations assume normality of stimuli traits by Central Limit Theorem (CLT).\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.1 Data modeling: The CBTL analysis {style=\"font-size:80%;\"}\n\nFourth, we check if the models still shows signs of 'trouble'.\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-CBTL_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_judges_influential.png){width=70%}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=70%}\n\n*CBTL analysis*, influential points based on Steps $2$ and $3$. *Left panel* shows the points identified in the residuals analysis. *Right panel* shows the points identified in the stimuli traits analysis.\n:::\n\n:::\n\n::: {.notes}\n- On a second misfit identification, no misfit stimuli is in the group of influential points\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2 Data modeling: The ITCJ analyses \n\n# 5.2.2.1 Data modeling: The ITCJ analysis 1 \n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models1, the **first** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = e_{IA} \\\\\n  e_{IA} & \\sim \\text{Normal}( 0, s_{A} )\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\ns_{A} & \\sim \\text{Exponential}( 1/5 )\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The between-stimuli variability $(s_{A})$ is assigned a **non-informative exponential prior** with an average of $\\lambda^{-1}=5$ and a variance of $\\lambda^{-2}=5^{2}$. This reflects the lack of any expectation regarding the between-stimuli variability.\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to Step $1$ of the *CBTL analysis*, but with a different prior.\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ1_priors layout-ncol=2 loyout-nrow=2}\n\n![](/figures/ITCJ_analysis/cropped/4_1_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_1_ITCJ_prior_individual.png){width=75%}\n\nFirst *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nSecond, we fit the **first** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ1_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_stimuli_trait_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_stimuli_trait_rank.png){width=100%}\n\nFirst *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nSecond, we fit the **first** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ1_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the first *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nSecond, we fit the **first** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ1_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_1_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the first *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ1_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ1_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.1.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ1_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.1.2.1 Data modeling: The ITCJ analysis 1 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ1_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_1_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the first *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.2 Data modeling: The ITCJ analysis 2\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models2, the **second** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Between-individual variability is assumed to be equal to $1$. Thus, the prior distribution is used to define the scale of individual latent traits, as it is required in latent variable models [@Depaoli_2021].\n- The within-individual (between-stimuli) variability $(s_{A})$ is assigned a **weakly informative Beta-proportion prior** with an average of $\\mu=0.5$ and a 'sample size' of $M=5$. This reflects the expectation that the stimuli are more homogeneous than the individuals [@Lawson_2015].\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, without covariates for the individuals.\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n\n![](/figures/ITCJ_analysis/cropped/4_2_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_1_ITCJ_prior_individual.png){width=75%}\n\nSecond *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_individual_trait_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_individual_trait_rank.png){width=100%}\n\nSecond *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the second *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_2_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the second *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.2 Data modeling: The ITCJ analysis 2 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_2_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the second *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.3 Data modeling: The ITCJ analysis 3\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models3, the **third** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0  \\\\\n    0     & 1 \n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The effects of age and the hearing status groups on the mean latent trait of individuals has the same **weakly informative prior** as in the *CBTL analysis*,\n- Between- and within-individual (between-stimuli) variability has the same prior as the previous ITCJ model.\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of Steps $1$ and $3$ from the *CBTL analysis*, with covariates for the individuals.\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n![](/figures/ITCJ_analysis/cropped/4_3_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_1_ITCJ_prior_individual.png){width=75%}\n\nThird *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_betas_sigmas_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_betas_sigmas__rank.png){width=100%}\n\nThird *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nSecond, we fit the **third** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the third *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nSecond, we fit the **third** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_3_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the third *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.3 Data modeling: The ITCJ analysis 3 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_3_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the third *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.4 Data modeling: The ITCJ analysis 4\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models4, the **fourth** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & := f_{O}(D_{R}, S, C) \\\\\n  D_{R} & := f_{D}(T_{IA}, B_{J}) \\\\\n  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\\\\n  T_{I} & := f_{T}(e_{I}) \\\\\n  B_{J} & := f_{B}(e_{J}) \\\\\n  e_{IA} & \\dsep \\{ e_{I}, e_{J}\\} \\\\\n  e_{I} & \\dsep \\{ e_{J}\\}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\; \n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Between- and within-individual (between-stimuli) variability has the same prior as the previous ITCJ models,\n- Between-judge variability is assumed to be equal to $1$. Thus, the prior distribution is used to define the scale of judges latent biases, as it is required in latent variable models [@Depaoli_2021].\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, without any covariates for individuals or judges. However, technically this is **no** longer a BTL model.\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n![](/figures/ITCJ_analysis/cropped/4_4_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_1_ITCJ_prior_individual.png){width=75%}\n\nFourth *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_judge_bias_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_judge_bias_rank.png){width=100%}\n\nFourth *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fourth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fourth *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fourth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_4_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.4 Data modeling: The ITCJ analysis 4 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_4_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the fourth *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.5 Data modeling: The ITCJ analysis 5\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models5, the **fifth** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\\n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3); \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix} ; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0 & 0 \\\\\n    0     & 1 & 0 \\\\\n    0     & 0 & 1\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The effects of age and the hearing status groups on the mean latent trait of individuals has the same **weakly informative prior** as in the *CBTL analysis*,\n- The effects of judges groups on the mean latent bias has the same **weakly informative prior** as in the *CBTL analysis*,\n- Between- and within-individual (between-stimuli) variability has the same prior as the previous ITCJ models,\n- Between-judge variability has the same prior as the previous ITCJ models.\n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model is akin to the combination of all three steps from the *CBTL analysis*, with covariates for individuals and judges. However, this is **no** longer a BTL model.\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n![](/figures/ITCJ_analysis/cropped/4_5_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_1_ITCJ_prior_individual.png){width=75%}\n\nFifth *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_betas_sigmas_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_betas_sigmas__rank){width=100%}\n\nFifth *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fifth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fifth *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nSecond, we fit the **fifth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_5_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.5 Data modeling: The ITCJ analysis 5 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_5_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the fifth *ITCJ analysis*.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n# 5.2.2.6 Data modeling: The ITCJ analysis 6\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs seen in @sec-ITCJ_models6, the **sixth** ITCJ model is represented by,\n\n::: {layout-ncol=2}\n$$\n\\begin{aligned}\n  O_{R} & \\overset{iid}{\\sim} \\text{Bernoulli} \\left[ \\text{inv_logit}( D_{R} ) \\right] \\\\\n  D_{R} & = \\left( T_{IA}[i,a] - T_{IA}[h,b] \\right) \\\\\n  T_{IA} & = T_{I} + e_{IA} \\\\\n  T_{I} & = \\beta_{XIc} XIc + \\beta_{XId}[XId] + e_{I} \\\\\n  B_{J} & = \\beta_{ZJd}[ZJd] + e_{J} \\\\\n  \\boldsymbol{e} & \\sim \\text{Multi-Normal}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )\n  \\\\\n  \\boldsymbol{\\Sigma} &= \\boldsymbol{V} \\boldsymbol{Q} \\boldsymbol{V}\n\\end{aligned}\n$$\n\n$$\n\\begin{split}\n\\beta_{XIc} &\\sim \\text{Normal}(0, 0.05); \\\\ \n\\beta_{XId}[GI] &\\sim \\text{Normal}(0, 0.5); \\\\ \n\\beta_{ZJd}[GJ] &\\sim \\text{Normal}(0, 0.3); \\\\\nhs_{I} &\\sim \\text{Dirichlet}(5, GI) \\; \\rightarrow \\; s_{XI} = GI \\cdot hs_{I}; \\\\\nhs_{J} &\\sim \\text{Dirichlet}(5, GJ); \\; \\rightarrow \\; s_{ZJ} = GJ \\cdot hs_{I}; \\\\\ns_{A} &\\sim \\text{Beta_proportion}(0.5, 5); \\\\\n\\boldsymbol{\\mu} &= [0, 0, 0]^{T}; \\;\n\\boldsymbol{Q} = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n\\end{bmatrix}; \\;\n\\boldsymbol{V} = \\begin{bmatrix}\n    s_{A} & 0      & 0 \\\\\n    0     & s_{XI} & 0 \\\\\n    0     & 0      & s_{ZJ}\n\\end{bmatrix}\n\\end{split}\n$$\n:::\n\n:::\n\n::: {.fragment style=\"font-size:80%;\"}\nAssumptions:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The effects of age and the hearing status groups on the mean latent trait of individuals has the same **weakly informative prior** as in the *CBTL analysis*,\n- The effects of judges groups on the mean latent bias has the same **weakly informative prior** as in the *CBTL analysis*,\n- Within-individual (between-stimuli) variability has the same prior as the previous ITCJ models.\n- Between-individual and between-judges variability are now constraint to add to one (i.e., a simplex) across hearing status and judges groups, respectively. This requirement is enforced through a *weakly informative Dirichlet prior*. \n:::\n:::\n:::\n\n:::{.fragment style=\"font-size:60%; color:gray\"}\n$*$ This model has no equivalent in the current CJ literature.\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nFirst, we need specify the appropriate **priors** for the model:\n\n::: {.fragment style=\"font-size:80%;\"}\nAs a result of the prior assumptions, the **prior predictive check** shows that:\n\n::: {#fig-ITCJ2_priors layout-ncol=2 loyout-nrow=2}\n\n![](/figures/ITCJ_analysis/cropped/4_6_1_ITCJ_prior_confusion.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_1_ITCJ_prior_stimulus.png){width=75%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_1_ITCJ_prior_individual.png){width=75%}\n\nSixth *ITCJ analysis*, prior predictive checks.\n:::\n\n:::\n\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nSecond, we fit the **second** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **diagnostic statistics and plots** indicate that,\n\n::: {#fig-ITCJ2_diagnostics layout-ncol=2}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_betas_sigmas_trace.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_betas_sigmas__rank){width=100%}\n\nSixth *ITCJ analysis*, example of parameter diagnostics. *Leftmost six panels* show the trace plots. *Rightmost six panels* show the trace rank plots.\n:::\n\n:::\n\n::: {.notes}\n- All $\\hat{R}$ are equal to $1$, and none is above $1.05$\n- Only $s_{A}$ has a $n_{eff} \\approx 3000$, the rest have $n_{eff} > 10000$\n- There is sufficient information in the posterior distributions\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nSecond, we fit the **sixth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **parameter recovery plots** indicates that, \n\n::: {#fig-ITCJ2_recovery layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_recovery2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_ITCJ_parameter_recovery.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, parameter recovery. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the sixth *ITCJ analysis*. \n:::\n\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nSecond, we fit the **sixth** ITCJ model to the data using the specified priors.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **RMSE plots** indicates that, \n\n::: {#fig-ITCJ2_rmse layout-ncol=2}\n\n![](/figures/CBTL_analysis/non-cropped/3_2_CBTL_parameter_rmse2.png){width=100%}\n\n![](/figures/ITCJ_analysis/non-cropped/4_6_2_ITCJ_parameter_rmse.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, RMSE. *Leftmost four panels* show the *CBTL analysis*. *Top right panel* of *CBTL analysis* exclude the 'extreme' estimates for the stimuli traits. *Rightmost two panels* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {.fragment style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred1 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_confusion.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_posterior_confusion.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for confusion matrix. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred2 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_stimulus.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_posterior_stimulus.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for stimuli wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nThird, we assess the in-sample predictive accuracy of the model.\n\n::: {style=\"font-size:80%;\"}\nThe **posterior predictive plots** indicates that, \n\n::: {#fig-ITCJ2_posterior_pred3 layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_posterior_individual.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_posterior_individual.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, posterior predictive for individual wins. *Left panel* show the *CBTL analysis*, which assumes normality of stimuli traits by Central Limit Theorem (CLT). *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n::: {.notes}\n- This can only be understood comparatively\n:::\n\n\n---\n\n## 5.2.2.6 Data modeling: The ITCJ analysis 6 {style=\"font-size:80%;\"}\n\nFourth, we check if the model still shows signs of 'trouble'\n\n::: {style=\"font-size:80%;\"}\nThe **influential points plots** indicates that, \n\n::: {#fig-ITCJ2_influential layout-ncol=2}\n\n![](/figures/CBTL_analysis/cropped/3_2_CBTL_individual_influential.png){width=100%}\n\n![](/figures/ITCJ_analysis/cropped/4_6_2_ITCJ_individual_influential.png){width=100%}\n\n*ITCJ* versus *CBTL* analysis, influential points. *Left panel* shows the points identified in the *CBTL* stimuli traits analysis. *Right panel* show the sixth *ITCJ analysis*.\n:::\n\n:::\n\n<!-- ######################################### -->\n\n# 5.3 Model comparison\n\n--- \n\n## 5.3 Model comparison {style=\"font-size:80%;\"}\n\nFinally, we compare the approximate out-of-sample fit for all *ITCJ models*.\n\n::: {style=\"font-size:80%;\"}\nThe **approximate out-of-sample fit comparison** indicates that, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- There is a clear difference in between ITCJ models $1-3$ (Bayesian *equivalent* of the BTL model) and ITCJ models $4-6$, which account for judges' biases, even considering the parameter penalty!,\n- ITCJ model $4$ and $5$ show similar performance, this implies that adding covariates to model $4$ (model $5$) does not substantially improves its approximate out-of-sample fit,\n- ITCJ model $6$ has the best relative approximate out-of-sample fit.\n:::\n:::\n\n::: {#fig-model_comparison}\n\n![](/figures/ITCJ_analysis/cropped/5_ITCJ_model_comparison.png){width=70%}\n\n*ITCJ analysis*, model comparison. *Left panel* shows all models. *Right panel* shows a smaller set of models.\n:::\n:::\n\n---\n\n## 5.3 Model comparison {style=\"font-size:80%;\"}\n\n```{r}\n#| echo: false\n#| output: false\nlibrerias = c('tidyverse','gt')\nsapply(librerias, require, character.only=T)\n\ndir = '/home/josema/Desktop/1. Work/1 research/PhD Antwerp/#thesis/paper3/paper3_presentation'\n\nvar_int = c('variable','value','mean','median','sd','q5','q95','rmse') \n# ROPE_lower, ROPE_upper, ROPE_prec\n```\n\nAlso, we compare and interpret the parameter estimates: \n\n```{r}\n#| echo: false\n#| output: false\nparam_CBTL = read.csv( \n  file = file.path( dir,'summaries','3_2_CBTL_estimated_parameter.csv' ) )\n# param_CBTL[,-1] = round( param_CBTL[,-1], 3)\nparam_CBTL\n\nidx1 = with( param_CBTL, str_detect(variable,' - ') )\nidx2 = with( param_CBTL, \n             str_detect(variable,'^TIA') |\n               str_detect(variable,'^TI') | \n               str_detect(variable,'^BJ') )\n\nparam_ITCJ = read.csv( \n  file = file.path( dir,'summaries','4_6_2_ITCJ_estimated_parameter.csv' ) )\nparam_ITCJ[,-1] = round( param_ITCJ[,-1], 3)\n\nidx3 = with( param_ITCJ, str_detect(variable,' - ') )\nidx4 = with( param_ITCJ, \n            str_detect(variable,'^TIA') |\n              str_detect(variable,'^TI') | \n              str_detect(variable,'^BJ') )\n```\n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-parameter_estimates1 layout-ncol=2}\n\n```{r}\nparam_CBTL[!(idx1 | idx2), var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Parameter table\" ) |>\n  tab_footnote(\n    footnote = 'No equivalent parameter in original simulation.',\n    locations = cells_body(columns=1, rows=10) )\n```\n\n```{r}\nparam_ITCJ[!(idx3 | idx4), var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Parameter table\" )\n```\n\nParameter estimates. *Left table* reports the *CBTL analysis*. *Right table* reports the *ITCJ analysis*, model $6$.\n:::\n\n:::\n\n---\n\n## 5.3 Model comparison {style=\"font-size:80%;\"}\n\nAlso, we compare and interpret the parameter estimates: \n\n::: {.fragment style=\"font-size:80%;\"}\n\n::: {#fig-parameter_estimates2 layout-ncol=2}\n\n```{r}\nparam_CBTL[idx1, var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Contrast table\" )\n```\n\n```{r}\nparam_ITCJ[idx3, var_int] |>\n  gt() |>\n  opt_table_font( size=12 ) |>\n  fmt_number( columns=everything(), decimals=2, use_seps=F ) |>\n  # cols_label(\n  #   ROPE_lower = \"ropeL\",\n  #   ROPE_upper = \"ropeU\",\n  #   ROPE_prec = \"ropeP\"\n  # ) |>\n  tab_header( title = \"Contrast table\" )\n```\n\nContrast estimates. *Left table* reports the *CBTL analysis*. *Right table* reports the *ITCJ analysis*, model $6$.\n:::\n\n:::\n\n\n<!-- ######################################### -->\n\n\n# 6. Discussion\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nThis study fulfills its **two overarching goals**, that is,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Showing how apply the *ITCJ model* to a simulated dataset,\n\n    A **tutorial component**, offering detailed guidance on data simulation, prior and model specification, estimation, and interpretation using the software `R` and `Stan`.\n\n2. Evaluating whether the approach yield accurate and reliable trait estimates and inference parameters,\n\n    A **model validation component** benchmarked against the *CBTL analysis*.\n:::\n:::\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nThe *CBTL analysis* results provide preliminary evidence that,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- Researchers **cannot** treat \"sample-freeness\" as an inherent property of the BTL model, contrary to previous beliefs [@Bramley_2008; @Andrich_1978]. Instead, the property depends on the specific data under analysis.\n\n- When judges exhibit bias, the *CBTL analysis* **fails** to capture the complexity of the traits [@Thurstone_1927a; @Andrich_1978; @Bramley_2008; @Kelly_et_al_2022], producing **inaccurate and unreliable** estimates [@Ackerman_1989; @Zimmerman_1994; @McElreath_2020; @Hoyle_et_al_2023]. This limitation is particularly evident in the estimation of inference parameters and judges' biases.\n\n- The common CJ practice of separating trait estimation from hypothesis testing [@Casalicchio_et_al_2015; @Bramley_et_al_2019; @Boonen_et_al_2020; @Bouwer_et_al_2023; @vanDaal_et_al_2017; @Jones_et_al_2019; @Gijsen_et_al_2021], **introduces bias and reduces the reliability** of inferences [@McElreath_2020; @Kline_et_al_2023; @Hoyle_et_al_2023].\n\n- The BTL model is **overconfident** when predicting comparison outcomes, as shown by the posterior predictive checks based on the expected values.\n:::\n:::\n\n--- \n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nMoreover, the *CBTL analysis* results also provide preliminary evidence that,\n\n::: incremental \n::: {style=\"font-size:78%;\"}\n- Despite its **statistical definition** as an *outlier* detection tool [@Rivera_et_al_2025], *misfit* analysis **fail** to detect 'extreme' cases;\n\n- Despite its **conceptual definition** as a \"lack-of-consensus\" identification tool [@Pollitt_2012a; @Pollitt_2012b], *misfit* analysis **does not consistently classify all** stimuli, judges or individual exhibiting consensus or lack of consensus (see @fig-data_preference);\n\n    [ **Note:** The definition of consensus aligns with the microeconomics' concept of transitivity, that is, if $A \\succ B \\succ C$, then $A \\succ C$ [@Regenwetter_et_al_2011]. As Pollit [@Pollitt_2012a] explains: \"If a portfolio's WMS exceeds the criterion of mean plus two standard deviations, this means the judges did not judge it consistently, some considering it ‘better’ than others did. Significant portfolio misfit indicates a specific difference between judges in how they would **_rank order_** the portfolios, arising from a difference in how they understand or value the trait they are trying to assess.\" ]{style=\"font-size:80%;\"}\n\n- In fact, as show in this study, simple features of the data-generating process can produce lack of consensus or transitivity. For example, $\\text{IA}[6,3] \\succ \\text{IA}[6,7] \\succ \\text{IA}[31,6]$, but $\\text{IA}[31,6] \\succ \\text{IA}[6,3]$ (see @fig-data_preference);\n\n- Then, as expected, **excluding** *misfitting* stimuli and judges in a second model fit [@Pollitt_2012a; @Pollitt_2012b] **does not** improve trait estimation nor inferences, as the model continues to struggle with **'extreme' stimuli** and unmodeled data features.\n:::\n:::\n\n---\n\n## 6. Discussion {style=\"font-size:80%;\"}\n\nIn contrast, results from the ITCJ analysis indicate that,\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The frequentist BTL model and its *equivalent* Bayesian ITCJ models (models $1-3$) show **similar insufficient fit**; however, the ITCJ models exhibit a slightly better recovery performance due to the regularizing influence of **weakly informative priors** (see parameter recovery and RMSE plots).\n\n    [ **Note:** ITCJ models $1-3$ can be estimated with the `BTm()` function; however, the practice is largely absent in the current CJ literature. ]{style=\"font-size:80%;\"}\n    \n- Incorporating the hierarchical structure of stimuli and accounting for judges' biases (ITCJ model $4$) **improves** the prediction of comparison outcomes by up to $10$ percentage points in the overall True Positives (TP) and True Negatives (TN), as indicated by posterior predictive checks, more than including covariates in the model (model $3$).\n- Expanding the model to include the hierarchical structure of stimuli, judges' biases, heterogeneity in discriminal dispersions, and measurement error in inferences (ITCJ model $6$) **enhances both** the accuracy and reliability of all trait estimates and inference parameters. \n- ITCJ model $6$ enables to test other inferences not available under the *CBTL analysis* \n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 6.1 Future research directions\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\nBuilding upon Rivera et al. [@Rivera_et_al_2025], **four** research avenues deserve attention.\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. Sampling and comparison mechanisms,\n\n    This study used random sampling and comparison algorithms. Future work should assess how alternative sampling strategies and comparison algorithms affect the accuracy and reliability of trait estimates and inference parameters, e.g., \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- what happens when data is not randomly sampled or when comparison are not random? \n- is the Adaptive Comparative Judgment (ACJ) algorithm random or non-random?\n:::\n:::\n\n2. Validity of *'misfit'* analysis,\n\n    Preliminary evidence in this study suggest that *'misfit'* analysis often miss classifies or fails to classify cases. Future work should then determine, e.g., \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- what *'misfit'* analysis actually diagnose? \n- are its conceptual and statistical definitions aligned? \n- does the analysis function as an *outlier* detection tool? \n- does it holds real analytical value in the CJ workflow?\n:::\n:::\n    \n:::\n:::\n\n---\n\n## 6.1 Future research directions {style=\"font-size:80%;\"}\n\nBuilding upon Rivera et al. [@Rivera_et_al_2025], **four** research avenues deserve attention.\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n3. Sources of judges biases,\n\n    Evidence from this study indicates that researchers need to move beyond the traditional BTL model, explicitly integrating judges' biases in CJ analyses. This opens the door for future studies to investigate which factors influence these biases. For instance, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- do gender, age, culture, income, education, training, or expertise affect judges' biases?, \n- how many stimuli/individuals and judges are needed to support specific inferences?\n:::\n:::\n\n4. Prospective power and replication studies!\n\n    Considering the preliminary evidence of this study, \n    \n::: incremental \n::: {style=\"font-size:80%;\"}\n- in any random sample, what is the probability that at least one judge is biased?\n- if that probability is not low, how confident can researchers be that their CJ data are free of judges' biases? \n:::\n:::\n\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 6.2 Study limitations\n\n---\n\n## 6.2 Study limitations {style=\"font-size:80%;\"}\n\nDespite the relevance of its results, this study has some limitations:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- The empirical test of the *ITCJ analyses* relies on a single, *'small'* simulated dataset,\n- The assessment of out-of-sample fit depends on approximate measures, such as PSIS, \n- The analysis did not use additional variables from the simulated data to evaluate the models' ability to not reject null hypotheses when the null is true (except for judges' groups),\n- The study did not explicitly design or plan the evaluation of the *misfit* analysis properties.\n:::\n:::\n\n\n<!-- ######################################### -->\n\n# 7. Conclusion\n\n---\n\n## 7. Conclusion {style=\"font-size:80%;\"}\n\nThis study achieves its **two main goals**, \n\n::: incremental \n::: {style=\"font-size:80%;\"}\n1. It provides a practical tutorial in `R` and `Stan` on how to apply the *ITCJ analysis* to a CJ data, \n2. It validates the model's ability to produce accurate and reliable trait estimates and inference parameters compared to the *CBTL analysis*.\n:::\n:::\n\n:::{.fragment }\nThe results of the study indicates that,\n\n::: incremental \n:::{style=\"font-size:80%;\"}\n- Researchers should move beyond the *CBTL analysis* toward a more systematic, integrated approach for trait estimation and inference, as exemplified by the *ITCJ analysis* [@Rivera_et_al_2025]. \n\n- There are several promising directions for future research.\n:::\n:::\n:::\n\n<!-- ######################################### -->\n\n# Licence {style=\"font-size:80%;\"}\n\n---\n\n## Licence {style=\"font-size:80%;\"}\n\nAll the code that is original to this study and not attributed to any other authors is copyrighted by [Jose Manuel Rivera Espejo](https://orcid.org/0000-0002-3088-2783) and released under the new [BSD-3-Clause](https://opensource.org/license/BSD-3-Clause) license. \n\n<!-- ######################################### -->\n\n# Appendix A - From Design to Sample: Step 2 {#sec-AppA}\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\nThe study generates a synthetic random sample and comparison datasets from the conceptual population simulated in **Step 1**. \n\n::: {.fragment}\nMore specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms shown in @fig-cj17, sample size calculations were conducted assuming:\n\n::: incremental \n::: {style=\"font-size:80%;\"}\n- That \"reaching\" one children from the HI-HA or HI-CI groups costs ten times $(10x)$ more that \"reaching\" one NH child.\n- Three criteria for individual sample size selection: (1) a minimum power to detect $\\beta_{XIc}$ of $80\\%$ $(1-\\beta)$, (2) a minimum power to detect differences in $bXId$ of $80\\%$ $(1-\\beta)$, and (3) a maximum efficiency possible, i.e., less and more balanced sample sizes are preferred.\n- That \"hiring\" one AU judge cost five times $(5x)$ as much as \"hiring\" an IL judge, while \"hiring\" one PT judge cost three times $(3x)$ as much as an IL judge.\n- Three criteria for judge sample size selection: (1) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject $\\beta_{ZJc} = 0$, (2) a minimum confidence of $95\\%$ $(1 - \\alpha)$ to not reject differences in $\\beta_{ZJd}$ equal to zero, and (3) maximum efficiency, i.e., less and more balanced sample sizes are preferred.\n:::\n:::\n\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-individual_ss}\n![](/figures/population_summary/sim_individual_sample_size.png){width=100%}\n\nIndividual's sample size calculation, considering requirements for Power, Efficiency and Cost.\n:::\n:::\n\n---\n\n## Appendix A - From Design to Sample: Step 2 {style=\"font-size:80%;\"}\n\n::: {.fragment style=\"font-size:80%;\"}\n::: {#fig-judges_ss}\n![](/figures/population_summary/sim_judges_sample_size.png){width=100%}\n\nJudges's sample size calculation, considering requirements for Confidence, Efficiency and Cost.\n:::\n:::\n\n---\n\n# References {style=\"font-size:80%;\"}\n\n:::{#refs style=\"font-size:80%;\"}\n\n:::\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["styles.css"],"output-file":"presentation.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.550","auto-stretch":true,"slideNumber":true,"chalkboard":true,"previewLinks":"auto","csl":"diabetologia.csl","logo":"figures/logo-uantwerpen-sw-en-cmyk-pos.png","footer":"[Online manuscript (work in progress)](https://jriveraespejo.github.io/paper3_manuscript/)","title":"Finding CJ: The modeling of comparative judgment data with `R` (and `Stan`)\n","author":[{"name":{"given":"Jose(ma)","family":"Rivera"},"orcid":"0000-0002-3088-2783","url":"https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/","email":"JoseManuel.RiveraEspejo@uantwerpen.be","corresponding":true,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Tine","family":"van Daal"},"orcid":"0000-0001-9398-9775","url":"https://www.uantwerpen.be/en/staff/tine-vandaal/","email":"tine.vandaal@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Sven","family":"De Maeyer"},"orcid":"0000-0003-2888-1631","url":"https://www.uantwerpen.be/en/staff/sven-demaeyer/","email":"sven.demaeyer@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Training and education sciences","group":"Edubron"}]},{"name":{"given":"Steven","family":"Gillis"},"orcid":null,"url":"https://www.uantwerpen.be/nl/personeel/steven-gillis/","email":"steven.gillis@uantwerpen.be","corresponding":false,"affiliation":[{"name":"University of Antwerp","department":"Linguistics","group":"Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)"}]}],"date":"last-modified","bibliography":["references.bib"],"title-slide-attributes":{"data-notes":"(to do)\n"}}}},"projectFormats":["revealjs"]}