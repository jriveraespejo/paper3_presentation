---
title: |
  Bayesian modeling of comparative judgment data with `R` and `Stan`
author:
  - name: 
      given: Jose(ma)
      family: Rivera
    orcid: 0000-0002-3088-2783
    url: https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/
    email: JoseManuel.RiveraEspejo@uantwerpen.be
    corresponding: true
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Tine
      family: van Daal
    orcid: 0000-0001-9398-9775
    url: https://www.uantwerpen.be/en/staff/tine-vandaal/
    email: tine.vandaal@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Sven
      family: De Maeyer
    orcid: 0000-0003-2888-1631
    url: https://www.uantwerpen.be/en/staff/sven-demaeyer/
    email: sven.demaeyer@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Steven
      family: Gillis
    orcid: 
    url: https://www.uantwerpen.be/nl/personeel/steven-gillis/
    email: steven.gillis@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Linguistics
        group: Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)
date: last-modified
bibliography: references.bib
title-slide-attributes: 
  data-notes: | 
    (to do) 
---

# 1. Introduction {style="font-size:80%;"}

---

## 1. Introduction {style="font-size:80%;"}

The Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] offers a **simple method** for measuring traits and conducting statistical inference from comparative judgment (CJ) data [@Andrich_1978; @Pollitt_2012b]. 

[Its simplicity stems from two features:]{.fragment}

::: incremental 
::: {style="font-size:80%;"}
1. A reliance on an extensive set of simplifying assumptions about the traits, judges, and stimuli involved in CJ assessments [@Thurstone_1927b; @Bramley_2008],
2. The use of ad hoc procedures to handle inferences, including hypothesis testing [@Pollitt_2012b].
:::
:::

::: {.fragment}
However, recent studies question:

::: incremental 
::: {style="font-size:80%;"}
- Do these assumptions hold in modern CJ applications? [@Bramley_2008; @Kelly_et_al_2022; @Rivera_et_al_2025]
- Do the ad hoc procedures effectively fulfill their intended analytical purpose? [@Kelly_et_al_2022; @Rivera_et_al_2025]
:::
:::
:::

---

## 1. Introduction {style="font-size:80%;"}

To address these concerns, Rivera et al. [@Rivera_et_al_2025] proposed *The Information-Theoretical model for CJ*. 

[1. The approach extends the general form of Thurstone's law of comparative judgment [@Thurstone_1927a; @Thurstone_1927b], combining Thurstone's core theoretical principles with key CJ assessment design features.]{.fragment style="font-size:80%;"}

[2. This integration enables the development of models tailored to the assumed data-generating process of the CJ system under study, thus:]{.fragment style="font-size:80%;"}

::: incremental 
::: {style="font-size:80%;"}
- Eliminating the need to rely on the simplifying assumptions of the BTL model,
- Removing the dependence on ad hoc hypothesis-testing procedures.
:::
:::

[Nevertheless, although approach has the potential to yield reliable trait estimates and accurate statistical inferences, **this promise still needs to be empirically tested**.]{.fragment style="font-size:80%;"} 

<!-- ######################################### -->

# 2. Research goals

---

## 2. Research goals {style="font-size:80%;"}

Thus, this study has **two overarching goals**:

::: {.fragment style="font-size:80%;"}
1. *To show how apply the Information-Theoretical model for CJ to a simulated dataset*,

    A **tutorial component**, offering detailed guidance on data simulation, prior and model specification, estimation, and interpretation using the software `R` and `Stan`.
:::

::: {.fragment style="font-size:80%;"}
Once a *sufficiently trustworthy model* is found in goal 1,

2. *Evaluate whether the approach yield reliable trait estimates and accurate statistical inferences*,

    A **model validation component** benchmarked against the classical BTL analysis.
:::

<!-- ######################################### -->

# 3. A tale of two analytical approaches

---

## 3. A tale of two analytical approaches {style="font-size:80%;"}

CJ data can be analyzed under two analytical approaches:

::: incremental 
1. **The classical BTL analysis** [@Pollitt_2012a; @Pollitt_2012b],
    
    which applies several sequential methods to estimate (generate) the traits and conduct inferences,

2. **The Information-Theoretical model for CJ** [@Rivera_et_al_2025],

    which applies one systematic, integrated approach for the same two purposes.
:::

<!-- ######################################### -->

---

## 3.1 The classical BTL analysis {#sec-BTL style="font-size:80%;"}

This approach applies several sequential methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]:

::: incremental 
::: {style="font-size:80%;"}
1. **Apply the BTL model**,
    
::: incremental 
::: {style="font-size:80%;"}
- To estimate the traits of the stimuli (mean and standard error)
- To generate the model residuals
:::
:::

2. **Generate summaries** or **apply (multilevel) regression** to the stimuli's trait (mean estimates),
    
::: incremental 
::: {style="font-size:80%;"}
- To aggregate the trait of the stimuli at the individual level
- To assess the variability and conduct inferences at the stimuli and individual levels
- To calculate correlation with other methods (a way of "concurrent validity") or conduct inferences.
:::
:::

3. **Generate summaries** or **apply (multilevel) regression** to the model residuals,
    
::: incremental 
::: {style="font-size:80%;"}
- To aggregate the remaining variability at the judges level (investigate bias)
- To assess the remaining variability and conduct inferences about judges biases
- To conduct inferences, including *misfit* identification, for stimuli, individuals, and judges
:::
:::

:::
:::

<!-- ######################################### -->

--- 

## 3.2 The Information-Theoretical model for CJ {style="font-size:80%;"}

In contrast, this approach applies one systematic, integrated approach to estimate traits and conduct inferences [@Rivera_et_al_2025]. In broad terms, the approach:

::: incremental 
::: {style="font-size:80%;"}
1. Begins with the general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] (see next slide),
2. Adapts this structure to the assumed data-generating process of the CJ system under study,
3. Develops one or more *bespoke* statistical models for analyzing the CJ system.
4. Use the one or more statistical models to estimate traits and conduct inferences.
:::
:::

::: {.fragment}
With these steps a researcher can:

::: incremental 
::: {style="font-size:80%;"}
- Estimate the traits of the stimuli and individuals (full distribution)
- Assess the variability and conduct inferences at the stimuli and individual levels
- Estimate the biases of the judges and judgments (full distribution)
- Assess the variability and conduct inferences at the judgments and judges levels
- Conduct *oulier* identification for stimuli, individuals, judgments, and judges (akin to *misfit* identification)
:::
:::

:::

--- 

## 3.2 The Information-Theoretical model for CJ {style="font-size:80%;" #sec-3.2}

<!-- commands for d-separation -->
\newcommand{\dsep}{\:\bot\:}
\newcommand{\ndsep}{\:\not\bot\:}
\newcommand{\cond}{\:|\:}

The general CJ structure proposed by Rivera et al. [@Rivera_et_al_2025] takes the following form:

::: {.fragment style="font-size:80%;"}

::: {#fig-cj15 layout-ncol=2 }

![](/images/CJ_TM_15.png){width=80%}

$$
\begin{aligned}
  O_{R} & := f_{O}(D_{R}, S, C) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\
  e_{I} & \dsep \{ e_{J}, e_{IA}, e_{JK} \} \\
  e_{J} & \dsep \{ e_{IA}, e_{JK} \} \\
  e_{IA} & \dsep e_{JK} 
\end{aligned}
$$

Comparative judgment model. *Left panel* illustrates the DAG. *Right panel * depicts the associated SCM.
:::

:::

---

## 3.2 The Information-Theoretical model for CJ {style="font-size:80%;"}

Leading to the general probabilistic and statistical model:

::: {.fragment style="font-size:80%;"}

::: {#fig-cj16a layout-ncol=3}

$$
\begin{aligned}
  O_{R} & := f_{O}(D_{R}, S, C) \\ 
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\ \\
  e_{I} & \dsep \{ e_{J}, e_{IA}, e_{JK} \} \\
  e_{J} & \dsep \{ e_{IA}, e_{JK} \} \\
  e_{IA} & \dsep e_{JK}
\end{aligned}
$$

$$
\begin{aligned}
  & P( O_{R} \mid D_{R}, S, C ) \\
  & P( D_{R} \mid T_{IA}, B_{JK} ) \\
  & P( T_{IA} \mid T_{I}, X_{IA}, e_{IA} ) \\
  & P( T_{I} \mid X_{I}, e_{I} ) \\
  & P( B_{JK} \mid B_{J}, Z_{JK}, e_{JK} ) \\
  & P( B_{J} \mid Z_{J}, e_{J} ) \\ \\
  & P( e_{I} ) P( e_{IA} ) P( e_{J} ) P( e_{JK} ) \\ \\ \\
\end{aligned}
$$

$$
\begin{aligned}
  O_{R} & \overset{iid}{\sim} \text{Bernoulli} \left[ \text{inv_logit}( D_{R} ) \right] \\
  D_{R} & = \left( T_{IA}[i,a] - T_{IA}[h,b] \right) + B_{JK}[j,k] \\
  T_{IA} & = T_{I} + \beta_{XA} X_{IA} + e_{IA} \\
  T_{I} & = \beta_{XI} X_{I} + e_{I} \\
  B_{JK} & = B_{J} + \beta_{ZK} Z_{JK} + e_{JK} \\
  B_{J} & = \beta_{ZJ} Z_{J} + e_{J} \\ \\
  \boldsymbol{e} & \sim \text{Multi-Normal}( \boldsymbol{\mu}, \boldsymbol{\Sigma} )
  \\
  \boldsymbol{\Sigma} &= \boldsymbol{V} \boldsymbol{Q} \boldsymbol{V} \\ \\
\end{aligned}
$$

Comparative judgment model, assuming different discriminal dispersions for traits. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model. 
:::

:::


::: {.fragment}
Imposing the following constraints to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$ [@Depaoli_2021]: 
:::

::: {.fragment style="font-size:80%;"}

::: {#fig-cj16b}
$$
\boldsymbol{\mu} = [0, 0, 0, 0]^{T}; \quad 
\boldsymbol{Q} = \begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1 
  \end{bmatrix}; \quad 
  \boldsymbol{V} = \begin{bmatrix}
    s_{XI} & 0 & 0 & 0 \\
    0 & p_{IA} & 0 & 0 \\
    0 & 0 & s_{ZJ} & 0 \\
    0 & 0 & 0 & p_{JK} 
  \end{bmatrix}; \quad 
  \sum_{g=1}^{3} s_{XI}[g]/3 = 1; \quad
  0< p_{IA} < 1; \quad 
  \sum_{g=1}^{3} s_{ZJ}[g]/3 = 1; \quad
  0< p_{JK} < 1
$$ 

Constraints of the CJ model to solve indeterminacies in *location*, *orientation*, and *scale* of $T_{I}$, $T_{IA}$, $B_{J}$, and $B_{JK}$.
:::
:::

<!-- ######################################### -->

# 4. Methods 

---

## 4. Methods {#sec-methods style="font-size:80%;"}

To meet the tutorial and model validation goals, this study follows the Bayesian (research) workflow [@Depaoli_et_al_2017; @Neal_2020; @Gelman_et_al_2020; @Schad_et_al_2020; @Betancourt_2020; @McElreath_2024b; @McElreath_2024c]:

::: {#fig-workflow}
![](/images/workflow.png){width=80%}

Bayesian (research) workflow.
:::

---

## 4. Methods {style="font-size:80%;"}

Specifically, the study follows these steps (overarching goals in parenthesis):

::: incremental 
::: {style="font-size:75%;"}
1. **Theory $\rightarrow$ Estimand(s) $\rightarrow$ Design** (*Tutorial and Model validation*)

    Considering three steps: 

::: incremental 
a. Define the CJ structure and explicitly state its assumptions from relevant literature; 
b. Specify the estimand(s) of interest and provide formal definitions for each target parameter;
c. Simulate a _synthetic conceptual population_ that reflects the defined structure and assumptions;
:::

2. **Design $\rightarrow$ Sample** (*Tutorial and Model validation*)
    
    Generate _**two** synthetic samples and comparison datasets_ from the conceptual population in step $1$;

3. **{Theory, Design, Estimand(s)} $\rightarrow$ Estimator** (*Tutorial and Model validation*)

    Specify models for analyzing the _**first** synthetic comparison dataset_ using both the classical BTL analysis and the Information-Theoretical model for CJ;
    
4. **Estimator $\rightarrow$ Prior predictive** (*Tutorial*)

    Perform prior predictive checks;
:::
:::

---

## 4. Methods {style="font-size:80%;"}

::: incremental 
::: {style="font-size:75%;"}
5. **{Estimator, Sample} $\rightarrow$ Estimate(s)** (*Tutorial and Model validation*)

    Apply both the classical BTL model and the Information-Theoretical model for CJ to the _**first** synthetic comparison dataset_;

6. **Estimate(s) $\rightarrow$ {Diagnostic, Post predictive}** (*Tutorial*)

    Assess the quality of the models and estimate(s) in terms of stationarity, convergence, mixing, parameter recovery, in-sample fit, approximate out-of-sample fit, and in-sample predictive accuracy;
    
7. **{Diagnostic, Post predictive} $\rightarrow$ Estimator** (*Tutorial*)

    Incrementally refine the statistical model repeating steps 3–6 until a *sufficiently trustworthy model* is obtained according to the criteria outlined in step 6;

8. **Estimator $\rightarrow$ Estimate(s) $\rightarrow$ Effects $\leftarrow$ Estimand(s)** (*Model validation*)

    Generate the *estimate(s)* of interest for CJ the _**first** synthetic comparison dataset_ using both the classical BTL analysis and the Information-Theoretical model, and interpret the results;
    
9. **Estimator $\rightarrow$ Estimate(s) $\rightarrow$ Predictions $\leftarrow$ Estimand(s)** (*Model validation*)

    Generate predictions for the _**second** synthetic comparison dataset_ using both the classical BTL analysis and the Information-Theoretical model for CJ, and compare their out-of-sample predictive accuracy.
:::
:::


<!-- ######################################### -->

---

## 4.1 From Theory to Design: Steps 1a-1c {style="font-size:80%;"}

The conceptual population simulation is based on the data characteristics and findings reported by Boonen et al. [@Boonen_et_al_2020]:

::: {.fragment style="font-size:80%;"}
Regarding the data characteristics, the study:

::: incremental 
::: {style="font-size:80%;"}
- Includes multiple stimuli nested within multiple individuals,
- Considers individuals with different characteristics (e.g., age, hearing status),
- Assigns each judge to make only one comparison per stimulus pair,
- Involves judges who differ in characteristics (e.g., experience level),
- Selects stimuli, individuals, and judges using a (pseudo-)random sampling algorithm,
- Involves multiple judges performing multiple comparisons, assigned through a random comparison algorithm.
:::
:::

:::

::: {.fragment style="font-size:80%;"}
Regarding the study findings, the study report that:

::: incremental 
::: {style="font-size:80%;"}
- Individuals with different hearing statuses differ in both their mean latent trait levels and their **error variances**,
- More unexplained variability exists between individuals than within individuals (i.e., at the stimulus level),
- No evidence of systematic judge bias was found (treated here as a model assumption),
- Judges' experience levels did not account for differences in mean latent traits between stimuli, but differences in **error variances** were not assessed.
:::
:::

:::

---

## 4.1 From Theory to Design: Steps 1a-1c {style="font-size:80%;"}

Thus, adapting the general CJ structure proposed by Rivera et al.'s [@Rivera_et_al_2025] to the data characteristics reported by Boonen et al. [@Boonen_et_al_2020] lead to the following conceptual population data-generating process:

::: {.fragment style="font-size:80%;"}

::: {#fig-cj17 layout-ncol=2}

![](/images/CJ_population_DAG.png){width=85%}

$$
\begin{aligned}
  O_{R} & := f_{O}(D_{R}, S, C) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\ \\
  e_{I} & \dsep \{ e_{J}, e_{IA} \} \\
  e_{J} & \dsep \{ e_{IA} \}
\end{aligned}
$$

CJ data-generating process for the conceptual population. *Left panel* shows the DAG. *Right panel * depicts the associated SCM.
:::

:::

---

## 4.1 From Theory to Design: Steps 1a-1c {style="font-size:80%;"}

Moreover, integrating the adapted CJ structure with assumptions derived from Boonen et al.'s [@Boonen_et_al_2020] findings results in the following statistical data-generating process:

::: {.fragment style="font-size:80%;"}

::: {#fig-cj18a layout-ncol=3}

$$
\begin{aligned}
  O_{R} & := f_{O}(D_{R}, S, C) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\ \\
  e_{I} & \dsep \{ e_{J}, e_{IA} \} \\
  e_{J} & \dsep \{ e_{IA} \}
\end{aligned}
$$

$$
\begin{aligned}
  & P( O_{R} \mid D_{R}, S, C ) \\
  & P( D_{R} \mid T_{IA}, B_{JK} ) \\
  & P( T_{IA} \mid T_{I}, e_{IA} ) \\
  & P( T_{I} \mid X_{I}, e_{I} ) \\
  & P( B_{JK} \mid B_{J} ) \\
  & P( B_{J} \mid Z_{J}, e_{J} ) \\ \\
  & P( e_{I} ) P( e_{IA} ) P( e_{J} )
\end{aligned}
$$

$$
\begin{aligned}
  O_{R} & \overset{iid}{\sim} \text{Bernoulli} \left[ \text{inv_logit}( D_{R} ) \right] \\
  D_{R} & = \left( T_{IA}[i,a] - T_{IA}[h,b] \right) + B_{JK}[j,k] \\
  T_{IA} & = T_{I} + e_{IA} \\
  T_{I} & = \beta_{XI} X_{I} + e_{I} \\
  B_{JK} & = B_{J} \\
  B_{J} & = \beta_{ZJ} Z_{J} + e_{J} \\ \\
  \boldsymbol{e} & \sim \text{Multi-Normal}( \boldsymbol{\mu}, \boldsymbol{\Sigma} )
  \\
  \boldsymbol{\Sigma} &= \boldsymbol{V} \boldsymbol{Q} \boldsymbol{V}
\end{aligned}
$$

Data-generating process for simulated CJ data. *Left panel* illustrates the SCM. *Middle panel* shows the probabilistic model. *Right panel* illustrates the statistical model.
:::

:::

::: {.fragment}
With the following parameter assumptions:
:::

::: {.fragment style="font-size:80%;"}
::: {#fig-cj18b layout-ncol=2 }

$$
\begin{split}
X_{I} &= \{ X_{Ic}, X_{Id}[g=1], X_{Id}[g=2], X_{Id}[g=3] \} \\
\beta_{XI} & = \{ \beta_{XIc}, \beta_{XId[g=1]}, \beta_{XId[g=2]}, \beta_{XId[g=3]} \} = \{ 0.1, 1, 0, -1\} \\
Z_{J} &= \{ Z_{Jd}[g=1], Z_{Jd}[g=2], Z_{Jd}[g=3] \} \\
\beta_{ZJ} &= \{ \beta_{ZJd[g=1]}, \beta_{ZJd[g=2]}, \beta_{ZJd[g=3]} \} = \{ 0, 0, 0\}
\end{split}
$$

$$
\begin{split}
s_{XI[g]} &= \{ s_{XId[g=1]}, s_{XId[g=2]}, s_{XId[g=3]} \} = \{ 1.5, 0.75, 0.75\} \\
s_{ZJ} &= \{ s_{ZJd[g=1]}, s_{ZJd[g=2]}, s_{ZJd[g=3]} \} = \{ 0.5, 1, 1.5\} \\
p_{IA} &= 0.2 \\
\boldsymbol{\mu} &= [0, 0, 0]^{T}; \quad 
\boldsymbol{Q} = \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
\end{bmatrix} ;
\boldsymbol{V} = \begin{bmatrix}
    s_{XI} & 0 & 0 \\
    0 & p_{IA} & 0 \\
    0 & 0 & s_{ZJ} 
\end{bmatrix}
\end{split}
$$

Simulating parameter assumptions.
:::
:::


---

## 4.1 From Theory to Design: Steps 1a-1c {style="font-size:80%;"}

In layman terms:

::: incremental 
::: {style="font-size:60%;"}
- No stimuli characteristics $(X_{IA})$,
- Individual characteristics $(X_{I})$ include a continuous variable $(X_{Ic})$ for the age of children, and a categorical variable with three levels representing individual groups: normal-hearing (NH, $X_{Id}[g=1]$), hearing-impaired with hearing aids (HI-HA, $X_{Id}[g=2]$), and hearing-impaired with cochlear implants (HI-CI, $X_{Id}[g=3]$) children;
- There is a "small" [@Cohen_1988; @Sawilowsky_2009] but increasing effect of the continuous variable $(\beta_{XIc})$ on the mean latent trait of individuals;
- There are "very large" [@Cohen_1988; @Sawilowsky_2009] differences in the mean latent trait across individual groups $(\beta_{XId[g=1]} > \beta_{XId[g=2]} > \beta_{XId[g=3]})$;
- Judges make only one comparison; thus, there are no judgment-level characteristics $(Z_{JK})$, judgement-level effects $(\beta_{ZJK})$, or residual judgment variability $(p_{JK})$;
- Judges characteristics $(Z_{J})$ include a categorical variable with three levels representing judge groups: audiologist (AU, $Z_{Jd}[g=1]$), primary teachers (PT, $Z_{Jd}[g=2]$), and inexperienced listeners (IL, $Z_{Jd}[g=3]$);
- Judges exhibit biases, but mean latent biases across judge groups are equal to zero $(\beta_{ZJd[g=1]}=\beta_{ZJd[g=2]}=\beta_{ZJd[g=3]}=0)$;
- Residual latent errors $(\boldsymbol{e})$ are centered around zero with zero correlation $(\boldsymbol{\mu}, \boldsymbol{Q})$;
- Individual latent trait residual variability differs by groups ($s_{XId[g=1]} > s_{XId[g=2]} = s_{XId[g=3]}$, with $\sum_{g=1}^{3} s_{XId[g]}/3 = 1$);
- Judges' latent bias residual variability differs by groups ($s_{ZJd[g=1]} < s_{ZJd[g=2]} < s_{ZJD[g=3]}$, with $\sum_{g=1}^{3} s_{ZJ[g]}/3 = 1$);
- Stimuli latent trait residual variability is smaller than average individual latent trait residual variability $(p_{IA} < 1)$.
:::
:::


---

## 4.1 From Theory to Design: Steps 1a-1c {style="font-size:80%;"}

More importantly, the simulation parameters define the **_estimands_** of interest:

::: incremental 
::: {style="font-size:65%;"}
- $\beta_{XIc}$ represents the expected change in the individuals' mean latent trait for one additional year of age;
- $(\beta_{XId[g=1]} - \beta_{XId[g=2]})$, $(\beta_{XId[g=1]} - \beta_{XId[g=3]})$, and  $(\beta_{XId[g=2]} - \beta_{XId[g=3]})$ represent the expected differences in mean latent  traits between NH and HI-HA children, NH and HI-CI children, and HI-HA and HI-CI children, respectively;
- $(\beta_{ZJd[g=1]} - \beta_{ZJd[g=2]})$, $(\beta_{ZJd[g=1]} - \beta_{ZJd[g=3]})$, and $(\beta_{ZJd[g=2]} - \beta_{ZJd[g=3]})$ represent the expected differences in mean latent bias between AU and PT judges, AU and IL judges, and PT and IL judges, respectively;
- $(s_{XId[g=1]} - s_{XId[g=2]})$, $(s_{XId[g=1]} - s_{XId[g=3]})$, and $(s_{XId[g=2]} - s_{XId[g=3]})$ represent the expected differences in residual variability of the latent trait between NH and HI-HA children, NH and HI-CI children, and HI-HA and HI-CI children, respectively;
- $(s_{ZJd[g=1]} - s_{ZJd[g=2]})$, $(s_{ZJd[g=1]} - s_{ZJd[g=3]})$, and $(s_{ZJd[g=2]} - s_{ZJd[g=3]})$ represent the expected differences in residual variability of the latent bias between AU and PT judges, AU and IL judges, and PT and IL judges, respectively;
- $p_{IA}$ represents the residual variability of the stimuli latent trait.
:::
:::

<!-- ######################################### -->

---

## 4.2 From Design to Sample: Step 2 {style="font-size:80%;"}

Differing only by replication seed, the study generates _**two** synthetic samples and comparison datasets_ from the conceptual population in **Step 1**. 

::: {.fragment}
More specifically, for the sampling $(S)$ and comparison $(C)$ mechanisms shown in @fig-cj17, sample size calculations were conducted (see next slides) and the following design was adopted:

::: incremental 
::: {style="font-size:80%;"}
- A sample of $54$ individuals, divided into three groups: $40$ NH $(X_{Id}[g=1])$, $7$ HI-HA $(X_{Id}[g=2])$, and $7$ HI-CI $(X_{Id}[g=3])$ children;
- A sample of $10$ stimuli per individual;
- A sample of $60$ judges, divided into three groups: $10$ AU $(Z_{Jd}[g=1])$, $10$ PT $(Z_{Jd}[g=2])$, and $40$ IL $(Z_{Jd}[g=3])$;
- Judges conduct only one-comparison of the same stimulus pair (i.e., design is NOT a *repeated measures design* [@Lawson_2015, chap. 9.5])
- Each stimulus is compared 20 times in total against other stimuli, across all judges.
:::
:::

:::

---

## 4.2 From Design to Sample: Step 2 {style="font-size:80%;"}

::: {.fragment style="font-size:80%;"}
::: {#fig-individual_ss}
![](/images/sim_individual_sample_size.png){width=100%}

Individual's sample size calculation, considering requirements for Power, Efficiency and Cost.
:::
:::

---

## 4.2 From Design to Sample: Step 2 {style="font-size:80%;"}

::: {.fragment style="font-size:80%;"}
::: {#fig-judges_ss}
![](/images/sim_judges_sample_size.png){width=100%}

Judges's sample size calculation, considering requirements for Confidence, Efficiency and Cost.
:::
:::

<!-- ######################################### -->

---

## 4.3 From Estimator and Sample to Estimate(s): The software of step 5 {style="font-size:80%;"}

All analysis were conducted using `R` version 4.2.2 [@R_2015]. Specifically:

::: incremental 
::: {style="font-size:80%;"}
1. For the **classical BTL analysis** described in @sec-BTL [@Pollitt_2012a; @Pollitt_2012b], the study uses:
    
::: incremental 
::: {style="font-size:80%;"}
a. The `BradleyTerry2` package [@Turner_et_al_2012a; @Turner_et_al_2012b] and its `BTm()` function to fit the BTL model to the data, and estimate both the stimuli traits and model residuals.
b. The `brms` package [@Burkner_2017; @Burkner_2018] and `Stan` version 2.26.1 [@Stan_2020] to fit two separate Bayesian multilevel regression models: one for the stimuli mean traits and another for the model residuals. 
c. Additional `R` packages to generate summaries and predictions from the data and fitted models, such as [ADD]{style="color:red;"}
:::
:::

2. For the **Information-Theoretical model for CJ** [@Rivera_et_al_2025], the study uses:

::: incremental 
::: {style="font-size:80%;"}
a. `Stan` version 2.26.1 [@Stan_2020] to fit a series of increasingly complex Bayesian Information-Theoretical CJ models,
b. Additional `R` packages to generate summaries and predictions from the data and fitted models, such as [ADD]{style="color:red;"}
:::
:::

:::
:::

::: {.fragment style="font-size:80%;"}
Notably, **for each Bayesian model**, four Markov chains of $4000$ iterations were run, each with distinct starting values. The first $2000$ iterations served as warm-up, and the remaining $2000$ were used as posterior samples.
:::

<!-- ######################################### -->

---

## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style="font-size:80%;"}

The study assess the quality of the models and estimate(s) in terms of:

::: incremental 
::: {style="font-size:80%;"}
1. **_Stationarity, convergence, and mixing_**, using

::: incremental 
::: {style="font-size:80%;"}
- Graphical analyses, including trace plots, rank-normalized trace plots, autocorrelation function (ACF) plots, and comparison plot of prior to posterior distributions,
- Diagnostic statistics, including the potential scale reduction factor statistics $(\hat{R})$ with a cut-off value of $1.05$ [@Vehtari_et_al_2021] and effective sample size statistics $(n_{\text{eff}})$ [@Gelman_et_al_2014].
:::
:::

2. **_Parameter recovery_**, using

::: incremental 
::: {style="font-size:80%;"}
- The graphical comparisons of "true" parameters values versus posterior estimates,
- The parameter posterior Root Mean Squared Error $(\text{RMSE})$, defined as follows:
:::
:::
    
:::
:::

::: {.fragment}
$$
\text{RMSE}( \boldsymbol{\hat{\theta}}, \theta) = \sqrt{ \frac{1}{S} \sum_{s=1}^{S} ( \hat{\theta}_{s} - \theta )^2 }
$$
:::

::: {.fragment style="font-size:64%;"}
where $\boldsymbol{\hat{\theta}}$ is the vector of posterior samples associated with the "true" parameter $\theta$, and $\hat{\theta}_{s}$ is the $s$-th sample out of a total of $S$ posterior draws.
:::

---

## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style="font-size:80%;"}

The study assess the quality of the models and estimate(s) in terms of:

::: incremental 
::: {style="font-size:80%;"}
3. **_In-sample fit_**, using

::: incremental 
::: {style="font-size:80%;"}
- The deviance information criterion $(\text{DIC})$ [@Spiegelhalter_et_al_2002]
:::
:::

4. **_Approximate out-of-sample fit_**, using

::: incremental 
::: {style="font-size:80%;"}
- The widely applicable information criterion $(\text{WAIC})$ [@Watanabe_2013] and its standard error $(\text{SE}_{W})$, along with the differences in $\text{WAIC}$ between models $(\text{dWAIC} \pm 1 \cdot \text{dSE}_{W})$
- The Pareto Smoothing Importance Sampling criterion $(\text{PSIS})$ [@Vehtari_et_al_2017] and its standard error $(\text{SE}_{P})$, along with the differences in $\text{PSIS}$ between models $(\text{dPSIS} \pm 1 \cdot \text{dSE}_{P})$
:::
:::

5. **_In-sample predictive accuracy_**, using

::: incremental 
::: {style="font-size:80%;"}
- Confusion matrix comparing expected posterior predictions $E( \boldsymbol{\hat{y}_{s}})$ with observed outcomes $\boldsymbol{y}$ from the **_first_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,
- Confusion matrix comparing the posterior predictions $\hat{y}_{s}$ with observed outcomes  $\boldsymbol{y}$ from the **_first_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,
:::
:::

:::
:::

---

## 4.4 From Estimate(s) to Diagnostics and Post predictive: The evaluation criteria for step 6 {style="font-size:80%;"}

The study assess the quality of the models and estimate(s) in terms of:

::: incremental 
::: {style="font-size:80%;"}
6. **_Out-of-sample predictive accuracy_**, using

::: incremental 
::: {style="font-size:80%;"}
- Confusion matrix comparing expected posterior predictions $E( \boldsymbol{\hat{y}_{s}})$ with observed outcomes $\boldsymbol{y}$ from the **_second_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,
- Confusion matrix comparing the posterior predictions $\hat{y}_{s}$ with observed outcomes  $\boldsymbol{y}$ from the **_second_** synthetic dataset, both non-aggregated and aggregated at the levels of stimuli, individuals, and judges,
:::
:::

:::
:::


<!-- ######################################### -->

# 5. Results

---

## 5. Results {style="font-size:80%;"}

In this section, the study will:

::: incremental 
1. Describe the _**first** synthetic comparison dataset_;
2. Progress through the steps 3-7 of the Bayesian (research) workflow, described in @sec-methods, using:

::: incremental 
- The classical BTL analysis, and 
- The Information-Theoretical model for CJ
:::

:::

---

## 5.1 The first synthetic comparison dataset {style="font-size:80%;"}

In terms of design, the dataset reveals that:

::: incremental 
::: {style="font-size:80%;"}
- Most stimuli were compared $20$ times; only two stimuli (IDs $2$ and $3$) from individual $58$ were compared slightly fewer times due to random variation.
- The stimuli comparison network indicates a random *balanced design* [@Lawson_2015, chap. 7.4].
:::
:::

::: {.fragment style="font-size:80%;"}
::: {#fig-stimuli_comparisons layout-ncol=2}
![](/images/stimuli_comparisons_bottom.png){width=60%}

![](/images/stimuli_network.png){width=60%}

Comparison design. *Left panel* shows the number of comparisons for individuals $(Is)$ and stimuli $(As)$. *Right panel* shows the stimuli comparison network.
:::
:::

---

## 5.1 The first synthetic comparison dataset {style="font-size:80%;"}

In a similar manner, the data indicates:

::: incremental 
::: {style="font-size:80%;"}
- Most individuals were compared $200$ times ($20$ comparisons × $10$ stimuli each); only one individual (ID $58$) was compared slightly fewer times due to random design variation;
- The connected component analysis and individual comparison network indicates a fully connected network and a *balanced design* for individuals [@Lawson_2015, chap. 7.4].
:::
:::

::: {.fragment style="font-size:80%;"}
::: {#fig-individual_comparisons layout-ncol=2}

![](/images/individuals_comparisons.png){width=60%}

![](/images/individual_network.png){width=55%}

Comparison design. *Left panel* shows the number of comparisons for individuals. *Right panel* shows the individual comparison network.
:::
:::

---

## 5.1 The first synthetic comparison dataset {style="font-size:80%;"}

On the other hand, the dataset shows:

::: incremental 
::: {style="font-size:80%;"}
- Judges compare individuals with varying frequency, ranging from $0$ to $13$ comparisons;
- Most judges complete $262$ comparisons, while some $264$ due to random design variation;
:::
:::

::: {.fragment style="font-size:80%;"}
::: {#fig-judges_comparisons layout-ncol=2}
![](/images/judges2individuals_comparisons.png){width=60%}

![](/images/judges_comparisons.png){width=90%}

Comparison design. *Left panel* shows the judges $(Js)$ vs the first $10$ individuals $(Is)$. *Right panel* shows the total number of judges' comparisons.
:::
:::




---

## 5.1 The first synthetic comparison dataset {style="font-size:80%;"}

Moreover,

::: incremental 
::: {style="font-size:80%;"}
- Judges to individual comparison network indicates a fully connected network
:::
:::

::: {.fragment style="font-size:80%;"}
::: {#fig-judges_individuals_comparisons}
![](/images/judges_individuals_network.png){width=100%}

Bipartite graph of judges to individual comparison network.
:::
:::


<!-- ######################################### -->

---

## 5.2 The classical BTL analysis {style="font-size:80%;"}

This approach applies several sequential methods, each with different purposes [@Pollitt_2012a; @Pollitt_2012b; @Jones_et_al_2019; @Boonen_et_al_2020; @Chambers_et_al_2022; @Bouwer_et_al_2023]:

<!-- ######################################### -->

---

## 5.3 The Information-Theoretical model for CJ {style="font-size:80%;"}

<!-- ######################################### -->

---

## 5.2 From Estimands and Estimator to Effects and Predictions: Steps 8 and 9 {style="font-size:80%;"}

---

## 5.2.1 The second synthetic comparison dataset {style="font-size:80%;"}

<!-- ######################################### -->

---

## 5.2.2 The classical BTL analysis {style="font-size:80%;"}

<!-- ######################################### -->

---

## 5.2.3 The Information-Theoretical model for CJ {style="font-size:80%;"}

<!-- ######################################### -->


# 6. Discussion

---

## 6. Discussion {style="font-size:80%;"}


<!-- ######################################### -->

---

## 6.1 Future research directions {style="font-size:80%;"}

<!-- ######################################### -->

---

## 6.2 Study limitations {style="font-size:80%;"}


<!-- ######################################### -->

# 7. Conclusion

---

## 7. Conclusion {style="font-size:80%;"}

<!-- ######################################### -->

---

## Licence {style="font-size:80%;"}

All the code that is original to this study and not attributed to any other authors is copyrighted by *Jose Manuel Rivera Espejo* and released under the New BSD (3-Clause) License: [https://opensource.org/license/BSD-3-Clause](https://opensource.org/license/BSD-3-Clause)

<!-- ######################################### -->

---

# References {style="font-size:80%;"}

:::{#refs style="font-size:80%;"}

:::
